meta_material
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_8_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_8_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_8_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
5584310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.0499e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_8_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_8_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_8_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
5429155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.0865e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_5_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_5_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_5_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
2575310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=6.4573e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_6_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_6_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_6_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
961655
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.7510e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_8_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_8_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_8_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
1464655
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=5.8682e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_6_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_6_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_6_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
961655
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=5.0500e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_8_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_8_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_8_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
5429155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.7444e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_6_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_6_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_6_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
3888620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.7008e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_5_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_5_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_5_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
2575310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=5.3039e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_7_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_7_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_7_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
1213155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.1998e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_7_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_7_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_7_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
4426155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=5.0386e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_6_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_6_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_6_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
3888620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.8895e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_6_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_6_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_6_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
3578310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.2735e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_9_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_9_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_9_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
6587310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.0450e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_5_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_5_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_5_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
943120
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=8.5746e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_4_unit_250_lr_0.0001_reg_scale_0.001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_4_unit_250_lr_0.0001_reg_scale_0.001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=250, bias=True)
    (1): Linear(in_features=250, out_features=250, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=250, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=250, out_features=125, bias=True)
    (mu): Linear(in_features=250, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_4_unit_250_lr_0.0001_reg_scale_0.001
number of trainable parameters is :
166905
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=250, bias=True)
    (1): Linear(in_features=250, out_features=250, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=250, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=250, out_features=125, bias=True)
    (mu): Linear(in_features=250, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.4817e-05)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_8_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_8_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_8_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
1542310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.2145e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_9_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_9_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_9_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
6897620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.6675e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_7_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_7_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_7_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
1290810
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=5.5369e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_5_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_5_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_5_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
943120
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=9.8073e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_8_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_8_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_8_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
1697620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.4083e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_5_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_5_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_5_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
787810
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=8.6822e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_7_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_7_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_7_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
1290810
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.7445e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_6_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_6_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_6_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
3578310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.8945e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_8_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_8_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_8_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
1464655
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.5531e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_5_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_5_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_5_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
787810
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=7.2274e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_9_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_9_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_9_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
1949120
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.1034e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_6_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_6_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_6_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
1194620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.7374e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_7_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_7_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_7_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
1446120
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.4656e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_5_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_5_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_5_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
2885620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=6.9883e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_7_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_7_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_7_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
4426155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.4439e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_9_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_9_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_9_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
1793810
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.5680e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_8_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_8_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_8_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
5894620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.5014e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_7_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_7_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_7_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
4891620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=1.9049e-05)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_7_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_7_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_7_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
4891620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.4670e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_5_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_5_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_5_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
2420155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=5.7450e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_6_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_6_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_6_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
3423155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=2.4384e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_5_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_5_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_5_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
2420155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=7.8102e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_6_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_6_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_6_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
1194620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=5.9383e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_9_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_9_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_9_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
1949120
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.2990e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_8_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_8_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_8_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
1542310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.3155e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_8_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_8_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_8_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
5894620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=2.8437e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_4_unit_250_lr_0.0001_reg_scale_0.001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_4_unit_250_lr_0.0001_reg_scale_0.001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=250, bias=True)
    (1): Linear(in_features=250, out_features=250, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=250, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=250, out_features=250, bias=True)
    (mu): Linear(in_features=250, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_4_unit_250_lr_0.0001_reg_scale_0.001
number of trainable parameters is :
205810
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=250, bias=True)
    (1): Linear(in_features=250, out_features=250, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=250, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=250, out_features=250, bias=True)
    (mu): Linear(in_features=250, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.1938e-05)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_9_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_9_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_9_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
6897620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.2581e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_6_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_6_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_6_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
1039310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=8.2670e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_9_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_9_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_9_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
1716155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.1534e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_7_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_7_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_7_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
4581310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.8903e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_8_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_8_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_8_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
5584310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.9103e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_7_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_7_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_7_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
1446120
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=6.2652e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_9_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_9_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_9_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
1793810
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.1862e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_5_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_5_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_5_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
710155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=1.0076e-05)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_6_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_6_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_6_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
3423155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.4679e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_9_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_9_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_9_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
6432155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.1049e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_7_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_7_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_7_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
1213155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=5.3937e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_8_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_8_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_8_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
1697620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=500, bias=True)
    (mu): Linear(in_features=500, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.2652e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_20_layer_num_5_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_20_layer_num_5_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
Chen/Chen_gaussian_20_layer_num_5_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
2885620
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=500, bias=True)
    (mu): Linear(in_features=1000, out_features=100, bias=True)
  )
)
size of sigma =  torch.Size([100, 20, 5, 5])
size of mu =  torch.Size([100, 20, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=6.0553e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_5_unit_500_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_5_unit_500_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_5_unit_500_lr_0.0001_reg_scale_0
number of trainable parameters is :
710155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=7.2645e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_6_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_6_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_6_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
1039310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=250, bias=True)
    (mu): Linear(in_features=500, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.3660e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_9_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_9_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_9_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
6587310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=4.4505e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_9_unit_500_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_9_unit_500_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_9_unit_500_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
1716155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=125, bias=True)
    (mu): Linear(in_features=500, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.8589e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_5_layer_num_9_unit_1000_lr_0.0001_reg_scale_0.0001
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_5_layer_num_9_unit_1000_lr_0.0001_reg_scale_0.0001
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
Chen/Chen_gaussian_5_layer_num_9_unit_1000_lr_0.0001_reg_scale_0.0001
number of trainable parameters is :
6432155
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=125, bias=True)
    (mu): Linear(in_features=1000, out_features=25, bias=True)
  )
)
size of sigma =  torch.Size([100, 5, 5, 5])
size of mu =  torch.Size([100, 5, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.0259e-06)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Chen/Chen_gaussian_10_layer_num_7_unit_1000_lr_0.0001_reg_scale_0
In read_data, flags.data_set = Chen
flgas.data_dir =  /home/sr365/MM_Bench/Data/
data_dir =  /home/sr365/MM_Bench/Data/Chen
total number of training sample is 49900, the dimension of the feature is 5
total number of test sample is 100
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/MDN/models/Chen/Chen_gaussian_10_layer_num_7_unit_1000_lr_0.0001_reg_scale_0
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
Chen/Chen_gaussian_10_layer_num_7_unit_1000_lr_0.0001_reg_scale_0
number of trainable parameters is :
4581310
Start eval now:
model in eval: MDN(
  (linears): ModuleList(
    (0): Linear(in_features=256, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=250, bias=True)
    (mu): Linear(in_features=1000, out_features=50, bias=True)
  )
)
size of sigma =  torch.Size([100, 10, 5, 5])
size of mu =  torch.Size([100, 10, 5])
Si3N4@@@/home/sr365/MM_Bench/Data/Chen/Si3N4_310nm-14280nm.txt shape=(1552, 3)
   lenda    re   im
0    310  2.18  0.0
1    360  2.12  0.0
2    410  2.09  0.0
3    470  2.07  0.0
4    520  2.06  0.0
Graphene@@@/home/sr365/MM_Bench/Data/Chen/Graphene_240nm-30000nm.txt shape=(28001, 3)
   lenda        re        im
0   2000  3.306460  3.152633
1   2001  3.307247  3.153458
2   2002  3.308034  3.154284
3   2003  3.308821  3.155109
4   2004  3.309608  3.155934
in compare truth pred function in eval_help package, your shape of pred file is (100, 256)
(Avg MSE=3.0569e-06)
Evaluation finished
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 240, training loss -10.80655, validation loss 0.00113
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 260, training loss -11.04506, validation loss 0.00047
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 280, training loss -11.22796, validation loss 0.00041
Saving the model down...
In read_data, flags.data_set = Peurifoy
shape of data_x (50000, 3)
shape of data_y (50000, 201)
total number of training sample is 40000, the dimension of the feature is 3
total number of test sample is 10000
Making network now
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=201, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=90, bias=True)
    (mu): Linear(in_features=500, out_features=30, bias=True)
  )
)
Start training now...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 0, training loss 0.04397, validation loss 0.29738
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 20, training loss -8.23314, validation loss 0.00310
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 40, training loss -8.46954, validation loss 0.00163
Saving the model down...
Epoch    56: reducing learning rate of group 0 to 8.0000e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 60, training loss -8.51928, validation loss 0.00141
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 80, training loss -9.21564, validation loss 0.00128
Saving the model down...
Epoch    99: reducing learning rate of group 0 to 6.4000e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 100, training loss -8.61056, validation loss 0.00088
Saving the model down...
Epoch   110: reducing learning rate of group 0 to 5.1200e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 120, training loss -9.51013, validation loss 0.00162
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 140, training loss -9.69399, validation loss 0.00128
Epoch   144: reducing learning rate of group 0 to 4.0960e-05.
Epoch   155: reducing learning rate of group 0 to 3.2768e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 160, training loss -9.90001, validation loss 0.00066
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 180, training loss -10.35892, validation loss 0.00078
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 200, training loss -10.52925, validation loss 0.00085
Epoch   209: reducing learning rate of group 0 to 2.6214e-05.
Epoch   220: reducing learning rate of group 0 to 2.0972e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 220, training loss -10.16992, validation loss 0.00064
Saving the model down...
Epoch   231: reducing learning rate of group 0 to 1.6777e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 240, training loss -10.71773, validation loss 0.00052
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 260, training loss -10.97115, validation loss 0.00051
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 280, training loss -11.17848, validation loss 0.00047
Saving the model down...
In read_data, flags.data_set = Peurifoy
shape of data_x (50000, 3)
shape of data_y (50000, 201)
total number of training sample is 40000, the dimension of the feature is 3
total number of test sample is 10000
Making network now
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=201, out_features=500, bias=True)
    (1): Linear(in_features=500, out_features=500, bias=True)
    (2): Linear(in_features=500, out_features=500, bias=True)
    (3): Linear(in_features=500, out_features=500, bias=True)
    (4): Linear(in_features=500, out_features=500, bias=True)
    (5): Linear(in_features=500, out_features=500, bias=True)
    (6): Linear(in_features=500, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=500, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=500, out_features=180, bias=True)
    (mu): Linear(in_features=500, out_features=60, bias=True)
  )
)
Start training now...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 0, training loss 0.41593, validation loss 0.27774
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 20, training loss -8.13059, validation loss 0.00232
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 40, training loss -8.27191, validation loss 0.00261
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 60, training loss -8.67538, validation loss 0.00310
Epoch    65: reducing learning rate of group 0 to 8.0000e-05.
Epoch    76: reducing learning rate of group 0 to 6.4000e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 80, training loss -8.93387, validation loss 0.00138
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 100, training loss -9.60659, validation loss 0.00089
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 120, training loss -9.74738, validation loss 0.00165
Epoch   130: reducing learning rate of group 0 to 5.1200e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 140, training loss -9.54533, validation loss 0.00105
Epoch   141: reducing learning rate of group 0 to 4.0960e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 160, training loss -10.10841, validation loss 0.00098
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 180, training loss -10.39985, validation loss 0.00053
Saving the model down...
Epoch   200: reducing learning rate of group 0 to 3.2768e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 200, training loss -9.72477, validation loss 0.00055
Epoch   211: reducing learning rate of group 0 to 2.6214e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 220, training loss -10.36898, validation loss 0.00061
Epoch   222: reducing learning rate of group 0 to 2.0972e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 240, training loss -10.83952, validation loss 0.00055
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 260, training loss -10.82040, validation loss 0.00038
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 280, training loss -11.14701, validation loss 0.00032
Saving the model down...
In read_data, flags.data_set = Peurifoy
shape of data_x (50000, 3)
shape of data_y (50000, 201)
total number of training sample is 40000, the dimension of the feature is 3
total number of test sample is 10000
Making network now
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=201, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=5, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=45, bias=True)
    (mu): Linear(in_features=1000, out_features=15, bias=True)
  )
)
Start training now...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 0, training loss -2.02523, validation loss 0.10280
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 20, training loss -7.50734, validation loss 0.00525
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 40, training loss -7.53299, validation loss 0.00330
Saving the model down...
Epoch    57: reducing learning rate of group 0 to 8.0000e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 60, training loss -8.64808, validation loss 0.00252
Saving the model down...
Epoch    76: reducing learning rate of group 0 to 6.4000e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 80, training loss -8.91833, validation loss 0.00311
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 100, training loss -9.14388, validation loss 0.00138
Saving the model down...
Epoch   102: reducing learning rate of group 0 to 5.1200e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 120, training loss -9.64494, validation loss 0.00100
Saving the model down...
Epoch   132: reducing learning rate of group 0 to 4.0960e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 140, training loss -9.60623, validation loss 0.00187
Epoch   159: reducing learning rate of group 0 to 3.2768e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 160, training loss -9.68683, validation loss 0.00173
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 180, training loss -10.13139, validation loss 0.00135
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 200, training loss -10.40388, validation loss 0.00063
Saving the model down...
Epoch   215: reducing learning rate of group 0 to 2.6214e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 220, training loss -10.21352, validation loss 0.00063
Saving the model down...
Epoch   226: reducing learning rate of group 0 to 2.0972e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 240, training loss -10.76028, validation loss 0.00043
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 260, training loss -11.08348, validation loss 0.00052
Epoch   270: reducing learning rate of group 0 to 1.6777e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 5, 3, 3])
size of mu =  torch.Size([1024, 5, 3])
This is Epoch 280, training loss -10.83699, validation loss 0.00037
Saving the model down...
Epoch   281: reducing learning rate of group 0 to 1.3422e-05.
In read_data, flags.data_set = Peurifoy
shape of data_x (50000, 3)
shape of data_y (50000, 201)
total number of training sample is 40000, the dimension of the feature is 3
total number of test sample is 10000
Making network now
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=201, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=10, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=90, bias=True)
    (mu): Linear(in_features=1000, out_features=30, bias=True)
  )
)
Start training now...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 0, training loss -2.18642, validation loss 0.08278
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 20, training loss -7.73609, validation loss 0.00542
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 40, training loss -8.32493, validation loss 0.00421
Saving the model down...
Epoch    55: reducing learning rate of group 0 to 8.0000e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 60, training loss -8.54724, validation loss 0.00292
Saving the model down...
Epoch    80: reducing learning rate of group 0 to 6.4000e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 80, training loss -8.96017, validation loss 0.00139
Saving the model down...
Epoch    91: reducing learning rate of group 0 to 5.1200e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 100, training loss -9.50199, validation loss 0.00111
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 120, training loss -9.24842, validation loss 0.00189
Epoch   122: reducing learning rate of group 0 to 4.0960e-05.
Epoch   133: reducing learning rate of group 0 to 3.2768e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 140, training loss -9.93956, validation loss 0.00075
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 160, training loss -10.54321, validation loss 0.00053
Saving the model down...
Epoch   172: reducing learning rate of group 0 to 2.6214e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 180, training loss -10.20977, validation loss 0.00125
Epoch   183: reducing learning rate of group 0 to 2.0972e-05.
Epoch   194: reducing learning rate of group 0 to 1.6777e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 200, training loss -10.67848, validation loss 0.00049
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 220, training loss -10.96157, validation loss 0.00049
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 240, training loss -11.23890, validation loss 0.00039
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 260, training loss -11.18731, validation loss 0.00075
Epoch   261: reducing learning rate of group 0 to 1.3422e-05.
Epoch   272: reducing learning rate of group 0 to 1.0737e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 10, 3, 3])
size of mu =  torch.Size([1024, 10, 3])
This is Epoch 280, training loss -11.25991, validation loss 0.00032
Saving the model down...
Epoch   283: reducing learning rate of group 0 to 8.5899e-06.
Epoch   294: reducing learning rate of group 0 to 6.8719e-06.
In read_data, flags.data_set = Peurifoy
shape of data_x (50000, 3)
shape of data_y (50000, 201)
total number of training sample is 40000, the dimension of the feature is 3
total number of test sample is 10000
Making network now
MDN(
  (linears): ModuleList(
    (0): Linear(in_features=201, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mdn): MDN(
    (pi): Sequential(
      (0): Linear(in_features=1000, out_features=20, bias=True)
      (1): Softmax(dim=1)
    )
    (sigma): Linear(in_features=1000, out_features=180, bias=True)
    (mu): Linear(in_features=1000, out_features=60, bias=True)
  )
)
Start training now...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 0, training loss -2.05534, validation loss 0.08885
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 20, training loss -7.22932, validation loss 0.00893
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 40, training loss -8.06120, validation loss 0.00248
Saving the model down...
Epoch    43: reducing learning rate of group 0 to 8.0000e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 60, training loss -8.52925, validation loss 0.00266
Epoch    70: reducing learning rate of group 0 to 6.4000e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 80, training loss -9.22651, validation loss 0.00221
Saving the model down...
Epoch    90: reducing learning rate of group 0 to 5.1200e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 100, training loss -9.16066, validation loss 0.00153
Saving the model down...
Epoch   101: reducing learning rate of group 0 to 4.0960e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 120, training loss -9.63802, validation loss 0.00173
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 140, training loss -9.51838, validation loss 0.00192
Epoch   141: reducing learning rate of group 0 to 3.2768e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 160, training loss -10.19863, validation loss 0.00125
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 180, training loss -10.17616, validation loss 0.00113
Saving the model down...
Epoch   188: reducing learning rate of group 0 to 2.6214e-05.
Epoch   199: reducing learning rate of group 0 to 2.0972e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 200, training loss -9.63026, validation loss 0.00063
Saving the model down...
Epoch   210: reducing learning rate of group 0 to 1.6777e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 220, training loss -10.82763, validation loss 0.00052
Saving the model down...
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 240, training loss -11.06259, validation loss 0.00047
Saving the model down...
Epoch   259: reducing learning rate of group 0 to 1.3422e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 260, training loss -10.52352, validation loss 0.00090
Epoch   270: reducing learning rate of group 0 to 1.0737e-05.
Doing Evaluation on the model now
size of sigma =  torch.Size([1024, 20, 3, 3])
size of mu =  torch.Size([1024, 20, 3])
This is Epoch 280, training loss -11.06880, validation loss 0.00098
Epoch   281: reducing learning rate of group 0 to 8.5899e-06.
