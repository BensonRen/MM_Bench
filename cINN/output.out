fake_2k
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7fab970c7ed0>, <FrEIA.framework.Node object at 0x7fab9609df90>, <FrEIA.framework.Node object at 0x7fab96010410>, <FrEIA.framework.Node object at 0x7fab96010490>, <FrEIA.framework.Node object at 0x7fab96010510>, <FrEIA.framework.Node object at 0x7fab96010590>, <FrEIA.framework.Node object at 0x7fab96010610>, <FrEIA.framework.Node object at 0x7fab96010690>, <FrEIA.framework.Node object at 0x7fab96010710>, <FrEIA.framework.Node object at 0x7fab96010790>, <FrEIA.framework.Node object at 0x7fab96010810>, <FrEIA.framework.Node object at 0x7fab96010890>, <FrEIA.framework.Node object at 0x7fab96010910>, <FrEIA.framework.Node object at 0x7fab96010990>, <FrEIA.framework.Node object at 0x7fab96010a10>, <FrEIA.framework.OutputNode object at 0x7fab96010a50>, <FrEIA.framework.ConditionNode object at 0x7fab96095bd0>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'coupling_6' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_6' takes the following inputs:
	 Output #0 of node 'coupling_6' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_6' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (14): PermuteRandom()
    (15): dummy()
    (16): None
  )
)
Yang/Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005
number of trainable parameters is :
5250756
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: mm4.pt
entering: mm5.pt
entering: mm1.pt
entering: mm6.pt
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: mm2.pt
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.852956  0.220900  1.065769  ...  0.079773 -0.219759  0.131969
1  0.921393  0.543554  0.157115  ...  0.385837  0.809758  0.466194
2  0.170848 -0.625883 -0.226945  ...  1.005194 -0.393970 -0.109585
3 -0.747838  0.116330 -0.553214  ... -0.935669  0.031301  0.637906
4 -0.297393 -0.701879  0.156574  ...  0.583903  0.132836 -0.232008

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06311111 0.05602823 0.04753659 ... 0.95726454 0.8445212  0.65748715]
 [0.06241791 0.05484949 0.0457614  ... 0.91915035 0.8138908  0.63578105]
 [0.05970559 0.05002344 0.03820124 ... 0.8956683  0.79238284 0.6187085 ]
 ...
 [0.06007729 0.05077808 0.03949883 ... 0.98430514 0.8669369  0.67380536]
 [0.06189755 0.05401891 0.04457466 ... 0.7931914  0.70826244 0.5580256 ]
 [0.06129612 0.05281509 0.04251935 ... 0.7730274  0.6911011  0.5451735 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.852956  0.220900  1.065769  ...  0.079773 -0.219759  0.131969
1  0.921393  0.543554  0.157115  ...  0.385837  0.809758  0.466194
2  0.170848 -0.625883 -0.226945  ...  1.005194 -0.393970 -0.109585
3 -0.747838  0.116330 -0.553214  ... -0.935669  0.031301  0.637906
4 -0.297393 -0.701879  0.156574  ...  0.583903  0.132836 -0.232008

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10738091 -0.03189546  0.04766375 ...  0.99694014  0.8079221
   0.646441  ]
 [-0.10770443 -0.03248829  0.04662967 ...  0.9577817   0.7749734
   0.6199343 ]
 [-0.10825777 -0.03341112  0.0451265  ...  0.9394535   0.75758696
   0.604735  ]
 ...
 [-0.11298718 -0.04104373  0.03297898 ...  1.048207    0.8503494
   0.68009853]
 [-0.10843085 -0.03361851  0.0448814  ...  0.8330771   0.67385185
   0.5410478 ]
 [-0.10851553 -0.0338212   0.04448155 ...  0.8259084   0.6665168
   0.53432333]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.852956  0.220900  1.065769  ...  0.079773 -0.219759  0.131969
1  0.921393  0.543554  0.157115  ...  0.385837  0.809758  0.466194
2  0.170848 -0.625883 -0.226945  ...  1.005194 -0.393970 -0.109585
3 -0.747838  0.116330 -0.553214  ... -0.935669  0.031301  0.637906
4 -0.297393 -0.701879  0.156574  ...  0.583903  0.132836 -0.232008

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08442608 0.05812771 0.02082876 ... 0.93757224 0.83481973 0.66929317]
 [0.08281367 0.05573731 0.01761388 ... 0.9044925  0.80887145 0.65177304]
 [0.08568745 0.05966556 0.02256839 ... 0.8795136  0.7857211  0.63296086]
 ...
 [0.08220207 0.05449306 0.01559781 ... 0.96813154 0.85936326 0.6863671 ]
 [0.08261985 0.05546845 0.01728173 ... 0.7733708  0.7005782  0.5739581 ]
 [0.08579613 0.06003744 0.02328324 ... 0.76484466 0.69228035 0.5668589 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.852956  0.220900  1.065769  ...  0.079773 -0.219759  0.131969
1  0.921393  0.543554  0.157115  ...  0.385837  0.809758  0.466194
2  0.170848 -0.625883 -0.226945  ...  1.005194 -0.393970 -0.109585
3 -0.747838  0.116330 -0.553214  ... -0.935669  0.031301  0.637906
4 -0.297393 -0.701879  0.156574  ...  0.583903  0.132836 -0.232008

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09531713 0.07299584 0.03626929 ... 0.90884554 0.8240293  0.6800396 ]
 [0.091547   0.06691954 0.02854329 ... 0.8853097  0.8062264  0.6687162 ]
 [0.09344934 0.06961468 0.03120786 ... 0.8659438  0.7892777  0.6566288 ]
 ...
 [0.09113187 0.06612647 0.02728526 ... 0.9556365  0.86062574 0.7039896 ]
 [0.08987215 0.06430568 0.02537084 ... 0.77053785 0.71474147 0.6078485 ]
 [0.09157696 0.06692009 0.02839142 ... 0.752655   0.7005719  0.59847987]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.852956  0.220900  1.065769  ...  0.079773 -0.219759  0.131969
1  0.921393  0.543554  0.157115  ...  0.385837  0.809758  0.466194
2  0.170848 -0.625883 -0.226945  ...  1.005194 -0.393970 -0.109585
3 -0.747838  0.116330 -0.553214  ... -0.935669  0.031301  0.637906
4 -0.297393 -0.701879  0.156574  ...  0.583903  0.132836 -0.232008

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.17688337  0.07354534  0.01068816 ...  0.8983708   0.8028357
   0.65205157]
 [ 0.16605917  0.05684197 -0.00856912 ...  0.897419    0.80501604
   0.65516543]
 [ 0.17300974  0.06781247  0.0014925  ...  0.8567252   0.7687155
   0.62752575]
 ...
 [ 0.1681424   0.06009105 -0.00486594 ...  0.96676767  0.855619
   0.688294  ]
 [ 0.17213695  0.06620628  0.00209284 ...  0.7592825   0.69680536
   0.5800031 ]
 [ 0.16848531  0.06062925 -0.00491109 ...  0.75393033  0.6931704
   0.57777095]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.852956  0.220900  1.065769  ...  0.079773 -0.219759  0.131969
1  0.921393  0.543554  0.157115  ...  0.385837  0.809758  0.466194
2  0.170848 -0.625883 -0.226945  ...  1.005194 -0.393970 -0.109585
3 -0.747838  0.116330 -0.553214  ... -0.935669  0.031301  0.637906
4 -0.297393 -0.701879  0.156574  ...  0.583903  0.132836 -0.232008

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09327252 0.03576417 0.02067649 ... 0.9238157  0.8181554  0.6293366 ]
 [0.09174936 0.03342782 0.01776735 ... 0.89739656 0.7983595  0.61686647]
 [0.0939597  0.03656122 0.02085185 ... 0.8733164  0.77686167 0.6019718 ]
 ...
 [0.09237258 0.03416149 0.0179705  ... 0.96745026 0.851606   0.6507036 ]
 [0.09284917 0.03517272 0.0201274  ... 0.7705772  0.6971967  0.55071735]
 [0.0937081  0.03639914 0.0213742  ... 0.75472975 0.6842265  0.54212344]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.852956  0.220900  1.065769  ...  0.079773 -0.219759  0.131969
1  0.921393  0.543554  0.157115  ...  0.385837  0.809758  0.466194
2  0.170848 -0.625883 -0.226945  ...  1.005194 -0.393970 -0.109585
3 -0.747838  0.116330 -0.553214  ... -0.935669  0.031301  0.637906
4 -0.297393 -0.701879  0.156574  ...  0.583903  0.132836 -0.232008

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12749535  0.06696132 -0.00864825 ...  0.9125867   0.8100787
   0.72992015]
 [ 0.1185829   0.05537367 -0.02265537 ...  0.8883069   0.793077
   0.71890354]
 [ 0.13053018  0.06929132 -0.00810236 ...  0.86316454  0.7710157
   0.70170313]
 ...
 [ 0.12536976  0.06393927 -0.01266325 ...  0.94221836  0.8322755
   0.7452471 ]
 [ 0.12421331  0.06262651 -0.01398608 ...  0.7616584   0.6950041
   0.6492299 ]
 [ 0.12486643  0.06298655 -0.01424536 ...  0.75010717  0.6861455
   0.6429879 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.852956  0.220900  1.065769  ...  0.079773 -0.219759  0.131969
1  0.921393  0.543554  0.157115  ...  0.385837  0.809758  0.466194
2  0.170848 -0.625883 -0.226945  ...  1.005194 -0.393970 -0.109585
3 -0.747838  0.116330 -0.553214  ... -0.935669  0.031301  0.637906
4 -0.297393 -0.701879  0.156574  ...  0.583903  0.132836 -0.232008

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17555165 0.10283086 0.02055261 ... 0.93870264 0.82701266 0.6612037 ]
 [0.17387883 0.10061815 0.01788354 ... 0.89871734 0.7968783  0.6410389 ]
 [0.17703684 0.10424227 0.02156866 ... 0.862634   0.7639213  0.6154605 ]
 ...
 [0.16908552 0.09300241 0.00694054 ... 0.9752065  0.85729635 0.68315995]
 [0.17550705 0.10289335 0.0207659  ... 0.76829374 0.69005144 0.5643321 ]
 [0.17234199 0.09789017 0.01360491 ... 0.7616037  0.6846123  0.5604489 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.852956  0.220900  1.065769  ...  0.079773 -0.219759  0.131969
1  0.921393  0.543554  0.157115  ...  0.385837  0.809758  0.466194
2  0.170848 -0.625883 -0.226945  ...  1.005194 -0.393970 -0.109585
3 -0.747838  0.116330 -0.553214  ... -0.935669  0.031301  0.637906
4 -0.297393 -0.701879  0.156574  ...  0.583903  0.132836 -0.232008

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10765728  0.05099311 -0.0180085  ...  0.91110384  0.83031154
   0.682209  ]
 [ 0.10538036  0.04784603 -0.02221003 ...  0.89740765  0.8203063
   0.67572093]
 [ 0.10806888  0.0509776  -0.0189164  ...  0.86217165  0.7895167
   0.6528889 ]
 ...
 [ 0.10504785  0.04724267 -0.02323189 ...  0.95373607  0.86389804
   0.7053551 ]
 [ 0.1078997   0.05135347 -0.01749933 ...  0.7588489   0.70799005
   0.5966111 ]
 [ 0.1062343   0.04881547 -0.02125928 ...  0.75521064  0.7049873
   0.5944716 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.852956  0.220900  1.065769  ...  0.079773 -0.219759  0.131969
1  0.921393  0.543554  0.157115  ...  0.385837  0.809758  0.466194
2  0.170848 -0.625883 -0.226945  ...  1.005194 -0.393970 -0.109585
3 -0.747838  0.116330 -0.553214  ... -0.935669  0.031301  0.637906
4 -0.297393 -0.701879  0.156574  ...  0.583903  0.132836 -0.232008

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.11779149 0.02529696 0.01824003 ... 0.87941587 0.85855895 0.7847693 ]
 [0.11468248 0.01886922 0.00873148 ... 0.86318046 0.8479445  0.77803284]
 [0.11493516 0.01907679 0.00839233 ... 0.82486963 0.81103486 0.75002694]
 ...
 [0.11321872 0.01563594 0.00351381 ... 0.93446153 0.9060183  0.8193981 ]
 [0.11534256 0.020172   0.01053637 ... 0.7245865  0.7275896  0.6900501 ]
 [0.11419329 0.01769081 0.00663459 ... 0.71898437 0.72270894 0.6865034 ]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.2287e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7fab95d403d0>, <FrEIA.framework.Node object at 0x7fab95d40090>, <FrEIA.framework.Node object at 0x7fab95d24110>, <FrEIA.framework.Node object at 0x7fab95d40550>, <FrEIA.framework.Node object at 0x7fab95f98d10>, <FrEIA.framework.Node object at 0x7fab95fc1110>, <FrEIA.framework.Node object at 0x7fab960ad2d0>, <FrEIA.framework.Node object at 0x7faba4ac8150>, <FrEIA.framework.Node object at 0x7fab96d45a90>, <FrEIA.framework.Node object at 0x7fab96010b50>, <FrEIA.framework.Node object at 0x7fab95c4a610>, <FrEIA.framework.Node object at 0x7fab95c8b210>, <FrEIA.framework.Node object at 0x7fab96095c50>, <FrEIA.framework.Node object at 0x7faaa8612750>, <FrEIA.framework.Node object at 0x7faaa8612850>, <FrEIA.framework.Node object at 0x7fab95de6d50>, <FrEIA.framework.Node object at 0x7fab95de6c90>, <FrEIA.framework.OutputNode object at 0x7fab95de69d0>, <FrEIA.framework.ConditionNode object at 0x7fab95de61d0>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'coupling_6' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_6' takes the following inputs:
	 Output #0 of node 'coupling_6' with dims (14,)

Node 'coupling_7' takes the following inputs:
	 Output #0 of node 'permute_6' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_7' takes the following inputs:
	 Output #0 of node 'coupling_7' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_7' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (14): PermuteRandom()
    (15): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (16): PermuteRandom()
    (17): dummy()
    (18): None
  )
)
Yang/Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005
number of trainable parameters is :
6000864
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: mm4.pt
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: mm6.pt
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: mm2.pt
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.011239  0.364956 -1.213930  ... -0.968874  0.506140 -0.630535
1  0.699865  0.838242  0.231641  ...  0.017695 -0.459875 -0.615173
2  0.460062 -0.494986 -0.487378  ...  1.057707  0.393077  0.514498
3 -0.885114 -0.539158  0.145286  ... -1.114832  0.799600  0.058777
4  0.064380 -0.761272 -0.001173  ...  0.587303 -1.233923 -0.573058

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06503518 0.05904979 0.05178051 ... 0.9283158  0.81975645 0.638879  ]
 [0.06455903 0.05822532 0.05051115 ... 0.8594557  0.7637751  0.59871715]
 [0.05863557 0.04860397 0.03657543 ... 0.86148465 0.76625794 0.60117453]
 ...
 [0.06089256 0.05222972 0.04177393 ... 0.9908017  0.87165004 0.67682564]
 [0.05965804 0.05023839 0.03890014 ... 0.7588028  0.68012094 0.53774583]
 [0.06076061 0.05197643 0.04134873 ... 0.7587843  0.6797432  0.53719664]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.011239  0.364956 -1.213930  ... -0.968874  0.506140 -0.630535
1  0.699865  0.838242  0.231641  ...  0.017695 -0.459875 -0.615173
2  0.460062 -0.494986 -0.487378  ...  1.057707  0.393077  0.514498
3 -0.885114 -0.539158  0.145286  ... -1.114832  0.799600  0.058777
4  0.064380 -0.761272 -0.001173  ...  0.587303 -1.233923 -0.573058

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10673067 -0.0309563   0.04901415 ...  0.9638779   0.77607477
   0.6182903 ]
 [-0.10650438 -0.03054857  0.04972085 ...  0.9084029   0.73576033
   0.58985496]
 [-0.11225186 -0.03982463  0.0349589  ...  0.9018382   0.7333255
   0.5898607 ]
 ...
 [-0.10723974 -0.03167415  0.04800919 ...  1.0261172   0.82960904
   0.66208804]
 [-0.10743833 -0.03203964  0.04737625 ...  0.79734564  0.64495647
   0.51854336]
 [-0.10782869 -0.03269508  0.04629886 ...  0.80580926  0.65119886
   0.52300596]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.011239  0.364956 -1.213930  ... -0.968874  0.506140 -0.630535
1  0.699865  0.838242  0.231641  ...  0.017695 -0.459875 -0.615173
2  0.460062 -0.494986 -0.487378  ...  1.057707  0.393077  0.514498
3 -0.885114 -0.539158  0.145286  ... -1.114832  0.799600  0.058777
4  0.064380 -0.761272 -0.001173  ...  0.587303 -1.233923 -0.573058

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08623029 0.06070164 0.02419093 ... 0.9061609  0.8086932  0.65028816]
 [0.08716983 0.06207533 0.02602199 ... 0.847219   0.7611627  0.6168752 ]
 [0.08195319 0.05435159 0.01564689 ... 0.8456668  0.76014787 0.61656344]
 ...
 [0.08416051 0.05752718 0.01981403 ... 0.9598715  0.85183334 0.6803822 ]
 [0.0824791  0.05517222 0.0167913  ... 0.7358204  0.6699218  0.5521319 ]
 [0.08463892 0.05833868 0.02101577 ... 0.74799055 0.6791969  0.5581235 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.011239  0.364956 -1.213930  ... -0.968874  0.506140 -0.630535
1  0.699865  0.838242  0.231641  ...  0.017695 -0.459875 -0.615173
2  0.460062 -0.494986 -0.487378  ...  1.057707  0.393077  0.514498
3 -0.885114 -0.539158  0.145286  ... -1.114832  0.799600  0.058777
4  0.064380 -0.761272 -0.001173  ...  0.587303 -1.233923 -0.573058

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.0929379  0.06895022 0.03068256 ... 0.8898685  0.8091359  0.67025936]
 [0.09383796 0.07038297 0.03246787 ... 0.82827044 0.7612146  0.6390523 ]
 [0.09139518 0.06670785 0.0283794  ... 0.82775927 0.7600864  0.6378968 ]
 ...
 [0.09130213 0.06644708 0.02781302 ... 0.9446416  0.8517233  0.6979949 ]
 [0.09000024 0.06453446 0.02571109 ... 0.7350551  0.68698454 0.5896839 ]
 [0.09036531 0.06504838 0.02619755 ... 0.73652387 0.6881768  0.5904912 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.011239  0.364956 -1.213930  ... -0.968874  0.506140 -0.630535
1  0.699865  0.838242  0.231641  ...  0.017695 -0.459875 -0.615173
2  0.460062 -0.494986 -0.487378  ...  1.057707  0.393077  0.514498
3 -0.885114 -0.539158  0.145286  ... -1.114832  0.799600  0.058777
4  0.064380 -0.761272 -0.001173  ...  0.587303 -1.233923 -0.573058

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[1.7146169e-01 6.5150619e-02 1.4799237e-03 ... 8.9815402e-01
  8.0453014e-01 6.5425789e-01]
 [1.7743298e-01 7.4427336e-02 1.1428714e-02 ... 8.2821113e-01
  7.5111771e-01 6.1786342e-01]
 [1.7518567e-01 7.1042657e-02 6.9173276e-03 ... 8.2744706e-01
  7.4831426e-01 6.1471707e-01]
 ...
 [1.7697127e-01 7.3723018e-02 1.0709375e-02 ... 9.4074070e-01
  8.3376652e-01 6.7231178e-01]
 [1.7384790e-01 6.8881065e-02 4.9669743e-03 ... 7.1839130e-01
  6.6585338e-01 5.5907100e-01]
 [1.7121728e-01 6.4830750e-02 1.0663271e-04 ... 7.3067957e-01
  6.7565125e-01 5.6597161e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.011239  0.364956 -1.213930  ... -0.968874  0.506140 -0.630535
1  0.699865  0.838242  0.231641  ...  0.017695 -0.459875 -0.615173
2  0.460062 -0.494986 -0.487378  ...  1.057707  0.393077  0.514498
3 -0.885114 -0.539158  0.145286  ... -1.114832  0.799600  0.058777
4  0.064380 -0.761272 -0.001173  ...  0.587303 -1.233923 -0.573058

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09357512 0.03615275 0.02091993 ... 0.9084028  0.80576015 0.6211979 ]
 [0.0956205  0.03928995 0.02482963 ... 0.83289087 0.746878   0.5832238 ]
 [0.09025125 0.03102699 0.01444261 ... 0.843132   0.755067   0.5885595 ]
 ...
 [0.0915384  0.03290842 0.01648757 ... 0.9647603  0.8493469  0.6491803 ]
 [0.09098203 0.03215614 0.01589109 ... 0.73487043 0.6692567  0.53265846]
 [0.0927196  0.03484237 0.0193059  ... 0.74017084 0.6731409  0.5350741 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.011239  0.364956 -1.213930  ... -0.968874  0.506140 -0.630535
1  0.699865  0.838242  0.231641  ...  0.017695 -0.459875 -0.615173
2  0.460062 -0.494986 -0.487378  ...  1.057707  0.393077  0.514498
3 -0.885114 -0.539158  0.145286  ... -1.114832  0.799600  0.058777
4  0.064380 -0.761272 -0.001173  ...  0.587303 -1.233923 -0.573058

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12894884  0.06895775 -0.00609097 ...  0.88885254  0.7923267
   0.71767855]
 [ 0.13673076  0.07844666  0.00449088 ...  0.822194    0.74207854
   0.6827923 ]
 [ 0.1247896   0.06248906 -0.01538721 ...  0.8218496   0.7410605
   0.68162614]
 ...
 [ 0.12719989  0.06604943 -0.0104849  ...  0.9372567   0.82764566
   0.74149346]
 [ 0.12541083  0.06404415 -0.0124684  ...  0.7248814   0.6671946
   0.62987   ]
 [ 0.12397     0.06187606 -0.01550809 ...  0.7351767   0.67504364
   0.6353729 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.011239  0.364956 -1.213930  ... -0.968874  0.506140 -0.630535
1  0.699865  0.838242  0.231641  ...  0.017695 -0.459875 -0.615173
2  0.460062 -0.494986 -0.487378  ...  1.057707  0.393077  0.514498
3 -0.885114 -0.539158  0.145286  ... -1.114832  0.799600  0.058777
4  0.064380 -0.761272 -0.001173  ...  0.587303 -1.233923 -0.573058

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17511831 0.10226125 0.01990545 ... 0.90960383 0.80458033 0.6458863 ]
 [0.18264492 0.1131424  0.03435656 ... 0.83830976 0.7466673  0.6045703 ]
 [0.16988797 0.09397045 0.00796074 ... 0.85373366 0.7590983  0.61338544]
 ...
 [0.17488721 0.10159129 0.01857799 ... 0.9581146  0.8419261  0.6713545 ]
 [0.17151958 0.09655413 0.01165375 ... 0.73439085 0.6630217  0.54533774]
 [0.17168938 0.09679458 0.01196805 ... 0.7422834  0.669314   0.54975957]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.011239  0.364956 -1.213930  ... -0.968874  0.506140 -0.630535
1  0.699865  0.838242  0.231641  ...  0.017695 -0.459875 -0.615173
2  0.460062 -0.494986 -0.487378  ...  1.057707  0.393077  0.514498
3 -0.885114 -0.539158  0.145286  ... -1.114832  0.799600  0.058777
4  0.064380 -0.761272 -0.001173  ...  0.587303 -1.233923 -0.573058

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10662524  0.04925634 -0.02080542 ...  0.8977058   0.81924903
   0.6742971 ]
 [ 0.10796236  0.05119914 -0.01806271 ...  0.8474759   0.78066623
   0.6482594 ]
 [ 0.10580024  0.04819888 -0.02205834 ...  0.84266543  0.7753297
   0.64376336]
 ...
 [ 0.11364275  0.05940813 -0.00655696 ...  0.9288715   0.8428967
   0.6901346 ]
 [ 0.10897443  0.05281362 -0.01559263 ...  0.7252633   0.6811503
   0.5779275 ]
 [ 0.10651381  0.04916726 -0.02083978 ...  0.72916865  0.6845192
   0.5804039 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.011239  0.364956 -1.213930  ... -0.968874  0.506140 -0.630535
1  0.699865  0.838242  0.231641  ...  0.017695 -0.459875 -0.615173
2  0.460062 -0.494986 -0.487378  ...  1.057707  0.393077  0.514498
3 -0.885114 -0.539158  0.145286  ... -1.114832  0.799600  0.058777
4  0.064380 -0.761272 -0.001173  ...  0.587303 -1.233923 -0.573058

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.11520554 0.019878   0.01005363 ... 0.8631954  0.84669226 0.77670467]
 [0.12220116 0.03456876 0.03229743 ... 0.78538775 0.7794975  0.7278367 ]
 [0.11434625 0.01798856 0.0070771  ... 0.7857057  0.779865   0.72811973]
 ...
 [0.11470741 0.01876348 0.00826779 ... 0.93561834 0.9049493  0.8179418 ]
 [0.11768639 0.02510899 0.01804993 ... 0.67851186 0.68843526 0.661757  ]
 [0.11344622 0.01612136 0.00426766 ... 0.7008219  0.70785344 0.6759496 ]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=7.8578e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7fab95c8b290>, <FrEIA.framework.Node object at 0x7faaa8612690>, <FrEIA.framework.Node object at 0x7fab95da57d0>, <FrEIA.framework.Node object at 0x7fab95c9b250>, <FrEIA.framework.Node object at 0x7fab96f5e250>, <FrEIA.framework.Node object at 0x7faaa7a88bd0>, <FrEIA.framework.Node object at 0x7faaa7a88490>, <FrEIA.framework.Node object at 0x7fab96fb2550>, <FrEIA.framework.Node object at 0x7fab95c4ae50>, <FrEIA.framework.Node object at 0x7faaa860fb90>, <FrEIA.framework.Node object at 0x7fab95de6210>, <FrEIA.framework.OutputNode object at 0x7fab96d45710>, <FrEIA.framework.ConditionNode object at 0x7fab95daacd0>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): dummy()
    (12): None
  )
)
Yang/Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005
number of trainable parameters is :
3750540
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: mm4.pt
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: mm6.pt
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.846233  0.563745  0.094824  ...  0.829271 -0.166645  0.667507
1  0.532254  0.781514 -0.281538  ...  0.128602 -0.425215  0.438419
2  0.107279 -0.666471 -0.819987  ...  0.345918 -0.053104  0.670777
3 -0.795764  0.064733 -0.383811  ... -0.369414 -0.672099 -0.205481
4 -0.320457 -0.820109  0.388031  ... -0.532834  0.670477 -0.259658

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06267111 0.05521481 0.0462245  ... 0.8849447  0.7854186  0.6148949 ]
 [0.06216529 0.05431884 0.04482421 ... 0.8374931  0.7463938  0.58666253]
 [0.06466511 0.0581979  0.05020303 ... 0.91129464 0.80293405 0.6247855 ]
 ...
 [0.06483576 0.05879873 0.05151454 ... 0.9258963  0.8172115  0.6366568 ]
 [0.06330626 0.05619451 0.04756839 ... 0.7383125  0.66184324 0.5235155 ]
 [0.06138348 0.05363561 0.04462925 ... 0.7622707  0.6855174  0.5434013 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.846233  0.563745  0.094824  ...  0.829271 -0.166645  0.667507
1  0.532254  0.781514 -0.281538  ...  0.128602 -0.425215  0.438419
2  0.107279 -0.666471 -0.819987  ...  0.345918 -0.053104  0.670777
3 -0.795764  0.064733 -0.383811  ... -0.369414 -0.672099 -0.205481
4 -0.320457 -0.820109  0.388031  ... -0.532834  0.670477 -0.259658

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.11199586 -0.03943092  0.03555977 ...  0.94325984  0.767359
   0.6167022 ]
 [-0.10948867 -0.03541625  0.04190999 ...  0.89286375  0.7246798
   0.5822197 ]
 [-0.10788259 -0.0328542   0.04595032 ...  0.9424149   0.7540437
   0.5980892 ]
 ...
 [-0.10605077 -0.02973205  0.05112362 ...  0.9314693   0.7513963
   0.60009587]
 [-0.10774179 -0.03256673  0.04649213 ...  0.78708446  0.6353315
   0.51018465]
 [-0.1077324  -0.03236213  0.04704762 ...  0.81915677  0.66957235
   0.54227626]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.846233  0.563745  0.094824  ...  0.829271 -0.166645  0.667507
1  0.532254  0.781514 -0.281538  ...  0.128602 -0.425215  0.438419
2  0.107279 -0.666471 -0.819987  ...  0.345918 -0.053104  0.670777
3 -0.795764  0.064733 -0.383811  ... -0.369414 -0.672099 -0.205481
4 -0.320457 -0.820109  0.388031  ... -0.532834  0.670477 -0.259658

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08417868 0.05770297 0.02019916 ... 0.8775606  0.78661895 0.6356395 ]
 [0.08631283 0.06081964 0.02434879 ... 0.8227628  0.74167067 0.6035144 ]
 [0.08658126 0.06094715 0.02424567 ... 0.88558656 0.7891884  0.6342023 ]
 ...
 [0.08477657 0.05841665 0.02098726 ... 0.9033281  0.8052848  0.64697826]
 [0.08655421 0.0612171  0.02492721 ... 0.7152416  0.6518264  0.53815246]
 [0.08317903 0.05675804 0.01949182 ... 0.7572096  0.6895521  0.56788504]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.846233  0.563745  0.094824  ...  0.829271 -0.166645  0.667507
1  0.532254  0.781514 -0.281538  ...  0.128602 -0.425215  0.438419
2  0.107279 -0.666471 -0.819987  ...  0.345918 -0.053104  0.670777
3 -0.795764  0.064733 -0.383811  ... -0.369414 -0.672099 -0.205481
4 -0.320457 -0.820109  0.388031  ... -0.532834  0.670477 -0.259658

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.0923108  0.06811634 0.03001291 ... 0.8580183  0.7846079  0.6544268 ]
 [0.08703738 0.05952816 0.01889612 ... 0.8258214  0.7597344  0.63832366]
 [0.09459628 0.07141159 0.03337362 ... 0.8743079  0.7950294  0.65993667]
 ...
 [0.08550906 0.0571193  0.01599284 ... 0.8786992  0.799948   0.6639813 ]
 [0.09165788 0.06699495 0.02838561 ... 0.715958   0.6714691  0.5792017 ]
 [0.08624412 0.05896947 0.0197103  ... 0.76311326 0.7105194  0.6059746 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.846233  0.563745  0.094824  ...  0.829271 -0.166645  0.667507
1  0.532254  0.781514 -0.281538  ...  0.128602 -0.425215  0.438419
2  0.107279 -0.666471 -0.819987  ...  0.345918 -0.053104  0.670777
3 -0.795764  0.064733 -0.383811  ... -0.369414 -0.672099 -0.205481
4 -0.320457 -0.820109  0.388031  ... -0.532834  0.670477 -0.259658

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.7144853e-01  6.5235645e-02  2.8604269e-04 ...  8.5727727e-01
   7.7314031e-01  6.3277066e-01]
 [ 1.6954088e-01  6.2273741e-02 -3.3093393e-03 ...  8.3919764e-01
   7.6067799e-01  6.2503827e-01]
 [ 1.8360430e-01  8.4149569e-02  2.0943195e-02 ...  8.6391836e-01
   7.7059841e-01  6.2679309e-01]
 ...
 [ 1.7354582e-01  6.8529665e-02  4.1164756e-03 ...  8.6567676e-01
   7.7698576e-01  6.3395274e-01]
 [ 1.7420149e-01  6.9550246e-02  4.6982169e-03 ...  7.0892835e-01
   6.5761518e-01  5.5289298e-01]
 [ 1.5926911e-01  4.6206862e-02 -1.8775731e-02 ...  7.6672757e-01
   7.0843148e-01  5.9120852e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.846233  0.563745  0.094824  ...  0.829271 -0.166645  0.667507
1  0.532254  0.781514 -0.281538  ...  0.128602 -0.425215  0.438419
2  0.107279 -0.666471 -0.819987  ...  0.345918 -0.053104  0.670777
3 -0.795764  0.064733 -0.383811  ... -0.369414 -0.672099 -0.205481
4 -0.320457 -0.820109  0.388031  ... -0.532834  0.670477 -0.259658

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.092778   0.03491251 0.0193181  ... 0.872319   0.7782345  0.60367715]
 [0.0925567  0.03454292 0.0187681  ... 0.8179352  0.7357719  0.5762541 ]
 [0.09316623 0.03530568 0.0191652  ... 0.89269555 0.7907585  0.6104686 ]
 ...
 [0.0869043  0.02562229 0.00684482 ... 0.91822004 0.8134711  0.626185  ]
 [0.09509844 0.0385703  0.02420188 ... 0.72011423 0.65670097 0.52416354]
 [0.08509454 0.02342965 0.00596753 ... 0.77813244 0.7068684  0.5583782 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.846233  0.563745  0.094824  ...  0.829271 -0.166645  0.667507
1  0.532254  0.781514 -0.281538  ...  0.128602 -0.425215  0.438419
2  0.107279 -0.666471 -0.819987  ...  0.345918 -0.053104  0.670777
3 -0.795764  0.064733 -0.383811  ... -0.369414 -0.672099 -0.205481
4 -0.320457 -0.820109  0.388031  ... -0.532834  0.670477 -0.259658

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.2144628e-01  5.8552533e-02 -1.9573659e-02 ...  8.6208534e-01
   7.7273238e-01  7.0442855e-01]
 [ 1.2504482e-01  6.2818229e-02 -1.5008122e-02 ...  8.0913746e-01
   7.3284268e-01  6.7674887e-01]
 [ 1.3670081e-01  7.6953024e-02  6.5049529e-04 ...  8.6852610e-01
   7.7324313e-01  7.0214832e-01]
 ...
 [ 1.2620297e-01  6.4571589e-02 -1.2523919e-02 ...  9.0107733e-01
   8.0005574e-01  7.2214484e-01]
 [ 1.3172558e-01  7.1352422e-02 -4.9091280e-03 ...  7.1096027e-01
   6.5548515e-01  6.2100220e-01]
 [ 1.1618769e-01  5.3947270e-02 -2.1999717e-02 ...  7.3872429e-01
   6.8012232e-01  6.4035749e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.846233  0.563745  0.094824  ...  0.829271 -0.166645  0.667507
1  0.532254  0.781514 -0.281538  ...  0.128602 -0.425215  0.438419
2  0.107279 -0.666471 -0.819987  ...  0.345918 -0.053104  0.670777
3 -0.795764  0.064733 -0.383811  ... -0.369414 -0.672099 -0.205481
4 -0.320457 -0.820109  0.388031  ... -0.532834  0.670477 -0.259658

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.17270242  0.09842652  0.01436403 ...  0.8709801   0.7742363
   0.6248224 ]
 [ 0.17576319  0.10304132  0.02073339 ...  0.82662404  0.738764
   0.59984076]
 [ 0.17798771  0.10526466  0.0225141  ...  0.88982385  0.78313255
   0.6275311 ]
 ...
 [ 0.1791394   0.10797724  0.02735674 ...  0.8847114   0.7826028
   0.6292067 ]
 [ 0.17453353  0.10069638  0.01692224 ...  0.720865    0.6507933
   0.53591084]
 [ 0.16198358  0.08381715 -0.00408444 ...  0.7900188   0.71308005
   0.5838082 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.846233  0.563745  0.094824  ...  0.829271 -0.166645  0.667507
1  0.532254  0.781514 -0.281538  ...  0.128602 -0.425215  0.438419
2  0.107279 -0.666471 -0.819987  ...  0.345918 -0.053104  0.670777
3 -0.795764  0.064733 -0.383811  ... -0.369414 -0.672099 -0.205481
4 -0.320457 -0.820109  0.388031  ... -0.532834  0.670477 -0.259658

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10988969  0.0539719  -0.01419693 ...  0.85745037  0.7882123
   0.6532943 ]
 [ 0.1107116   0.055051   -0.01286405 ...  0.8235949   0.7615044
   0.63489103]
 [ 0.10981187  0.05338366 -0.0156959  ...  0.8813896   0.8027339
   0.6609541 ]
 ...
 [ 0.106904    0.04999043 -0.01925766 ...  0.90808403  0.8266754
   0.67902625]
 [ 0.11028069  0.0543638  -0.01391006 ...  0.71619356  0.6731428
   0.5719266 ]
 [ 0.10816801  0.05289173 -0.01364386 ...  0.75426054  0.70747983
   0.5979618 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.846233  0.563745  0.094824  ...  0.829271 -0.166645  0.667507
1  0.532254  0.781514 -0.281538  ...  0.128602 -0.425215  0.438419
2  0.107279 -0.666471 -0.819987  ...  0.345918 -0.053104  0.670777
3 -0.795764  0.064733 -0.383811  ... -0.369414 -0.672099 -0.205481
4 -0.320457 -0.820109  0.388031  ... -0.532834  0.670477 -0.259658

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.11542486 0.0203014  0.0106383  ... 0.82389665 0.8135635  0.75288904]
 [0.11598852 0.02142179 0.01217738 ... 0.79199433 0.7870196  0.7337885 ]
 [0.1144246  0.01795542 0.00660661 ... 0.85597223 0.8341936  0.76578134]
 ...
 [0.11726312 0.02416492 0.01652938 ... 0.8494964  0.8318558  0.7650678 ]
 [0.11580972 0.02101302 0.01152849 ... 0.67763364 0.6867843  0.66028047]
 [0.11488651 0.01955295 0.01036415 ... 0.7203324  0.7286254  0.6923188 ]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.3044e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaa2903590>, <FrEIA.framework.Node object at 0x7faaa2903f10>, <FrEIA.framework.Node object at 0x7faaa2903e50>, <FrEIA.framework.Node object at 0x7faaa2903a10>, <FrEIA.framework.Node object at 0x7faaa2903ad0>, <FrEIA.framework.Node object at 0x7faaa2903990>, <FrEIA.framework.Node object at 0x7faaa2903390>, <FrEIA.framework.Node object at 0x7faaa29034d0>, <FrEIA.framework.Node object at 0x7faaa2c63850>, <FrEIA.framework.Node object at 0x7faaa291aad0>, <FrEIA.framework.Node object at 0x7faaa291af10>, <FrEIA.framework.OutputNode object at 0x7faaa291a590>, <FrEIA.framework.ConditionNode object at 0x7faaa766ec10>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): dummy()
    (12): None
  )
)
Yang/Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005
number of trainable parameters is :
3750540
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: mm6.pt
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.876637  0.109568  0.503874  ... -0.211205  0.636014 -1.051391
1  0.545489  0.914566  0.763852  ...  0.393909  0.329383 -0.869516
2  0.239803 -0.671238 -1.242709  ... -0.015022 -0.118997  0.261216
3 -0.637917 -0.121457  0.191792  ... -0.010521 -0.018279  0.296313
4 -0.310086 -0.651550  0.108984  ...  0.261765  0.670065 -0.231981

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06092963 0.05247483 0.04237596 ... 0.9612966  0.84890795 0.66139585]
 [0.06337216 0.0560901  0.04713795 ... 0.8568935  0.7613914  0.59682167]
 [0.06122034 0.05268764 0.04233518 ... 0.9203416  0.81292444 0.63375664]
 ...
 [0.05816254 0.04757345 0.03472333 ... 0.9667756  0.8528983  0.66393185]
 [0.06248617 0.05490951 0.04577567 ... 0.78922534 0.70445037 0.5548679 ]
 [0.06181951 0.0537634  0.04402545 ... 0.75781345 0.6785741  0.53608686]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.876637  0.109568  0.503874  ... -0.211205  0.636014 -1.051391
1  0.545489  0.914566  0.763852  ...  0.393909  0.329383 -0.869516
2  0.239803 -0.671238 -1.242709  ... -0.015022 -0.118997  0.261216
3 -0.637917 -0.121457  0.191792  ... -0.010521 -0.018279  0.296313
4 -0.310086 -0.651550  0.108984  ...  0.261765  0.670065 -0.231981

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10879859 -0.03417966  0.04403409 ...  1.0078806   0.8187218
   0.65612924]
 [-0.11017202 -0.03656209  0.04003069 ...  0.905391    0.73398364
   0.58890367]
 [-0.11202735 -0.03950745  0.03540933 ...  0.96060026  0.7771038
   0.62150264]
 ...
 [-0.10760665 -0.0323396   0.04686356 ...  0.98397195  0.79631734
   0.63666785]
 [-0.10867324 -0.03404781  0.0441542  ...  0.84124875  0.67943585
   0.54472256]
 [-0.10832021 -0.03347388  0.04507962 ...  0.8073659   0.6529616
   0.52470887]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.876637  0.109568  0.503874  ... -0.211205  0.636014 -1.051391
1  0.545489  0.914566  0.763852  ...  0.393909  0.329383 -0.869516
2  0.239803 -0.671238 -1.242709  ... -0.015022 -0.118997  0.261216
3 -0.637917 -0.121457  0.191792  ... -0.010521 -0.018279  0.296313
4 -0.310086 -0.651550  0.108984  ...  0.261765  0.670065 -0.231981

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08264887 0.05541786 0.01710439 ... 0.9505383  0.8460417  0.6777824 ]
 [0.08595333 0.06009007 0.02316632 ... 0.83697337 0.7527835  0.6109589 ]
 [0.08388061 0.05700998 0.01901565 ... 0.8934662  0.7974054  0.64152646]
 ...
 [0.08357829 0.05667513 0.01868016 ... 0.9440327  0.8398745  0.67272455]
 [0.08394672 0.05734742 0.0197174  ... 0.77805185 0.70358515 0.57536286]
 [0.0839228  0.05724062 0.01949821 ... 0.74864936 0.6795779  0.5582557 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.876637  0.109568  0.503874  ... -0.211205  0.636014 -1.051391
1  0.545489  0.914566  0.763852  ...  0.393909  0.329383 -0.869516
2  0.239803 -0.671238 -1.242709  ... -0.015022 -0.118997  0.261216
3 -0.637917 -0.121457  0.191792  ... -0.010521 -0.018279  0.296313
4 -0.310086 -0.651550  0.108984  ...  0.261765  0.670065 -0.231981

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08872947 0.06245275 0.02304505 ... 0.9226824  0.8355237  0.68794334]
 [0.09215638 0.06761886 0.02882546 ... 0.83135366 0.76359904 0.6405951 ]
 [0.08997619 0.06408456 0.02431804 ... 0.86625373 0.78966343 0.65694976]
 ...
 [0.09265175 0.06855063 0.03030512 ... 0.90627337 0.8221034  0.67882997]
 [0.08963999 0.06387508 0.02470189 ... 0.76395285 0.709543   0.6044271 ]
 [0.09082763 0.06576212 0.02705619 ... 0.74029636 0.6908591  0.5920985 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.876637  0.109568  0.503874  ... -0.211205  0.636014 -1.051391
1  0.545489  0.914566  0.763852  ...  0.393909  0.329383 -0.869516
2  0.239803 -0.671238 -1.242709  ... -0.015022 -0.118997  0.261216
3 -0.637917 -0.121457  0.191792  ... -0.010521 -0.018279  0.296313
4 -0.310086 -0.651550  0.108984  ...  0.261765  0.670065 -0.231981

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.7111023e-01  6.4646721e-02  5.3948164e-04 ...  9.3277746e-01
   8.3004868e-01  6.7110157e-01]
 [ 1.6916505e-01  6.1675966e-02 -3.8229227e-03 ...  8.4065425e-01
   7.6193917e-01  6.2598532e-01]
 [ 1.7411992e-01  6.9529116e-02  4.0083230e-03 ...  8.6872834e-01
   7.7736163e-01  6.3310552e-01]
 ...
 [ 1.7419244e-01  6.9297493e-02  6.9513321e-03 ...  9.2615920e-01
   8.2567316e-01  6.6849399e-01]
 [ 1.6901171e-01  6.1436862e-02 -3.5803318e-03 ...  7.6756030e-01
   7.0356774e-01  5.8484232e-01]
 [ 1.7258611e-01  6.7044526e-02  1.8773377e-03 ...  7.2880691e-01
   6.7304933e-01  5.6353652e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.876637  0.109568  0.503874  ... -0.211205  0.636014 -1.051391
1  0.545489  0.914566  0.763852  ...  0.393909  0.329383 -0.869516
2  0.239803 -0.671238 -1.242709  ... -0.015022 -0.118997  0.261216
3 -0.637917 -0.121457  0.191792  ... -0.010521 -0.018279  0.296313
4 -0.310086 -0.651550  0.108984  ...  0.261765  0.670065 -0.231981

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09114374 0.03249106 0.01656815 ... 0.94141865 0.83264375 0.63897014]
 [0.09302732 0.0351295  0.01906984 ... 0.8375584  0.7505362  0.5855843 ]
 [0.09179117 0.03331304 0.01705542 ... 0.8917357  0.7921915  0.61222327]
 ...
 [0.08914489 0.02912693 0.01143788 ... 0.93628085 0.828339   0.6360818 ]
 [0.09154722 0.03304394 0.01705743 ... 0.7697158  0.69622564 0.54997987]
 [0.09191759 0.03360601 0.01774274 ... 0.7405188  0.6733655  0.53520024]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.876637  0.109568  0.503874  ... -0.211205  0.636014 -1.051391
1  0.545489  0.914566  0.763852  ...  0.393909  0.329383 -0.869516
2  0.239803 -0.671238 -1.242709  ... -0.015022 -0.118997  0.261216
3 -0.637917 -0.121457  0.191792  ... -0.010521 -0.018279  0.296313
4 -0.310086 -0.651550  0.108984  ...  0.261765  0.670065 -0.231981

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12204885  0.0599086  -0.01712739 ...  0.9249314   0.8199868
   0.7371658 ]
 [ 0.12771127  0.06639248 -0.01054332 ...  0.8306909   0.7489367
   0.6878283 ]
 [ 0.12976554  0.06869203 -0.00826761 ...  0.8715166   0.7775048
   0.70632535]
 ...
 [ 0.12608376  0.06473768 -0.01188838 ...  0.9169005   0.8134608
   0.73234797]
 [ 0.12668481  0.06578109 -0.01025954 ...  0.7522719   0.68778056
   0.64412564]
 [ 0.12675387  0.06522429 -0.01183587 ...  0.7246353   0.66656524
   0.62916404]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.876637  0.109568  0.503874  ... -0.211205  0.636014 -1.051391
1  0.545489  0.914566  0.763852  ...  0.393909  0.329383 -0.869516
2  0.239803 -0.671238 -1.242709  ... -0.015022 -0.118997  0.261216
3 -0.637917 -0.121457  0.191792  ... -0.010521 -0.018279  0.296313
4 -0.310086 -0.651550  0.108984  ...  0.261765  0.670065 -0.231981

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17143139 0.09681192 0.0124706  ... 0.9468485  0.8348968  0.6675483 ]
 [0.17086564 0.09574759 0.01079831 ... 0.849438   0.75769055 0.6135632 ]
 [0.1764421  0.10345018 0.02058953 ... 0.8825474  0.7801244  0.62703365]
 ...
 [0.173152   0.09925905 0.01569885 ... 0.9310488  0.8218297  0.6580939 ]
 [0.17363764 0.10006186 0.01685053 ... 0.76867306 0.6906572  0.564932  ]
 [0.17286238 0.09830764 0.01376703 ... 0.7393794  0.6661961  0.547103  ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.876637  0.109568  0.503874  ... -0.211205  0.636014 -1.051391
1  0.545489  0.914566  0.763852  ...  0.393909  0.329383 -0.869516
2  0.239803 -0.671238 -1.242709  ... -0.015022 -0.118997  0.261216
3 -0.637917 -0.121457  0.191792  ... -0.010521 -0.018279  0.296313
4 -0.310086 -0.651550  0.108984  ...  0.261765  0.670065 -0.231981

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10413817  0.04619214 -0.02430496 ...  0.9282317   0.8448752
   0.6928375 ]
 [ 0.10976924  0.05345953 -0.01544741 ...  0.83253264  0.768221
   0.6393251 ]
 [ 0.10923442  0.05302119 -0.01552063 ...  0.88507736  0.80807495
   0.6659558 ]
 ...
 [ 0.10902843  0.05280139 -0.01575702 ...  0.92659044  0.8422674
   0.69031286]
 [ 0.10856993  0.05218363 -0.01654309 ...  0.7612697   0.7093823
   0.5973065 ]
 [ 0.10668905  0.04939848 -0.0205265  ...  0.73690176  0.6901034
   0.5839883 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.876637  0.109568  0.503874  ... -0.211205  0.636014 -1.051391
1  0.545489  0.914566  0.763852  ...  0.393909  0.329383 -0.869516
2  0.239803 -0.671238 -1.242709  ... -0.015022 -0.118997  0.261216
3 -0.637917 -0.121457  0.191792  ... -0.010521 -0.018279  0.296313
4 -0.310086 -0.651550  0.108984  ...  0.261765  0.670065 -0.231981

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.11379096 0.01691154 0.00559658 ... 0.90792805 0.88416755 0.8037233 ]
 [0.11590503 0.02128661 0.01205227 ... 0.7955722  0.7904295  0.73638296]
 [0.11748783 0.02450159 0.01675227 ... 0.8359118  0.8187077  0.75507975]
 ...
 [0.11403529 0.01734981 0.00609601 ... 0.8907741  0.8693982  0.7929927 ]
 [0.11654387 0.02268729 0.01432613 ... 0.72570115 0.7278527  0.69005907]
 [0.11419986 0.01768667 0.00661504 ... 0.7013091  0.7075397  0.67553294]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.6364e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7fab95eabcd0>, <FrEIA.framework.Node object at 0x7faaa43c3490>, <FrEIA.framework.Node object at 0x7faaa43c3710>, <FrEIA.framework.Node object at 0x7faaa43c35d0>, <FrEIA.framework.Node object at 0x7faaa43c3e10>, <FrEIA.framework.Node object at 0x7fab95c9bf90>, <FrEIA.framework.Node object at 0x7fab95fe1f50>, <FrEIA.framework.Node object at 0x7faaad644ed0>, <FrEIA.framework.Node object at 0x7fab95fee310>, <FrEIA.framework.OutputNode object at 0x7fab95feef10>, <FrEIA.framework.ConditionNode object at 0x7fab95eaba10>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): dummy()
    (10): None
  )
)
Yang/Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005
number of trainable parameters is :
3000432
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: mm6.pt
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.851364  0.448329  1.013079  ...  0.070430 -0.403465  0.319558
1  0.790778  0.792077  0.051371  ...  0.070630 -1.549349 -0.442442
2  0.199900 -0.743529  0.271184  ... -0.361410  0.799682  0.166997
3 -0.599318 -0.386503  0.927014  ...  0.258635  0.855174  0.526005
4 -0.744897 -0.882080 -0.452721  ... -0.801284 -0.020822  0.562656

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06328407 0.05615163 0.04750111 ... 0.92839193 0.820448   0.63983685]
 [0.06514029 0.05921907 0.05201325 ... 0.86191124 0.76539147 0.59969485]
 [0.06436272 0.0578935  0.0500157  ... 0.8769351  0.77621084 0.6064878 ]
 ...
 [0.06062974 0.0517849  0.04110283 ... 0.9870666  0.868615   0.67465955]
 [0.06072961 0.05189752 0.04119324 ... 0.7548108  0.6764938  0.53484267]
 [0.06010757 0.05105594 0.04020233 ... 0.76777047 0.6879119  0.54367846]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.851364  0.448329  1.013079  ...  0.070430 -0.403465  0.319558
1  0.790778  0.792077  0.051371  ...  0.070630 -1.549349 -0.442442
2  0.199900 -0.743529  0.271184  ... -0.361410  0.799682  0.166997
3 -0.599318 -0.386503  0.927014  ...  0.258635  0.855174  0.526005
4 -0.744897 -0.882080 -0.452721  ... -0.801284 -0.020822  0.562656

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10745047 -0.03212973  0.04713529 ...  0.9597627   0.7734964
   0.616783  ]
 [-0.10637392 -0.03039563  0.04989266 ...  0.90061414  0.727139
   0.58164644]
 [-0.10742287 -0.03204483  0.04732543 ...  0.9084934   0.73131394
   0.5834727 ]
 ...
 [-0.10906021 -0.0346615   0.04319513 ...  1.0291543   0.8323095
   0.6643475 ]
 [-0.10812056 -0.03317457  0.04552481 ...  0.7991619   0.6460664
   0.51916695]
 [-0.10633311 -0.03020379  0.05035603 ...  0.80777097  0.65393937
   0.5259049 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.851364  0.448329  1.013079  ...  0.070430 -0.403465  0.319558
1  0.790778  0.792077  0.051371  ...  0.070630 -1.549349 -0.442442
2  0.199900 -0.743529  0.271184  ... -0.361410  0.799682  0.166997
3 -0.599318 -0.386503  0.927014  ...  0.258635  0.855174  0.526005
4 -0.744897 -0.882080 -0.452721  ... -0.801284 -0.020822  0.562656

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08609539 0.06053761 0.02400913 ... 0.90305924 0.8061099  0.6484748 ]
 [0.08918564 0.06526938 0.03053663 ... 0.83530354 0.75083596 0.60919595]
 [0.08723412 0.06213261 0.02606778 ... 0.83697206 0.7507357  0.6079233 ]
 ...
 [0.08456684 0.05810639 0.02056877 ... 0.9651912  0.85592353 0.68308246]
 [0.08354039 0.0566163  0.01860226 ... 0.7465458  0.67816097 0.5574952 ]
 [0.08183269 0.05431563 0.0157467  ... 0.7554979  0.68653464 0.56443065]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.851364  0.448329  1.013079  ...  0.070430 -0.403465  0.319558
1  0.790778  0.792077  0.051371  ...  0.070630 -1.549349 -0.442442
2  0.199900 -0.743529  0.271184  ... -0.361410  0.799682  0.166997
3 -0.599318 -0.386503  0.927014  ...  0.258635  0.855174  0.526005
4 -0.744897 -0.882080 -0.452721  ... -0.801284 -0.020822  0.562656

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09161308 0.06684421 0.02804296 ... 0.8905369  0.80974436 0.6707005 ]
 [0.08855686 0.06208196 0.02236256 ... 0.8392012  0.7701223  0.64506495]
 [0.09383015 0.07037897 0.03248738 ... 0.8353461  0.7653334  0.64093983]
 ...
 [0.09188305 0.0673282  0.02881017 ... 0.9447057  0.8516151  0.69783354]
 [0.09061791 0.06536004 0.02639611 ... 0.7388365  0.6899172  0.59159684]
 [0.0886063  0.06238568 0.02319087 ... 0.7516699  0.7003759  0.59866416]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.851364  0.448329  1.013079  ...  0.070430 -0.403465  0.319558
1  0.790778  0.792077  0.051371  ...  0.070630 -1.549349 -0.442442
2  0.199900 -0.743529  0.271184  ... -0.361410  0.799682  0.166997
3 -0.599318 -0.386503  0.927014  ...  0.258635  0.855174  0.526005
4 -0.744897 -0.882080 -0.452721  ... -0.801284 -0.020822  0.562656

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.7618522e-01  7.2336704e-02  1.0289967e-02 ...  8.8204253e-01
   7.9180771e-01  6.4537579e-01]
 [ 1.6930234e-01  6.1717123e-02 -1.5135407e-03 ...  8.6585969e-01
   7.8170562e-01  6.3974863e-01]
 [ 1.7865799e-01  7.6391578e-02  1.3075620e-02 ...  8.2910633e-01
   7.4819744e-01  6.1386627e-01]
 ...
 [ 1.7531721e-01  7.1189731e-02  7.5199306e-03 ...  9.4086963e-01
   8.3371711e-01  6.7220056e-01]
 [ 1.7153004e-01  6.5288812e-02  8.7571144e-04 ...  7.3562354e-01
   6.7954141e-01  5.6868458e-01]
 [ 1.6285327e-01  5.1892400e-02 -1.4399886e-02 ...  7.5553763e-01
   6.9664884e-01  5.8139193e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.851364  0.448329  1.013079  ...  0.070430 -0.403465  0.319558
1  0.790778  0.792077  0.051371  ...  0.070630 -1.549349 -0.442442
2  0.199900 -0.743529  0.271184  ... -0.361410  0.799682  0.166997
3 -0.599318 -0.386503  0.927014  ...  0.258635  0.855174  0.526005
4 -0.744897 -0.882080 -0.452721  ... -0.801284 -0.020822  0.562656

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09440869 0.0374867  0.02276628 ... 0.89900446 0.79839563 0.61642885]
 [0.09722432 0.04193884 0.02873322 ... 0.8408029  0.75260067 0.58672833]
 [0.09492871 0.03822096 0.02347368 ... 0.8378451  0.74897    0.583881  ]
 ...
 [0.09275435 0.03478344 0.01885746 ... 0.96288764 0.84764886 0.6479975 ]
 [0.09232207 0.03415544 0.01820539 ... 0.7401599  0.67298794 0.53492326]
 [0.088916   0.02906321 0.01227291 ... 0.7527604  0.6845524  0.5430298 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.851364  0.448329  1.013079  ...  0.070430 -0.403465  0.319558
1  0.790778  0.792077  0.051371  ...  0.070630 -1.549349 -0.442442
2  0.199900 -0.743529  0.271184  ... -0.361410  0.799682  0.166997
3 -0.599318 -0.386503  0.927014  ...  0.258635  0.855174  0.526005
4 -0.744897 -0.882080 -0.452721  ... -0.801284 -0.020822  0.562656

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.21812791e-01  5.92901409e-02 -1.83298588e-02 ...  8.94093513e-01
   7.96408653e-01  7.20591486e-01]
 [ 1.17962152e-01  5.43478727e-02 -2.42079794e-02 ...  8.46386790e-01
   7.60844171e-01  6.96140230e-01]
 [ 1.35320276e-01  7.57398903e-02 -7.45058060e-07 ...  8.28782618e-01
   7.44685650e-01  6.83171093e-01]
 ...
 [ 1.26632392e-01  6.49842620e-02 -1.22349858e-02 ...  9.39675450e-01
   8.29465151e-01  7.42754340e-01]
 [ 1.33563548e-01  7.39590228e-02 -1.45897269e-03 ...  7.23985791e-01
   6.65773749e-01  6.28431082e-01]
 [ 1.21041805e-01  5.87085485e-02 -1.84340179e-02 ...  7.39349663e-01
   6.78730726e-01  6.38260901e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.851364  0.448329  1.013079  ...  0.070430 -0.403465  0.319558
1  0.790778  0.792077  0.051371  ...  0.070630 -1.549349 -0.442442
2  0.199900 -0.743529  0.271184  ... -0.361410  0.799682  0.166997
3 -0.599318 -0.386503  0.927014  ...  0.258635  0.855174  0.526005
4 -0.744897 -0.882080 -0.452721  ... -0.801284 -0.020822  0.562656

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17720178 0.10558358 0.02466786 ... 0.9081651  0.8033242  0.64494485]
 [0.17494333 0.10254657 0.02088699 ... 0.8566201  0.7639328  0.61824787]
 [0.17996994 0.10879433 0.02798703 ... 0.8346472  0.7412754  0.5993539 ]
 ...
 [0.17319033 0.098975   0.01490796 ... 0.97365975 0.8541715  0.67987424]
 [0.16968279 0.09373093 0.00770378 ... 0.7401614  0.66809905 0.5491801 ]
 [0.17325763 0.09965852 0.01646444 ... 0.7528182  0.67856556 0.5567548 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.851364  0.448329  1.013079  ...  0.070430 -0.403465  0.319558
1  0.790778  0.792077  0.051371  ...  0.070630 -1.549349 -0.442442
2  0.199900 -0.743529  0.271184  ... -0.361410  0.799682  0.166997
3 -0.599318 -0.386503  0.927014  ...  0.258635  0.855174  0.526005
4 -0.744897 -0.882080 -0.452721  ... -0.801284 -0.020822  0.562656

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10380587  0.04544903 -0.02575693 ...  0.9010521   0.8225422
   0.67691624]
 [ 0.1151693   0.06167074 -0.0033448  ...  0.8567276   0.78653955
   0.65152425]
 [ 0.10979509  0.05366191 -0.01488051 ...  0.8466747   0.7773415
   0.644513  ]
 ...
 [ 0.11240239  0.05761801 -0.00906536 ...  0.94075346  0.8519784
   0.69623566]
 [ 0.11128101  0.05576551 -0.01202974 ...  0.73814714  0.69066167
   0.584134  ]
 [ 0.10768095  0.05110779 -0.0177435  ...  0.74155855  0.69473183
   0.58767873]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.851364  0.448329  1.013079  ...  0.070430 -0.403465  0.319558
1  0.790778  0.792077  0.051371  ...  0.070630 -1.549349 -0.442442
2  0.199900 -0.743529  0.271184  ... -0.361410  0.799682  0.166997
3 -0.599318 -0.386503  0.927014  ...  0.258635  0.855174  0.526005
4 -0.744897 -0.882080 -0.452721  ... -0.801284 -0.020822  0.562656

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.11495873  0.01941755  0.00947726 ...  0.8604599   0.84492
   0.77555877]
 [ 0.11165202  0.01240477 -0.00126508 ...  0.8291617   0.8198328
   0.75790834]
 [ 0.1189823   0.02764884  0.02151185 ...  0.7957864   0.78507215
   0.7308272 ]
 ...
 [ 0.11629155  0.02210164  0.01333982 ...  0.9257829   0.8963978
   0.8116945 ]
 [ 0.11771843  0.02510959  0.01789865 ...  0.68981266  0.69750684
   0.66815925]
 [ 0.11529763  0.02014557  0.01064986 ...  0.70558023  0.71291435
   0.6799067 ]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.4498e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaabd84c50>, <FrEIA.framework.Node object at 0x7faaabd84d90>, <FrEIA.framework.Node object at 0x7faaabd84c90>, <FrEIA.framework.Node object at 0x7faaabd84310>, <FrEIA.framework.Node object at 0x7faaabdbcdd0>, <FrEIA.framework.Node object at 0x7faaabdbc690>, <FrEIA.framework.Node object at 0x7faaabdbcc90>, <FrEIA.framework.Node object at 0x7faaabdbc450>, <FrEIA.framework.Node object at 0x7fab95de6790>, <FrEIA.framework.Node object at 0x7faaa7a97050>, <FrEIA.framework.Node object at 0x7faaabd8f190>, <FrEIA.framework.Node object at 0x7fab95ea47d0>, <FrEIA.framework.Node object at 0x7faaa7a9d150>, <FrEIA.framework.Node object at 0x7faaa7a9d990>, <FrEIA.framework.Node object at 0x7faaa7a9d650>, <FrEIA.framework.Node object at 0x7faaa7669bd0>, <FrEIA.framework.Node object at 0x7faaa43f1bd0>, <FrEIA.framework.Node object at 0x7fab95eb2b90>, <FrEIA.framework.Node object at 0x7faaa2c69850>, <FrEIA.framework.OutputNode object at 0x7faaa7e80a10>, <FrEIA.framework.ConditionNode object at 0x7faaa8612e50>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'coupling_6' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_6' takes the following inputs:
	 Output #0 of node 'coupling_6' with dims (14,)

Node 'coupling_7' takes the following inputs:
	 Output #0 of node 'permute_6' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_7' takes the following inputs:
	 Output #0 of node 'coupling_7' with dims (14,)

Node 'coupling_8' takes the following inputs:
	 Output #0 of node 'permute_7' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_8' takes the following inputs:
	 Output #0 of node 'coupling_8' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_8' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (14): PermuteRandom()
    (15): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (16): PermuteRandom()
    (17): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (18): PermuteRandom()
    (19): dummy()
    (20): None
  )
)
Yang/Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005
number of trainable parameters is :
6750972
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: mm6.pt
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.904624  0.326342  0.098057  ...  0.937380  0.342420 -0.306099
1  0.647794  0.763651 -0.187596  ... -0.832098 -0.599374 -0.879632
2 -0.259641 -0.341707  0.255022  ... -0.992007 -0.309344  0.600517
3 -0.806756  0.308137 -0.363009  ... -0.022736 -0.062399 -0.481236
4 -0.183799 -0.893794  0.087533  ...  0.518753 -0.387864  1.171986

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06188971 0.05406624 0.04472251 ... 0.92128605 0.8160513  0.6376062 ]
 [0.06362046 0.05664922 0.04816061 ... 0.85181814 0.7578077  0.59460646]
 [0.05865891 0.04838763 0.03591618 ... 0.86287475 0.7655151  0.5993719 ]
 ...
 [0.06398679 0.05740841 0.0494851  ... 0.9718482  0.855559   0.6648232 ]
 [0.06236955 0.05451415 0.04491968 ... 0.7284631  0.6541065  0.5180922 ]
 [0.06359029 0.05676834 0.04855906 ... 0.7906306  0.70549357 0.5554962 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.904624  0.326342  0.098057  ...  0.937380  0.342420 -0.306099
1  0.647794  0.763651 -0.187596  ... -0.832098 -0.599374 -0.879632
2 -0.259641 -0.341707  0.255022  ... -0.992007 -0.309344  0.600517
3 -0.806756  0.308137 -0.363009  ... -0.022736 -0.062399 -0.481236
4 -0.183799 -0.893794  0.087533  ...  0.518753 -0.387864  1.171986

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10770963 -0.0323976   0.04690114 ...  0.9849211   0.8005408
   0.64221835]
 [-0.10887179 -0.03440943  0.04352573 ...  0.91238046  0.7402345
   0.59416485]
 [-0.10836442 -0.03356224  0.04491067 ...  0.91744184  0.739643
   0.5906676 ]
 ...
 [-0.11020693 -0.03649953  0.04027829 ...  1.0231764   0.8284272
   0.66194785]
 [-0.10863164 -0.03403655  0.04410684 ...  0.78107023  0.6305742
   0.5065377 ]
 [-0.1065343  -0.0305678   0.04973188 ...  0.8503947   0.6855154
   0.5485879 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.904624  0.326342  0.098057  ...  0.937380  0.342420 -0.306099
1  0.647794  0.763651 -0.187596  ... -0.832098 -0.599374 -0.879632
2 -0.259641 -0.341707  0.255022  ... -0.992007 -0.309344  0.600517
3 -0.806756  0.308137 -0.363009  ... -0.022736 -0.062399 -0.481236
4 -0.183799 -0.893794  0.087533  ...  0.518753 -0.387864  1.171986

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08421304 0.0579419  0.020711   ... 0.92319864 0.82403886 0.6624062 ]
 [0.086217   0.06051607 0.02377248 ... 0.8371549  0.7532537  0.61148393]
 [0.08145749 0.05338386 0.01410486 ... 0.87443507 0.78255904 0.631608  ]
 ...
 [0.08343511 0.05644934 0.01836345 ... 0.959887   0.85183525 0.680416  ]
 [0.08577932 0.05987807 0.0229314  ... 0.71379066 0.65095633 0.53769296]
 [0.08171569 0.0540459  0.0152795  ... 0.7602249  0.6899401  0.5664097 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.904624  0.326342  0.098057  ...  0.937380  0.342420 -0.306099
1  0.647794  0.763651 -0.187596  ... -0.832098 -0.599374 -0.879632
2 -0.259641 -0.341707  0.255022  ... -0.992007 -0.309344  0.600517
3 -0.806756  0.308137 -0.363009  ... -0.022736 -0.062399 -0.481236
4 -0.183799 -0.893794  0.087533  ...  0.518753 -0.387864  1.171986

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09296349 0.06934115 0.03193016 ... 0.8873321  0.8077965  0.6697521 ]
 [0.09043615 0.06482466 0.02524868 ... 0.825138   0.7590252  0.6377686 ]
 [0.09146611 0.06659305 0.02772196 ... 0.86321104 0.78720665 0.6553025 ]
 ...
 [0.09072334 0.06558067 0.02686737 ... 0.9366871  0.84555507 0.69398904]
 [0.09056564 0.06518576 0.02600612 ... 0.7088077  0.66632324 0.5760975 ]
 [0.08670831 0.05917795 0.01883936 ... 0.7611109  0.7075895  0.603296  ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.904624  0.326342  0.098057  ...  0.937380  0.342420 -0.306099
1  0.647794  0.763651 -0.187596  ... -0.832098 -0.599374 -0.879632
2 -0.259641 -0.341707  0.255022  ... -0.992007 -0.309344  0.600517
3 -0.806756  0.308137 -0.363009  ... -0.022736 -0.062399 -0.481236
4 -0.183799 -0.893794  0.087533  ...  0.518753 -0.387864  1.171986

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.7068709e-01  6.3997537e-02 -2.0113587e-04 ...  8.9114106e-01
   7.9931653e-01  6.5076458e-01]
 [ 1.7078990e-01  6.4238131e-02 -9.9325180e-04 ...  8.3732605e-01
   7.5888640e-01  6.2360835e-01]
 [ 1.6774607e-01  5.9643507e-02 -7.0863962e-03 ...  8.5873598e-01
   7.7177823e-01  6.3045168e-01]
 ...
 [ 1.7122740e-01  6.4912289e-02  6.8753958e-05 ...  9.4990480e-01
   8.4095591e-01  6.7732263e-01]
 [ 1.7539990e-01  7.1404815e-02  6.3286126e-03 ...  7.0333493e-01
   6.5386051e-01  5.5061257e-01]
 [ 1.7173000e-01  6.5783679e-02  1.6626716e-04 ...  7.5646853e-01
   6.9405401e-01  5.7775986e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.904624  0.326342  0.098057  ...  0.937380  0.342420 -0.306099
1  0.647794  0.763651 -0.187596  ... -0.832098 -0.599374 -0.879632
2 -0.259641 -0.341707  0.255022  ... -0.992007 -0.309344  0.600517
3 -0.806756  0.308137 -0.363009  ... -0.022736 -0.062399 -0.481236
4 -0.183799 -0.893794  0.087533  ...  0.518753 -0.387864  1.171986

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09173386 0.03346971 0.01802129 ... 0.8978524  0.7989248  0.6173136 ]
 [0.09217621 0.03386922 0.01763466 ... 0.8274809  0.7433407  0.5811974 ]
 [0.09079367 0.03174436 0.01498073 ... 0.85962486 0.7669382  0.5958444 ]
 ...
 [0.0932945  0.03566618 0.02012397 ... 0.9460454  0.8344749  0.639482  ]
 [0.09403522 0.03684953 0.02176918 ... 0.70737183 0.6471906  0.5181955 ]
 [0.09357905 0.03618811 0.0210574  ... 0.7754452  0.70059466 0.55277467]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.904624  0.326342  0.098057  ...  0.937380  0.342420 -0.306099
1  0.647794  0.763651 -0.187596  ... -0.832098 -0.599374 -0.879632
2 -0.259641 -0.341707  0.255022  ... -0.992007 -0.309344  0.600517
3 -0.806756  0.308137 -0.363009  ... -0.022736 -0.062399 -0.481236
4 -0.183799 -0.893794  0.087533  ...  0.518753 -0.387864  1.171986

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12583536  0.06500557 -0.01072493 ...  0.88760006  0.7919795
   0.7178008 ]
 [ 0.12430817  0.0616813  -0.01662946 ...  0.82623357  0.74597716
   0.6860176 ]
 [ 0.12179229  0.05837151 -0.02067786 ...  0.8533595   0.7646041
   0.69784546]
 ...
 [ 0.12410426  0.06209975 -0.01515126 ...  0.93327874  0.82507086
   0.7399637 ]
 [ 0.13059351  0.06958494 -0.00745842 ...  0.6907271   0.641074
   0.6115082 ]
 [ 0.12688273  0.06574383 -0.01070505 ...  0.7395802   0.67828566
   0.6375782 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.904624  0.326342  0.098057  ...  0.937380  0.342420 -0.306099
1  0.647794  0.763651 -0.187596  ... -0.832098 -0.599374 -0.879632
2 -0.259641 -0.341707  0.255022  ... -0.992007 -0.309344  0.600517
3 -0.806756  0.308137 -0.363009  ... -0.022736 -0.062399 -0.481236
4 -0.183799 -0.893794  0.087533  ...  0.518753 -0.387864  1.171986

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17537598 0.10278812 0.02073175 ... 0.9112774  0.8062094  0.64720047]
 [0.17556228 0.10249913 0.01973054 ... 0.8283763  0.73999584 0.6006064 ]
 [0.16865778 0.09200856 0.00514331 ... 0.8668237  0.7690146  0.6200509 ]
 ...
 [0.17777288 0.10616755 0.02514887 ... 0.9572867  0.8408947  0.6704202 ]
 [0.17431998 0.10011613 0.01582539 ... 0.71089506 0.6429563  0.53046846]
 [0.17504254 0.10161212 0.01834968 ... 0.7630065  0.6849123  0.560184  ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.904624  0.326342  0.098057  ...  0.937380  0.342420 -0.306099
1  0.647794  0.763651 -0.187596  ... -0.832098 -0.599374 -0.879632
2 -0.259641 -0.341707  0.255022  ... -0.992007 -0.309344  0.600517
3 -0.806756  0.308137 -0.363009  ... -0.022736 -0.062399 -0.481236
4 -0.183799 -0.893794  0.087533  ...  0.518753 -0.387864  1.171986

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10684937  0.05009468 -0.0188624  ...  0.88375866  0.8099798
   0.66886705]
 [ 0.11050558  0.05444396 -0.01416239 ...  0.8292316   0.7658305
   0.6378008 ]
 [ 0.0936005   0.03103134 -0.04542631 ...  0.85094273  0.7825233
   0.64907455]
 ...
 [ 0.10758162  0.0507654  -0.01848021 ...  0.9439107   0.854789
   0.69834256]
 [ 0.10303989  0.04401375 -0.02822465 ...  0.7201379   0.67752105
   0.5756445 ]
 [ 0.10919644  0.05305652 -0.01532918 ...  0.77504075  0.72052073
   0.6051382 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.904624  0.326342  0.098057  ...  0.937380  0.342420 -0.306099
1  0.647794  0.763651 -0.187596  ... -0.832098 -0.599374 -0.879632
2 -0.259641 -0.341707  0.255022  ... -0.992007 -0.309344  0.600517
3 -0.806756  0.308137 -0.363009  ... -0.022736 -0.062399 -0.481236
4 -0.183799 -0.893794  0.087533  ...  0.518753 -0.387864  1.171986

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[1.15646541e-01 2.08711326e-02 1.17297471e-02 ... 8.48666251e-01
  8.34925711e-01 7.68473864e-01]
 [1.16707489e-01 2.29207575e-02 1.44323409e-02 ... 8.07398438e-01
  7.99516737e-01 7.42720008e-01]
 [1.14091650e-01 1.74544752e-02 6.26280904e-03 ... 8.31189454e-01
  8.16991031e-01 7.54509926e-01]
 ...
 [1.16219789e-01 2.19977200e-02 1.32879019e-02 ... 9.21063304e-01
  8.92790854e-01 8.09148788e-01]
 [1.18223876e-01 2.60576606e-02 1.90989077e-02 ... 6.53932929e-01
  6.66676164e-01 6.45774841e-01]
 [1.12314492e-01 1.37174129e-02 6.07460737e-04 ... 7.17351317e-01
  7.21778154e-01 6.86031699e-01]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.7152e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaac62e990>, <FrEIA.framework.Node object at 0x7faaa72eb950>, <FrEIA.framework.Node object at 0x7faaa7648050>, <FrEIA.framework.Node object at 0x7faaa72ebfd0>, <FrEIA.framework.Node object at 0x7faaa2c46f90>, <FrEIA.framework.Node object at 0x7faaa2c46dd0>, <FrEIA.framework.Node object at 0x7faaa2c46ad0>, <FrEIA.framework.Node object at 0x7fab95eb2b90>, <FrEIA.framework.Node object at 0x7faaafebfa10>, <FrEIA.framework.Node object at 0x7faab5a2f690>, <FrEIA.framework.Node object at 0x7faab5a2f0d0>, <FrEIA.framework.OutputNode object at 0x7fab95d24750>, <FrEIA.framework.ConditionNode object at 0x7faaa7648a50>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): dummy()
    (12): None
  )
)
Yang/Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005
number of trainable parameters is :
3750540
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: mm6.pt
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.934254  0.469295 -0.041232  ...  0.092581 -0.684922 -0.341694
1  0.744412  0.963593  0.433444  ...  0.616978 -0.100866  0.282608
2  0.117671 -0.451933 -0.151863  ...  0.036543 -0.226435 -0.477594
3 -0.695802  0.250387  0.410491  ... -0.079786 -0.476498  0.033081
4  0.242728 -0.826459 -0.352847  ... -0.078591 -0.732459  1.730867

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06171315 0.05362403 0.04387425 ... 0.9190629  0.8133152  0.6350445 ]
 [0.06288755 0.05537183 0.04619406 ... 0.84507096 0.7518973  0.59010285]
 [0.06312908 0.05577767 0.04680055 ... 0.9110905  0.8042492  0.62673956]
 ...
 [0.06364266 0.05666706 0.04816449 ... 0.97215766 0.85545826 0.66448337]
 [0.06016348 0.05095779 0.03981084 ... 0.8496051  0.75486887 0.59185195]
 [0.06087872 0.05217663 0.04165106 ... 0.75627035 0.6775952  0.5355854 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.934254  0.469295 -0.041232  ...  0.092581 -0.684922 -0.341694
1  0.744412  0.963593  0.433444  ...  0.616978 -0.100866  0.282608
2  0.117671 -0.451933 -0.151863  ...  0.036543 -0.226435 -0.477594
3 -0.695802  0.250387  0.410491  ... -0.079786 -0.476498  0.033081
4  0.242728 -0.826459 -0.352847  ... -0.078591 -0.732459  1.730867

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10676397 -0.03094226  0.0491237  ...  0.94883335  0.7671095
   0.61341023]
 [-0.10851744 -0.03384674  0.04440746 ...  0.8935741   0.72351384
   0.5801617 ]
 [-0.10904461 -0.03470334  0.04304221 ...  0.9479859   0.76278543
   0.6076671 ]
 ...
 [-0.10949108 -0.03539005  0.04198885 ...  1.0236627   0.8270372
   0.6596923 ]
 [-0.1069299  -0.03122622  0.0486542  ...  0.86881995  0.7001779
   0.5598458 ]
 [-0.11098716 -0.03781086  0.03813455 ...  0.806888    0.65415287
   0.5266743 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.934254  0.469295 -0.041232  ...  0.092581 -0.684922 -0.341694
1  0.744412  0.963593  0.433444  ...  0.616978 -0.100866  0.282608
2  0.117671 -0.451933 -0.151863  ...  0.036543 -0.226435 -0.477594
3 -0.695802  0.250387  0.410491  ... -0.079786 -0.476498  0.033081
4  0.242728 -0.826459 -0.352847  ... -0.078591 -0.732459  1.730867

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08429864 0.05792722 0.02054906 ... 0.8958188  0.80110663 0.6456828 ]
 [0.08555288 0.0594411  0.02223711 ... 0.8254953  0.7434349  0.6042969 ]
 [0.08441943 0.05776899 0.01999855 ... 0.8896597  0.7939263  0.63874125]
 ...
 [0.08697821 0.06165406 0.02531428 ... 0.95754105 0.8492373  0.67790145]
 [0.08118758 0.05318158 0.01403551 ... 0.78778094 0.7123645  0.5823016 ]
 [0.08345941 0.05651982 0.0184976  ... 0.74267155 0.6749008  0.555133  ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.934254  0.469295 -0.041232  ...  0.092581 -0.684922 -0.341694
1  0.744412  0.963593  0.433444  ...  0.616978 -0.100866  0.282608
2  0.117671 -0.451933 -0.151863  ...  0.036543 -0.226435 -0.477594
3 -0.695802  0.250387  0.410491  ... -0.079786 -0.476498  0.033081
4  0.242728 -0.826459 -0.352847  ... -0.078591 -0.732459  1.730867

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09215544 0.06793597 0.02991842 ... 0.8711883  0.7948506  0.6610843 ]
 [0.09547605 0.07297876 0.03567311 ... 0.8167819  0.75193167 0.6328097 ]
 [0.09047328 0.06486678 0.02528834 ... 0.8724462  0.79432404 0.65990263]
 ...
 [0.09609471 0.07400255 0.03704117 ... 0.939615   0.8474356  0.6949971 ]
 [0.08991387 0.0643708  0.02544591 ... 0.7603773  0.7069979  0.6029004 ]
 [0.09088168 0.06581406 0.02703883 ... 0.7376234  0.6888852  0.5908705 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.934254  0.469295 -0.041232  ...  0.092581 -0.684922 -0.341694
1  0.744412  0.963593  0.433444  ...  0.616978 -0.100866  0.282608
2  0.117671 -0.451933 -0.151863  ...  0.036543 -0.226435 -0.477594
3 -0.695802  0.250387  0.410491  ... -0.079786 -0.476498  0.033081
4  0.242728 -0.826459 -0.352847  ... -0.078591 -0.732459  1.730867

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.17205627  0.06608343  0.00210863 ...  0.87657666  0.78777087
   0.64268655]
 [ 0.1643633   0.05436948 -0.0130291  ...  0.83207464  0.7550448
   0.6210997 ]
 [ 0.17866525  0.0765259   0.01196364 ...  0.8706574   0.7776685
   0.63268083]
 ...
 [ 0.17221035  0.06646201  0.00136244 ...  0.9385636   0.8326238
   0.67182386]
 [ 0.17331575  0.06799808  0.00487888 ...  0.7675556   0.70363176
   0.5849174 ]
 [ 0.16987026  0.06279948 -0.0026921  ...  0.73778015  0.6807178
   0.5692241 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.934254  0.469295 -0.041232  ...  0.092581 -0.684922 -0.341694
1  0.744412  0.963593  0.433444  ...  0.616978 -0.100866  0.282608
2  0.117671 -0.451933 -0.151863  ...  0.036543 -0.226435 -0.477594
3 -0.695802  0.250387  0.410491  ... -0.079786 -0.476498  0.033081
4  0.242728 -0.826459 -0.352847  ... -0.078591 -0.732459  1.730867

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09241112 0.03441703 0.01891991 ... 0.8888998  0.7911761  0.61201984]
 [0.09474744 0.037807   0.02252623 ... 0.8201854  0.73669827 0.5765521 ]
 [0.0926605  0.03457282 0.01838677 ... 0.8811972  0.7829789  0.605903  ]
 ...
 [0.09191267 0.03337547 0.01673163 ... 0.94880044 0.83661413 0.64086056]
 [0.09155393 0.03307088 0.01714334 ... 0.8026084  0.7225755  0.56725174]
 [0.09254159 0.03457236 0.01897635 ... 0.73926353 0.67233753 0.5345167 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.934254  0.469295 -0.041232  ...  0.092581 -0.684922 -0.341694
1  0.744412  0.963593  0.433444  ...  0.616978 -0.100866  0.282608
2  0.117671 -0.451933 -0.151863  ...  0.036543 -0.226435 -0.477594
3 -0.695802  0.250387  0.410491  ... -0.079786 -0.476498  0.033081
4  0.242728 -0.826459 -0.352847  ... -0.078591 -0.732459  1.730867

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.1253311   0.06422192 -0.01186022 ...  0.8773797   0.78397477
   0.71205926]
 [ 0.13327542  0.07366934 -0.00168577 ...  0.8035798   0.7280935
   0.6731112 ]
 [ 0.13076797  0.06927758 -0.00856808 ...  0.8673836   0.7735888
   0.7031218 ]
 ...
 [ 0.12819117  0.06688145 -0.01012632 ...  0.9386664   0.8285693
   0.74205065]
 [ 0.11811522  0.05434072 -0.02450052 ...  0.7803828   0.7096119
   0.6596714 ]
 [ 0.12542188  0.06359062 -0.01367706 ...  0.72786367  0.66925687
   0.6311892 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.934254  0.469295 -0.041232  ...  0.092581 -0.684922 -0.341694
1  0.744412  0.963593  0.433444  ...  0.616978 -0.100866  0.282608
2  0.117671 -0.451933 -0.151863  ...  0.036543 -0.226435 -0.477594
3 -0.695802  0.250387  0.410491  ... -0.079786 -0.476498  0.033081
4  0.242728 -0.826459 -0.352847  ... -0.078591 -0.732459  1.730867

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17579943 0.10342205 0.02163008 ... 0.8906284  0.78957075 0.6354094 ]
 [0.17988957 0.10913181 0.02899882 ... 0.81765306 0.73071206 0.59365886]
 [0.17714258 0.10425222 0.02141884 ... 0.88342834 0.779757   0.6261576 ]
 ...
 [0.18208018 0.11252899 0.03377602 ... 0.9426001  0.82889414 0.6618214 ]
 [0.17272297 0.0985761  0.01467976 ... 0.76679885 0.6890468  0.56373256]
 [0.16992256 0.09409767 0.00821483 ... 0.7406539  0.66816026 0.5490327 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.934254  0.469295 -0.041232  ...  0.092581 -0.684922 -0.341694
1  0.744412  0.963593  0.433444  ...  0.616978 -0.100866  0.282608
2  0.117671 -0.451933 -0.151863  ...  0.036543 -0.226435 -0.477594
3 -0.695802  0.250387  0.410491  ... -0.079786 -0.476498  0.033081
4  0.242728 -0.826459 -0.352847  ... -0.078591 -0.732459  1.730867

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10932475  0.05339558 -0.01466021 ...  0.8823286   0.807593
   0.6665153 ]
 [ 0.11083005  0.05492817 -0.01346633 ...  0.81499314  0.7542846
   0.6296601 ]
 [ 0.11161223  0.05596739 -0.01211074 ...  0.8697767   0.79441786
   0.6556921 ]
 ...
 [ 0.10881215  0.05249688 -0.01613632 ...  0.9383631   0.8508034
   0.6958115 ]
 [ 0.10239312  0.04355796 -0.02817032 ...  0.79326224  0.73592675
   0.61630756]
 [ 0.10450172  0.04636438 -0.02459717 ...  0.7343687   0.68868154
   0.58330894]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.934254  0.469295 -0.041232  ...  0.092581 -0.684922 -0.341694
1  0.744412  0.963593  0.433444  ...  0.616978 -0.100866  0.282608
2  0.117671 -0.451933 -0.151863  ...  0.036543 -0.226435 -0.477594
3 -0.695802  0.250387  0.410491  ... -0.079786 -0.476498  0.033081
4  0.242728 -0.826459 -0.352847  ... -0.078591 -0.732459  1.730867

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.11686644 0.02342308 0.01554757 ... 0.84012973 0.8274281  0.76289743]
 [0.11547367 0.02033451 0.01052555 ... 0.7776333  0.7749256  0.7250898 ]
 [0.11624357 0.02184373 0.012633   ... 0.8429657  0.82490164 0.7595871 ]
 ...
 [0.1155207  0.02044147 0.01073214 ... 0.92061496 0.8923936  0.8088875 ]
 [0.11391367 0.01720035 0.00612271 ... 0.76028776 0.7587104  0.7128949 ]
 [0.11329865 0.01579717 0.00374979 ... 0.69665897 0.70443404 0.67350924]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.2544e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7fab95eb2b90>, <FrEIA.framework.Node object at 0x7faaaf30b550>, <FrEIA.framework.Node object at 0x7faaaf30bf50>, <FrEIA.framework.Node object at 0x7faaaf3042d0>, <FrEIA.framework.Node object at 0x7faaaf3040d0>, <FrEIA.framework.Node object at 0x7faaaf304050>, <FrEIA.framework.Node object at 0x7faaaf311610>, <FrEIA.framework.Node object at 0x7faaaf311110>, <FrEIA.framework.Node object at 0x7faaaf311450>, <FrEIA.framework.Node object at 0x7faaa72eb950>, <FrEIA.framework.Node object at 0x7faaac5f0950>, <FrEIA.framework.Node object at 0x7faab5df7d50>, <FrEIA.framework.Node object at 0x7faaaf331f10>, <FrEIA.framework.Node object at 0x7faaad9f8890>, <FrEIA.framework.Node object at 0x7faaa8612bd0>, <FrEIA.framework.Node object at 0x7faaa86122d0>, <FrEIA.framework.Node object at 0x7faaad677510>, <FrEIA.framework.Node object at 0x7faaa2c7f090>, <FrEIA.framework.Node object at 0x7fab95de6d50>, <FrEIA.framework.OutputNode object at 0x7fab95de6790>, <FrEIA.framework.ConditionNode object at 0x7faaae724750>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'coupling_6' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_6' takes the following inputs:
	 Output #0 of node 'coupling_6' with dims (14,)

Node 'coupling_7' takes the following inputs:
	 Output #0 of node 'permute_6' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_7' takes the following inputs:
	 Output #0 of node 'coupling_7' with dims (14,)

Node 'coupling_8' takes the following inputs:
	 Output #0 of node 'permute_7' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_8' takes the following inputs:
	 Output #0 of node 'coupling_8' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_8' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (14): PermuteRandom()
    (15): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (16): PermuteRandom()
    (17): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (18): PermuteRandom()
    (19): dummy()
    (20): None
  )
)
Yang/Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005
number of trainable parameters is :
6750972
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm6.pt
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.804574  0.117368  0.387643  ... -1.383518  0.165040 -0.197335
1  0.726231  0.836571  0.466466  ...  0.472864 -0.173118  0.269115
2 -0.131390 -0.656878 -0.034970  ... -0.139587 -0.916956  0.346578
3 -0.701114 -0.354235  0.578872  ...  0.723035  0.083145 -0.004308
4 -0.256051 -0.952952 -1.087169  ... -0.199797  0.833665 -0.681909

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.065058   0.05914833 0.05200004 ... 0.9829252  0.864833   0.6716483 ]
 [0.0657506  0.06033248 0.05379377 ... 0.8635338  0.7674315  0.6016103 ]
 [0.06341019 0.05614473 0.04720996 ... 0.89000195 0.7870059  0.6142916 ]
 ...
 [0.06435101 0.05793353 0.05015172 ... 0.9972929  0.8761388  0.679485  ]
 [0.05277614 0.0387146  0.02174146 ... 0.83099794 0.7414705  0.58349484]
 [0.06184915 0.05379741 0.04405628 ... 0.7577995  0.6786251  0.5361808 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.804574  0.117368  0.387643  ... -1.383518  0.165040 -0.197335
1  0.726231  0.836571  0.466466  ...  0.472864 -0.173118  0.269115
2 -0.131390 -0.656878 -0.034970  ... -0.139587 -0.916956  0.346578
3 -0.701114 -0.354235  0.578872  ...  0.723035  0.083145 -0.004308
4 -0.256051 -0.952952 -1.087169  ... -0.199797  0.833665 -0.681909

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.11025798 -0.0366033   0.04008657 ...  1.0331709   0.83674777
   0.66857624]
 [-0.10733712 -0.0318712   0.04764232 ...  0.9217675   0.74820316
   0.6006286 ]
 [-0.1075488  -0.03228331  0.04690176 ...  0.94294715  0.75892174
   0.6047908 ]
 ...
 [-0.10920796 -0.03491679  0.04276633 ...  1.0421973   0.8424213
   0.67193353]
 [-0.10973468 -0.03577444  0.04138517 ...  0.8986598   0.726109
   0.5812031 ]
 [-0.10718532 -0.03163671  0.04800647 ...  0.804348    0.64952254
   0.5213866 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.804574  0.117368  0.387643  ... -1.383518  0.165040 -0.197335
1  0.726231  0.836571  0.466466  ...  0.472864 -0.173118  0.269115
2 -0.131390 -0.656878 -0.034970  ... -0.139587 -0.916956  0.346578
3 -0.701114 -0.354235  0.578872  ...  0.723035  0.083145 -0.004308
4 -0.256051 -0.952952 -1.087169  ... -0.199797  0.833665 -0.681909

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08389546 0.05710499 0.01920886 ... 0.9792544  0.86816716 0.6924238 ]
 [0.08256224 0.0552329  0.01680833 ... 0.87360597 0.7838637  0.6340967 ]
 [0.08661459 0.06099094 0.02430081 ... 0.88365704 0.78897417 0.63509697]
 ...
 [0.08446235 0.05793129 0.02031278 ... 0.9812959  0.86872685 0.6919278 ]
 [0.08437495 0.05789671 0.02037137 ... 0.77657825 0.70283747 0.5750939 ]
 [0.08495152 0.05879116 0.02161297 ... 0.7432355  0.67497915 0.5548715 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.804574  0.117368  0.387643  ... -1.383518  0.165040 -0.197335
1  0.726231  0.836571  0.466466  ...  0.472864 -0.173118  0.269115
2 -0.131390 -0.656878 -0.034970  ... -0.139587 -0.916956  0.346578
3 -0.701114 -0.354235  0.578872  ...  0.723035  0.083145 -0.004308
4 -0.256051 -0.952952 -1.087169  ... -0.199797  0.833665 -0.681909

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.09157293  0.06691173  0.02843274 ...  0.9414003   0.84959483
   0.69683135]
 [ 0.08894022  0.06274717  0.02330315 ...  0.84740007  0.7766453
   0.64940184]
 [ 0.09288678  0.06867014  0.02991804 ...  0.8689499   0.7917805
   0.65835565]
 ...
 [ 0.09186141  0.06720656  0.02846566 ...  0.95769334  0.86165404
   0.7043377 ]
 [ 0.07324699  0.03746136 -0.00881194 ...  0.8198259   0.7550845
   0.6352479 ]
 [ 0.09018129  0.06476209  0.02585815 ...  0.7384752   0.68962467
   0.5913887 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.804574  0.117368  0.387643  ... -1.383518  0.165040 -0.197335
1  0.726231  0.836571  0.466466  ...  0.472864 -0.173118  0.269115
2 -0.131390 -0.656878 -0.034970  ... -0.139587 -0.916956  0.346578
3 -0.701114 -0.354235  0.578872  ...  0.723035  0.083145 -0.004308
4 -0.256051 -0.952952 -1.087169  ... -0.199797  0.833665 -0.681909

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.17276287  0.06715804  0.00376087 ...  0.94045013  0.83522344
   0.674257  ]
 [ 0.17183486  0.06557569  0.00302953 ...  0.85012907  0.77052844
   0.6325886 ]
 [ 0.17111126  0.06485817 -0.00138035 ...  0.87171954  0.7806921
   0.63596594]
 ...
 [ 0.17511225  0.07086727  0.00719047 ...  0.9500732   0.84058756
   0.67679167]
 [ 0.15620323  0.04175928 -0.02721453 ...  0.8215407   0.74685216
   0.61544967]
 [ 0.17252879  0.06686854  0.00233892 ...  0.728006    0.6730584
   0.56390196]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.804574  0.117368  0.387643  ... -1.383518  0.165040 -0.197335
1  0.726231  0.836571  0.466466  ...  0.472864 -0.173118  0.269115
2 -0.131390 -0.656878 -0.034970  ... -0.139587 -0.916956  0.346578
3 -0.701114 -0.354235  0.578872  ...  0.723035  0.083145 -0.004308
4 -0.256051 -0.952952 -1.087169  ... -0.199797  0.833665 -0.681909

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09323539 0.03565107 0.02035722 ... 0.9611261  0.8469274  0.6477757 ]
 [0.09424247 0.03725505 0.02254918 ... 0.86802983 0.77480865 0.6014314 ]
 [0.09395406 0.0365226  0.02071227 ... 0.87305343 0.77681315 0.6020045 ]
 ...
 [0.09208287 0.03367108 0.01721069 ... 0.9703889  0.8533982  0.6516689 ]
 [0.09135574 0.03271416 0.01653366 ... 0.7947413  0.71677613 0.56364083]
 [0.09355216 0.03612271 0.02091198 ... 0.73428714 0.6681303  0.53168   ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.804574  0.117368  0.387643  ... -1.383518  0.165040 -0.197335
1  0.726231  0.836571  0.466466  ...  0.472864 -0.173118  0.269115
2 -0.131390 -0.656878 -0.034970  ... -0.139587 -0.916956  0.346578
3 -0.701114 -0.354235  0.578872  ...  0.723035  0.083145 -0.004308
4 -0.256051 -0.952952 -1.087169  ... -0.199797  0.833665 -0.681909

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12421677  0.06261748 -0.0140132  ...  0.9490073   0.837382
   0.7487864 ]
 [ 0.12673905  0.06640378 -0.00873664 ...  0.84046596  0.75693065
   0.6937581 ]
 [ 0.13150802  0.07056391 -0.00656685 ...  0.86429447  0.7721356
   0.7026439 ]
 ...
 [ 0.13042066  0.06997401 -0.00611645 ...  0.95173573  0.83821225
   0.74861896]
 [ 0.1166636   0.05224988 -0.02731574 ...  0.7576161   0.6928035
   0.64821565]
 [ 0.12614232  0.06459454 -0.01237094 ...  0.72466505  0.66682565
   0.6294886 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.804574  0.117368  0.387643  ... -1.383518  0.165040 -0.197335
1  0.726231  0.836571  0.466466  ...  0.472864 -0.173118  0.269115
2 -0.131390 -0.656878 -0.034970  ... -0.139587 -0.916956  0.346578
3 -0.701114 -0.354235  0.578872  ...  0.723035  0.083145 -0.004308
4 -0.256051 -0.952952 -1.087169  ... -0.199797  0.833665 -0.681909

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.1741996  0.1008262  0.01784351 ... 0.96480817 0.84809    0.6761709 ]
 [0.17759806 0.10641524 0.02605855 ... 0.85418624 0.76179814 0.61663336]
 [0.17393737 0.09958696 0.01517996 ... 0.8838964  0.7812174  0.62781155]
 ...
 [0.1779569  0.10610801 0.02468663 ... 0.9698996  0.8504071  0.6767881 ]
 [0.1753065  0.1024617  0.02003565 ... 0.76706886 0.6896602  0.5643927 ]
 [0.1743391  0.10085478 0.01764309 ... 0.7426574  0.66924465 0.54949826]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.804574  0.117368  0.387643  ... -1.383518  0.165040 -0.197335
1  0.726231  0.836571  0.466466  ...  0.472864 -0.173118  0.269115
2 -0.131390 -0.656878 -0.034970  ... -0.139587 -0.916956  0.346578
3 -0.701114 -0.354235  0.578872  ...  0.723035  0.083145 -0.004308
4 -0.256051 -0.952952 -1.087169  ... -0.199797  0.833665 -0.681909

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10878994  0.05264154 -0.01568806 ...  0.9319378   0.84660566
   0.69338137]
 [ 0.11006187  0.0543769  -0.01343471 ...  0.84899986  0.7821541
   0.6494427 ]
 [ 0.10811426  0.05092661 -0.0191682  ...  0.868505    0.7949009
   0.65682113]
 ...
 [ 0.10681419  0.04963094 -0.02011985 ...  0.96126294  0.86866033
   0.70800805]
 [ 0.09940858  0.03943825 -0.03365818 ...  0.7808187   0.7275811
   0.6113368 ]
 [ 0.11201137  0.05680998 -0.01058251 ...  0.7280954   0.6826083
   0.57851   ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.804574  0.117368  0.387643  ... -1.383518  0.165040 -0.197335
1  0.726231  0.836571  0.466466  ...  0.472864 -0.173118  0.269115
2 -0.131390 -0.656878 -0.034970  ... -0.139587 -0.916956  0.346578
3 -0.701114 -0.354235  0.578872  ...  0.723035  0.083145 -0.004308
4 -0.256051 -0.952952 -1.087169  ... -0.199797  0.833665 -0.681909

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.11509158 0.01963726 0.00970408 ... 0.92745626 0.8993784  0.81425416]
 [0.11978833 0.02958047 0.02489647 ... 0.79897356 0.79337823 0.7385609 ]
 [0.11343744 0.01594654 0.00368679 ... 0.846502   0.82972085 0.763664  ]
 ...
 [0.11717463 0.02397311 0.01619905 ... 0.9298202  0.89956164 0.8138732 ]
 [0.11263508 0.01448113 0.00192586 ... 0.7262759  0.7306938  0.6928741 ]
 [0.11536072 0.02013773 0.01032719 ... 0.6902487  0.6984222  0.6689686 ]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.3399e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaabd5f290>, <FrEIA.framework.Node object at 0x7faaabd5ff50>, <FrEIA.framework.Node object at 0x7faaabd5fc90>, <FrEIA.framework.Node object at 0x7faaabd5f890>, <FrEIA.framework.Node object at 0x7faaabd5fa90>, <FrEIA.framework.Node object at 0x7faaabd5f410>, <FrEIA.framework.Node object at 0x7faaabd5f750>, <FrEIA.framework.Node object at 0x7faaabd45c50>, <FrEIA.framework.Node object at 0x7faaabd45710>, <FrEIA.framework.Node object at 0x7faaabd45f90>, <FrEIA.framework.Node object at 0x7faaab2dc450>, <FrEIA.framework.Node object at 0x7faaae780350>, <FrEIA.framework.Node object at 0x7faaac1a6490>, <FrEIA.framework.Node object at 0x7faaaa9dd5d0>, <FrEIA.framework.Node object at 0x7fab95ea4590>, <FrEIA.framework.OutputNode object at 0x7faaa7669bd0>, <FrEIA.framework.ConditionNode object at 0x7faaaca2e2d0>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'coupling_6' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_6' takes the following inputs:
	 Output #0 of node 'coupling_6' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_6' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (14): PermuteRandom()
    (15): dummy()
    (16): None
  )
)
Yang/Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005
number of trainable parameters is :
5250756
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm6.pt
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.063007  0.231312 -0.065191  ...  0.486142 -0.430340  0.269791
1  0.835625  0.715535  0.016571  ... -0.628352  0.502300  0.367903
2  0.750164 -0.860462 -0.495293  ...  0.605632 -0.272984 -0.230477
3 -0.720779  0.163096 -0.609839  ... -0.406774  0.981911  0.531533
4  0.136459 -0.839987  0.083019  ...  1.179634 -0.192359 -0.113740

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06437648 0.05806468 0.0504681  ... 0.9431968  0.8321392  0.6479753 ]
 [0.06183781 0.05375575 0.0439711  ... 0.89228415 0.79171103 0.61963224]
 [0.05946575 0.05017594 0.03914749 ... 0.92353976 0.81803936 0.6392584 ]
 ...
 [0.06194432 0.05393108 0.04423025 ... 1.0028682  0.88100564 0.68321365]
 [0.0625532  0.05499041 0.04585562 ... 0.7661963  0.68602586 0.54183567]
 [0.05837111 0.04833642 0.03640179 ... 0.849317   0.75595707 0.59363526]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.063007  0.231312 -0.065191  ...  0.486142 -0.430340  0.269791
1  0.835625  0.715535  0.016571  ... -0.628352  0.502300  0.367903
2  0.750164 -0.860462 -0.495293  ...  0.605632 -0.272984 -0.230477
3 -0.720779  0.163096 -0.609839  ... -0.406774  0.981911  0.531533
4  0.136459 -0.839987  0.083019  ...  1.179634 -0.192359 -0.113740

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10949543 -0.03532621  0.04217416 ...  1.0044807   0.8135979
   0.65059006]
 [-0.10812277 -0.03320304  0.04544339 ...  0.9295472   0.7526562
   0.602898  ]
 [-0.11269604 -0.04049942  0.03393891 ...  0.9689212   0.79037654
   0.63612473]
 ...
 [-0.10775644 -0.03252086  0.04664463 ...  1.0346414   0.8359455
   0.6666572 ]
 [-0.11052398 -0.03706968  0.03929794 ...  0.82139564  0.66508245
   0.53463924]
 [-0.11172754 -0.03896415  0.03633648 ...  0.93909955  0.76052964
   0.6091361 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.063007  0.231312 -0.065191  ...  0.486142 -0.430340  0.269791
1  0.835625  0.715535  0.016571  ... -0.628352  0.502300  0.367903
2  0.750164 -0.860462 -0.495293  ...  0.605632 -0.272984 -0.230477
3 -0.720779  0.163096 -0.609839  ... -0.406774  0.981911  0.531533
4  0.136459 -0.839987  0.083019  ...  1.179634 -0.192359 -0.113740

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08505222 0.05902407 0.02200634 ... 0.9318103  0.82951003 0.6650515 ]
 [0.08732825 0.0622832  0.02627333 ... 0.86858714 0.77833617 0.62892747]
 [0.08002271 0.05177477 0.01247269 ... 0.8983253  0.8043647  0.6491453 ]
 ...
 [0.08497566 0.05879883 0.02159068 ... 0.9675476  0.8577937  0.6843786 ]
 [0.08325718 0.0562651  0.01820227 ... 0.7565343  0.68686706 0.56411994]
 [0.08123519 0.05346346 0.01463118 ... 0.8148137  0.7348049  0.5985901 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.063007  0.231312 -0.065191  ...  0.486142 -0.430340  0.269791
1  0.835625  0.715535  0.016571  ... -0.628352  0.502300  0.367903
2  0.750164 -0.860462 -0.495293  ...  0.605632 -0.272984 -0.230477
3 -0.720779  0.163096 -0.609839  ... -0.406774  0.981911  0.531533
4  0.136459 -0.839987  0.083019  ...  1.179634 -0.192359 -0.113740

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09174982 0.06725365 0.0290051  ... 0.91276157 0.82698977 0.6819139 ]
 [0.08863366 0.06218089 0.02245611 ... 0.857844   0.7848706  0.6548234 ]
 [0.08516999 0.05704322 0.01683928 ... 0.8881407  0.8087462  0.6705243 ]
 ...
 [0.08806814 0.06114063 0.02087355 ... 0.96165013 0.86493325 0.70657825]
 [0.08981846 0.06413731 0.0249877  ... 0.74527276 0.69538015 0.5954127 ]
 [0.08825187 0.06191543 0.02282803 ... 0.8144046  0.7495488  0.63092446]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.063007  0.231312 -0.065191  ...  0.486142 -0.430340  0.269791
1  0.835625  0.715535  0.016571  ... -0.628352  0.502300  0.367903
2  0.750164 -0.860462 -0.495293  ...  0.605632 -0.272984 -0.230477
3 -0.720779  0.163096 -0.609839  ... -0.406774  0.981911  0.531533
4  0.136459 -0.839987  0.083019  ...  1.179634 -0.192359 -0.113740

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.7782429e-01  7.4917644e-02  1.3130754e-02 ...  8.9755023e-01
   8.0259728e-01  6.5211886e-01]
 [ 1.6299020e-01  5.2177131e-02 -1.4722854e-02 ...  8.7475556e-01
   7.8862309e-01  6.4450866e-01]
 [ 1.5799536e-01  4.4317961e-02 -2.2328258e-02 ...  9.0831691e-01
   8.1450939e-01  6.6227508e-01]
 ...
 [ 1.7275324e-01  6.7244887e-02  3.2323599e-03 ...  9.4063574e-01
   8.3415860e-01  6.7284048e-01]
 [ 1.7053659e-01  6.3743740e-02 -8.4862113e-04 ...  7.4068892e-01
   6.8417066e-01  5.7225293e-01]
 [ 1.6170095e-01  5.0113201e-02 -1.6067177e-02 ...  8.4540921e-01
   7.6462114e-01  6.2729204e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.063007  0.231312 -0.065191  ...  0.486142 -0.430340  0.269791
1  0.835625  0.715535  0.016571  ... -0.628352  0.502300  0.367903
2  0.750164 -0.860462 -0.495293  ...  0.605632 -0.272984 -0.230477
3 -0.720779  0.163096 -0.609839  ... -0.406774  0.981911  0.531533
4  0.136459 -0.839987  0.083019  ...  1.179634 -0.192359 -0.113740

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09341839 0.03598002 0.02091639 ... 0.93480766 0.8262727  0.6343969 ]
 [0.09299691 0.03514983 0.01930204 ... 0.8516396  0.76182663 0.5929854 ]
 [0.08673467 0.0257085  0.00806059 ... 0.90858245 0.8076148  0.6230186 ]
 ...
 [0.09305862 0.03528488 0.01958944 ... 0.96731997 0.85097694 0.65009403]
 [0.09210901 0.03390655 0.01813476 ... 0.75166786 0.6827242  0.5414951 ]
 [0.08377926 0.02104211 0.00182199 ... 0.8256805  0.74238455 0.58070636]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.063007  0.231312 -0.065191  ...  0.486142 -0.430340  0.269791
1  0.835625  0.715535  0.016571  ... -0.628352  0.502300  0.367903
2  0.750164 -0.860462 -0.495293  ...  0.605632 -0.272984 -0.230477
3 -0.720779  0.163096 -0.609839  ... -0.406774  0.981911  0.531533
4  0.136459 -0.839987  0.083019  ...  1.179634 -0.192359 -0.113740

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12826973  0.06823602 -0.00673121 ...  0.909372    0.8072511
   0.7277117 ]
 [ 0.12974265  0.06953469 -0.00603527 ...  0.8334906   0.7510027
   0.68923724]
 [ 0.11690006  0.05391285 -0.02339992 ...  0.8847152   0.7900222
   0.716572  ]
 ...
 [ 0.12769839  0.0665094  -0.01019415 ...  0.9543782   0.8402599
   0.7500739 ]
 [ 0.12374762  0.06161529 -0.01578158 ...  0.7430135   0.68139005
   0.6400459 ]
 [ 0.1162712   0.05305043 -0.02449831 ...  0.792897    0.7194805
   0.66678834]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.063007  0.231312 -0.065191  ...  0.486142 -0.430340  0.269791
1  0.835625  0.715535  0.016571  ... -0.628352  0.502300  0.367903
2  0.750164 -0.860462 -0.495293  ...  0.605632 -0.272984 -0.230477
3 -0.720779  0.163096 -0.609839  ... -0.406774  0.981911  0.531533
4  0.136459 -0.839987  0.083019  ...  1.179634 -0.192359 -0.113740

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.17213008  0.09797707  0.01420951 ...  0.934378    0.82460403
   0.6601119 ]
 [ 0.17762086  0.10601398  0.02503932 ...  0.8546624   0.7611501
   0.6155895 ]
 [ 0.17000283  0.09503442  0.01041469 ...  0.8963178   0.7951735
   0.63996017]
 ...
 [ 0.1738881   0.0999988   0.01629415 ...  0.9742579   0.8545556
   0.6800885 ]
 [ 0.17434952  0.10099718  0.01798204 ...  0.74433815  0.67153805
   0.5516604 ]
 [ 0.16160372  0.08250237 -0.00671923 ...  0.82332426  0.7373885
   0.5995927 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.063007  0.231312 -0.065191  ...  0.486142 -0.430340  0.269791
1  0.835625  0.715535  0.016571  ... -0.628352  0.502300  0.367903
2  0.750164 -0.860462 -0.495293  ...  0.605632 -0.272984 -0.230477
3 -0.720779  0.163096 -0.609839  ... -0.406774  0.981911  0.531533
4  0.136459 -0.839987  0.083019  ...  1.179634 -0.192359 -0.113740

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.11424053  0.06024626 -0.00544116 ...  0.9074559   0.82632804
   0.67887604]
 [ 0.11338679  0.05888566 -0.00754124 ...  0.84042645  0.7745067
   0.64369655]
 [ 0.09797135  0.03797472 -0.03481871 ...  0.8973664   0.8213638
   0.67703223]
 ...
 [ 0.10764717  0.05088949 -0.0182648  ...  0.95245314  0.8615967
   0.70307076]
 [ 0.10711609  0.05006526 -0.01953819 ...  0.7437439   0.69647944
   0.5889021 ]
 [ 0.10081397  0.04192516 -0.02949023 ...  0.80062675  0.7427944
   0.621651  ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.063007  0.231312 -0.065191  ...  0.486142 -0.430340  0.269791
1  0.835625  0.715535  0.016571  ... -0.628352  0.502300  0.367903
2  0.750164 -0.860462 -0.495293  ...  0.605632 -0.272984 -0.230477
3 -0.720779  0.163096 -0.609839  ... -0.406774  0.981911  0.531533
4  0.136459 -0.839987  0.083019  ...  1.179634 -0.192359 -0.113740

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.16243154e-01  2.20752954e-02  1.34358108e-02 ...  8.81976664e-01
   8.61230791e-01  7.86805272e-01]
 [ 1.17305145e-01  2.42947936e-02  1.67556107e-02 ...  8.04902673e-01
   7.98205495e-01  7.41932750e-01]
 [ 1.11853793e-01  1.29470825e-02 -1.70767307e-04 ...  8.61932874e-01
   8.46352160e-01  7.76730239e-01]
 ...
 [ 1.15153283e-01  1.96972191e-02  9.67639685e-03 ...  9.37447548e-01
   9.05996740e-01  8.18544507e-01]
 [ 1.16300717e-01  2.21841931e-02  1.35869384e-02 ...  6.98539197e-01
   7.06224024e-01  6.74892962e-01]
 [ 1.06736630e-01  2.15476751e-03 -1.65757239e-02 ...  8.06224704e-01
   7.99063325e-01  7.42483377e-01]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.3665e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaaa9c5e50>, <FrEIA.framework.Node object at 0x7faab55fc990>, <FrEIA.framework.Node object at 0x7faab55fcf50>, <FrEIA.framework.Node object at 0x7faab55fc9d0>, <FrEIA.framework.Node object at 0x7faaaa9da790>, <FrEIA.framework.Node object at 0x7faaaa9c2490>, <FrEIA.framework.Node object at 0x7faaaa9c2e90>, <FrEIA.framework.Node object at 0x7faaaa9c2a90>, <FrEIA.framework.Node object at 0x7faaaa99c650>, <FrEIA.framework.Node object at 0x7faaaa99c410>, <FrEIA.framework.Node object at 0x7faaaa99cd90>, <FrEIA.framework.Node object at 0x7faaaf797e90>, <FrEIA.framework.Node object at 0x7faaaa9c59d0>, <FrEIA.framework.Node object at 0x7faaab114950>, <FrEIA.framework.Node object at 0x7faaaffeb290>, <FrEIA.framework.OutputNode object at 0x7faaac1b2a10>, <FrEIA.framework.ConditionNode object at 0x7fab94047e90>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'coupling_6' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_6' takes the following inputs:
	 Output #0 of node 'coupling_6' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_6' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (14): PermuteRandom()
    (15): dummy()
    (16): None
  )
)
Yang/Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005
number of trainable parameters is :
5250756
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm6.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.884011  0.609126 -0.782748  ... -1.658057 -0.541116 -1.032763
1  0.735346  1.062096 -0.011991  ...  0.094761  1.020032 -0.629075
2  0.210827 -0.400603 -0.827131  ... -0.664808 -0.138889 -0.692943
3 -0.847899 -0.234112  1.021197  ...  0.141833  0.302926  0.118810
4 -0.421079 -0.870674 -0.484575  ... -0.480685  0.694821  0.526046

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06250934 0.05483565 0.0455268  ... 0.8907181  0.7897722  0.61776   ]
 [0.06364538 0.05672726 0.04831865 ... 0.818903   0.73072916 0.5750126 ]
 [0.06145266 0.05301818 0.0427494  ... 0.89855486 0.79543096 0.62135357]
 ...
 [0.05851649 0.04832652 0.03606242 ... 0.97978    0.8632781  0.6712583 ]
 [0.0622867  0.05446085 0.04495274 ... 0.7554337  0.67604613 0.53389555]
 [0.05941865 0.05000119 0.03876489 ... 0.75437015 0.67765945 0.5367737 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.884011  0.609126 -0.782748  ... -1.658057 -0.541116 -1.032763
1  0.735346  1.062096 -0.011991  ...  0.094761  1.020032 -0.629075
2  0.210827 -0.400603 -0.827131  ... -0.664808 -0.138889 -0.692943
3 -0.847899 -0.234112  1.021197  ...  0.141833  0.302926  0.118810
4 -0.421079 -0.870674 -0.484575  ... -0.480685  0.694821  0.526046

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10783744 -0.03270823  0.04626751 ...  0.9407098   0.7610383
   0.6089883 ]
 [-0.10807297 -0.03309584  0.04565132 ...  0.88174844  0.7163098
   0.5760926 ]
 [-0.10779005 -0.03265378  0.04633582 ...  0.93489885  0.7553543
   0.60393107]
 ...
 [-0.11168166 -0.03889328  0.03645307 ...  1.0276275   0.833308
   0.66658163]
 [-0.10883842 -0.03435963  0.04360732 ...  0.80409074  0.6487324
   0.52038944]
 [-0.1091629  -0.03478107  0.04306161 ...  0.79964304  0.6506269
   0.5254574 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.884011  0.609126 -0.782748  ... -1.658057 -0.541116 -1.032763
1  0.735346  1.062096 -0.011991  ...  0.094761  1.020032 -0.629075
2  0.210827 -0.400603 -0.827131  ... -0.664808 -0.138889 -0.692943
3 -0.847899 -0.234112  1.021197  ...  0.141833  0.302926  0.118810
4 -0.421079 -0.870674 -0.484575  ... -0.480685  0.694821  0.526046

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08465721 0.0583051  0.0209019  ... 0.8778604  0.78665596 0.63542175]
 [0.08757966 0.06266659 0.02679994 ... 0.8120246  0.7327743  0.59696704]
 [0.08325485 0.05601253 0.01760621 ... 0.8847904  0.7910723  0.6375999 ]
 ...
 [0.082555   0.05507105 0.01643246 ... 0.9624064  0.8542145  0.6823478 ]
 [0.08507272 0.05894296 0.02178826 ... 0.7396786  0.6717357  0.55230445]
 [0.07955456 0.05099804 0.01134436 ... 0.748379   0.6819294  0.5621836 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.884011  0.609126 -0.782748  ... -1.658057 -0.541116 -1.032763
1  0.735346  1.062096 -0.011991  ...  0.094761  1.020032 -0.629075
2  0.210827 -0.400603 -0.827131  ... -0.664808 -0.138889 -0.692943
3 -0.847899 -0.234112  1.021197  ...  0.141833  0.302926  0.118810
4 -0.421079 -0.870674 -0.484575  ... -0.480685  0.694821  0.526046

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09286651 0.06889994 0.03077433 ... 0.85371935 0.7811562  0.65212125]
 [0.09190229 0.06727926 0.02854598 ... 0.8095182  0.746547   0.62944937]
 [0.09541467 0.07293159 0.03573342 ... 0.86265504 0.7870256  0.6553389 ]
 ...
 [0.08925875 0.0631441  0.02359398 ... 0.93391466 0.8434814  0.6926833 ]
 [0.09252612 0.06838939 0.03013045 ... 0.73308444 0.684872   0.587976  ]
 [0.08738382 0.06056036 0.02118951 ... 0.74019766 0.6918889  0.59337616]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.884011  0.609126 -0.782748  ... -1.658057 -0.541116 -1.032763
1  0.735346  1.062096 -0.011991  ...  0.094761  1.020032 -0.629075
2  0.210827 -0.400603 -0.827131  ... -0.664808 -0.138889 -0.692943
3 -0.847899 -0.234112  1.021197  ...  0.141833  0.302926  0.118810
4 -0.421079 -0.870674 -0.484575  ... -0.480685  0.694821  0.526046

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.17445832  0.06981626  0.00657731 ...  0.86119556  0.77666974
   0.6354743 ]
 [ 0.17937359  0.07740733  0.0148409  ...  0.7941322   0.72500306
   0.600042  ]
 [ 0.17764555  0.07474124  0.01181698 ...  0.8650561   0.77669805
   0.6338575 ]
 ...
 [ 0.16758364  0.05932057 -0.00660691 ...  0.9598615   0.8491205
   0.68319356]
 [ 0.1758417   0.07201138  0.00806364 ...  0.7184676   0.6646143
   0.557509  ]
 [ 0.1645406   0.05442324 -0.01050451 ...  0.740535    0.68627596
   0.5749289 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.884011  0.609126 -0.782748  ... -1.658057 -0.541116 -1.032763
1  0.735346  1.062096 -0.011991  ...  0.094761  1.020032 -0.629075
2  0.210827 -0.400603 -0.827131  ... -0.664808 -0.138889 -0.692943
3 -0.847899 -0.234112  1.021197  ...  0.141833  0.302926  0.118810
4 -0.421079 -0.870674 -0.484575  ... -0.480685  0.694821  0.526046

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09270258 0.03473815 0.01890966 ... 0.8729391  0.7784711  0.60373855]
 [0.09332152 0.0356967  0.02014437 ... 0.80592906 0.72650844 0.5703278 ]
 [0.09296933 0.03511065 0.01926333 ... 0.8752855  0.7792553  0.60384   ]
 ...
 [0.08933209 0.0294507  0.01194513 ... 0.9579631  0.844578   0.6463032 ]
 [0.09305547 0.03531708 0.01976943 ... 0.7355603  0.66882885 0.5320156 ]
 [0.09099825 0.03238031 0.01679511 ... 0.73549664 0.6708635  0.5341126 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.884011  0.609126 -0.782748  ... -1.658057 -0.541116 -1.032763
1  0.735346  1.062096 -0.011991  ...  0.094761  1.020032 -0.629075
2  0.210827 -0.400603 -0.827131  ... -0.664808 -0.138889 -0.692943
3 -0.847899 -0.234112  1.021197  ...  0.141833  0.302926  0.118810
4 -0.421079 -0.870674 -0.484575  ... -0.480685  0.694821  0.526046

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12902826  0.06861579 -0.00712645 ...  0.86395943  0.77384996
   0.70502615]
 [ 0.13188967  0.07176077 -0.00414282 ...  0.7972249   0.72364354
   0.67022824]
 [ 0.12912029  0.06799537 -0.00891694 ...  0.87369984  0.78000325
   0.708578  ]
 ...
 [ 0.12237924  0.05952916 -0.0187214  ...  0.943919    0.8330498
   0.74547714]
 [ 0.12666303  0.06482375 -0.01272619 ...  0.7280568   0.66874796
   0.6304376 ]
 [ 0.11306715  0.04820698 -0.03130794 ...  0.73745346  0.6778336
   0.63796026]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.884011  0.609126 -0.782748  ... -1.658057 -0.541116 -1.032763
1  0.735346  1.062096 -0.011991  ...  0.094761  1.020032 -0.629075
2  0.210827 -0.400603 -0.827131  ... -0.664808 -0.138889 -0.692943
3 -0.847899 -0.234112  1.021197  ...  0.141833  0.302926  0.118810
4 -0.421079 -0.870674 -0.484575  ... -0.480685  0.694821  0.526046

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17292166 0.09888473 0.01516455 ... 0.8797769  0.78143764 0.6299909 ]
 [0.1805293  0.10991012 0.0298411  ... 0.81298476 0.7266419  0.59059817]
 [0.17691416 0.10443953 0.02226534 ... 0.87748665 0.77689123 0.62522566]
 ...
 [0.17142165 0.09648266 0.01167849 ... 0.9636239  0.8470161  0.6753358 ]
 [0.17410684 0.10021195 0.01643923 ... 0.73651516 0.66341096 0.54485834]
 [0.1656367  0.08859152 0.00169855 ... 0.75453633 0.6824928  0.5609887 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.884011  0.609126 -0.782748  ... -1.658057 -0.541116 -1.032763
1  0.735346  1.062096 -0.011991  ...  0.094761  1.020032 -0.629075
2  0.210827 -0.400603 -0.827131  ... -0.664808 -0.138889 -0.692943
3 -0.847899 -0.234112  1.021197  ...  0.141833  0.302926  0.118810
4 -0.421079 -0.870674 -0.484575  ... -0.480685  0.694821  0.526046

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10988583  0.05385935 -0.0145089  ...  0.86308444  0.79236794
   0.6560119 ]
 [ 0.10868092  0.05209436 -0.01703438 ...  0.80992305  0.7511401
   0.6279572 ]
 [ 0.10535331  0.04740515 -0.02341178 ...  0.8798059   0.8049767
   0.664395  ]
 ...
 [ 0.10191555  0.0428669  -0.02911893 ...  0.9500686   0.86075723
   0.7030588 ]
 [ 0.10597393  0.04824716 -0.02232796 ...  0.7349832   0.688228
   0.582465  ]
 [ 0.10329336  0.04512495 -0.02557975 ...  0.73692787  0.69241184
   0.58679223]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.884011  0.609126 -0.782748  ... -1.658057 -0.541116 -1.032763
1  0.735346  1.062096 -0.011991  ...  0.094761  1.020032 -0.629075
2  0.210827 -0.400603 -0.827131  ... -0.664808 -0.138889 -0.692943
3 -0.847899 -0.234112  1.021197  ...  0.141833  0.302926  0.118810
4 -0.421079 -0.870674 -0.484575  ... -0.480685  0.694821  0.526046

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.11395551  0.01721254  0.00595611 ...  0.82545805  0.8156582
   0.7546409 ]
 [ 0.11564881  0.02073166  0.01120162 ...  0.77552724  0.77301294
   0.72371435]
 [ 0.11422162  0.01764604  0.00636098 ...  0.8452204   0.8294953
   0.76376843]
 ...
 [ 0.11287469  0.0149067   0.00240803 ...  0.9283538   0.899698
   0.8144114 ]
 [ 0.11644015  0.02235299  0.01356795 ...  0.6845145   0.692417
   0.6642577 ]
 [ 0.11068948  0.01045269 -0.0040381  ...  0.72363913  0.7295613
   0.6923765 ]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.3643e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaaa003310>, <FrEIA.framework.Node object at 0x7faaaa003950>, <FrEIA.framework.Node object at 0x7faaaa003890>, <FrEIA.framework.Node object at 0x7faaaa003690>, <FrEIA.framework.Node object at 0x7faaaa003590>, <FrEIA.framework.Node object at 0x7faaaa003110>, <FrEIA.framework.Node object at 0x7faaaa003750>, <FrEIA.framework.Node object at 0x7faaaa003290>, <FrEIA.framework.Node object at 0x7fab94065e50>, <FrEIA.framework.Node object at 0x7fab94065a90>, <FrEIA.framework.Node object at 0x7fab940651d0>, <FrEIA.framework.Node object at 0x7fab94065b50>, <FrEIA.framework.Node object at 0x7fab94065790>, <FrEIA.framework.OutputNode object at 0x7fab940654d0>, <FrEIA.framework.ConditionNode object at 0x7faaadf36e50>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): dummy()
    (14): None
  )
)
Yang/Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005
number of trainable parameters is :
4500648
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm6.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.766550  0.599711  0.683796  ...  0.168184 -0.810767 -0.738577
1  0.762026  0.774740  0.624559  ...  0.521746  0.512383  0.081228
2  0.187338 -0.662043 -0.361459  ... -0.561465  0.371915 -0.064570
3 -0.815319 -0.240640  0.206946  ...  0.025086  0.389251  0.199834
4 -0.366821 -0.623131 -0.356325  ... -0.141907 -0.628995  0.068047

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06141923 0.05317577 0.04326259 ... 0.914452   0.80995786 0.63292843]
 [0.0648839  0.05881052 0.05143831 ... 0.84923977 0.755506   0.59283245]
 [0.0613347  0.05279745 0.04239486 ... 0.88618964 0.78486043 0.6134298 ]
 ...
 [0.06072931 0.05180474 0.04094531 ... 1.0137475  0.89043707 0.6903396 ]
 [0.05806058 0.04783662 0.03568131 ... 0.8087518  0.72257274 0.5694875 ]
 [0.06067721 0.05201195 0.04162988 ... 0.8203     0.7309175  0.5746793 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.766550  0.599711  0.683796  ...  0.168184 -0.810767 -0.738577
1  0.762026  0.774740  0.624559  ...  0.521746  0.512383  0.081228
2  0.187338 -0.662043 -0.361459  ... -0.561465  0.371915 -0.064570
3 -0.815319 -0.240640  0.206946  ...  0.025086  0.389251  0.199834
4 -0.366821 -0.623131 -0.356325  ... -0.141907 -0.628995  0.068047

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10793792 -0.03293717  0.04582462 ...  0.9609891   0.77471983
   0.6178844 ]
 [-0.10942443 -0.03529155  0.04213005 ...  0.91443837  0.7416682
   0.5951389 ]
 [-0.1092885  -0.03509101  0.04243252 ...  0.927801    0.7495651
   0.5993916 ]
 ...
 [-0.10913736 -0.03480807  0.04292947 ...  1.0572761   0.85403347
   0.68058753]
 [-0.11242962 -0.04006642  0.03462988 ...  0.85907376  0.6992234
   0.5636554 ]
 [-0.10685021 -0.03106126  0.04896244 ...  0.84499526  0.68242884
   0.54703045]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.766550  0.599711  0.683796  ...  0.168184 -0.810767 -0.738577
1  0.762026  0.774740  0.624559  ...  0.521746  0.512383  0.081228
2  0.187338 -0.662043 -0.361459  ... -0.561465  0.371915 -0.064570
3 -0.815319 -0.240640  0.206946  ...  0.025086  0.389251  0.199834
4 -0.366821 -0.623131 -0.356325  ... -0.141907 -0.628995  0.068047

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08343393 0.05663322 0.01879981 ... 0.8943983  0.800567   0.6458149 ]
 [0.08805735 0.06345897 0.02795638 ... 0.8432227  0.7580142  0.6147364 ]
 [0.08392814 0.05702488 0.0189848  ... 0.86770546 0.77699256 0.62747824]
 ...
 [0.08485875 0.05850341 0.0210679  ... 0.9849056  0.8720356  0.6944994 ]
 [0.08083524 0.05303704 0.01422881 ... 0.7940884  0.7181502  0.5871131 ]
 [0.08402991 0.0575744  0.02012827 ... 0.79264206 0.71564543 0.5840836 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.766550  0.599711  0.683796  ...  0.168184 -0.810767 -0.738577
1  0.762026  0.774740  0.624559  ...  0.521746  0.512383  0.081228
2  0.187338 -0.662043 -0.361459  ... -0.561465  0.371915 -0.064570
3 -0.815319 -0.240640  0.206946  ...  0.025086  0.389251  0.199834
4 -0.366821 -0.623131 -0.356325  ... -0.141907 -0.628995  0.068047

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09265128 0.06881054 0.03118028 ... 0.873019   0.79662716 0.6624477 ]
 [0.09398469 0.07087579 0.03366257 ... 0.84410775 0.7736194  0.64717996]
 [0.0898484  0.0639414  0.0242777  ... 0.8522748  0.77930796 0.6505021 ]
 ...
 [0.09220718 0.06772311 0.029036   ... 0.96198905 0.86526704 0.70685256]
 [0.0870965  0.06010683 0.02061726 ... 0.7886363  0.7294972  0.6178294 ]
 [0.08583644 0.057915   0.01750517 ... 0.78054464 0.72305286 0.61356056]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.766550  0.599711  0.683796  ...  0.168184 -0.810767 -0.738577
1  0.762026  0.774740  0.624559  ...  0.521746  0.512383  0.081228
2  0.187338 -0.662043 -0.361459  ... -0.561465  0.371915 -0.064570
3 -0.815319 -0.240640  0.206946  ...  0.025086  0.389251  0.199834
4 -0.366821 -0.623131 -0.356325  ... -0.141907 -0.628995  0.068047

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.65610895e-01  5.59947193e-02 -8.07243586e-03 ...  8.99432302e-01
   8.08127046e-01  6.58172548e-01]
 [ 1.63703069e-01  5.32737970e-02 -1.31232142e-02 ...  8.46777737e-01
   7.68189192e-01  6.31110787e-01]
 [ 1.69757441e-01  6.27431870e-02 -3.78718972e-03 ...  8.63527715e-01
   7.75574446e-01  6.33110344e-01]
 ...
 [ 1.77215934e-01  7.40800798e-02  1.12430155e-02 ...  9.47151542e-01
   8.39687824e-01  6.76907599e-01]
 [ 1.70558274e-01  6.36337101e-02  5.36739826e-04 ...  7.77735829e-01
   7.12375402e-01  5.91429234e-01]
 [ 1.67507544e-01  5.91185689e-02 -6.17381930e-03 ...  7.90961027e-01
   7.21652150e-01  5.97263038e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.766550  0.599711  0.683796  ...  0.168184 -0.810767 -0.738577
1  0.762026  0.774740  0.624559  ...  0.521746  0.512383  0.081228
2  0.187338 -0.662043 -0.361459  ... -0.561465  0.371915 -0.064570
3 -0.815319 -0.240640  0.206946  ...  0.025086  0.389251  0.199834
4 -0.366821 -0.623131 -0.356325  ... -0.141907 -0.628995  0.068047

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09322664 0.03568704 0.02056104 ... 0.89238083 0.7940093  0.6138959 ]
 [0.09734103 0.04206543 0.02871917 ... 0.83721805 0.75014126 0.5852839 ]
 [0.09028029 0.0308513  0.01352525 ... 0.86643565 0.7727411  0.5997832 ]
 ...
 [0.09458579 0.0376019  0.02239744 ... 0.9762875  0.8578905  0.6545329 ]
 [0.08809482 0.02787068 0.0109988  ... 0.7963898  0.71858263 0.5649781 ]
 [0.08499275 0.02279676 0.00367469 ... 0.8148624  0.7333528  0.5746597 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.766550  0.599711  0.683796  ...  0.168184 -0.810767 -0.738577
1  0.762026  0.774740  0.624559  ...  0.521746  0.512383  0.081228
2  0.187338 -0.662043 -0.361459  ... -0.561465  0.371915 -0.064570
3 -0.815319 -0.240640  0.206946  ...  0.025086  0.389251  0.199834
4 -0.366821 -0.623131 -0.356325  ... -0.141907 -0.628995  0.068047

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.11920524  0.05658466 -0.02063212 ...  0.8892174   0.7935591
   0.71911466]
 [ 0.12671039  0.06547415 -0.01110536 ...  0.8200356   0.74092627
   0.682281  ]
 [ 0.12664604  0.06428057 -0.01410389 ...  0.84608406  0.7589086
   0.6937627 ]
 ...
 [ 0.1269137   0.06534272 -0.01181489 ...  0.9610974   0.8461307
   0.7546395 ]
 [ 0.11460814  0.05078641 -0.0273836  ...  0.77835035  0.7083507
   0.65895855]
 [ 0.11277631  0.04757914 -0.03241503 ...  0.7860924   0.71382385
   0.6625394 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.766550  0.599711  0.683796  ...  0.168184 -0.810767 -0.738577
1  0.762026  0.774740  0.624559  ...  0.521746  0.512383  0.081228
2  0.187338 -0.662043 -0.361459  ... -0.561465  0.371915 -0.064570
3 -0.815319 -0.240640  0.206946  ...  0.025086  0.389251  0.199834
4 -0.366821 -0.623131 -0.356325  ... -0.141907 -0.628995  0.068047

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.16725567 0.09111902 0.00532579 ... 0.91749465 0.8137039  0.65393496]
 [0.16712965 0.09038994 0.00370798 ... 0.86395776 0.77044785 0.6232066 ]
 [0.17423388 0.1003814  0.0166584  ... 0.87411916 0.7743706  0.623549  ]
 ...
 [0.17665389 0.10432601 0.02245426 ... 0.98231506 0.8612838  0.6849946 ]
 [0.16639759 0.08958954 0.00288647 ... 0.7982034  0.71587807 0.5836231 ]
 [0.17710909 0.10524237 0.02392575 ... 0.8278239  0.7376218  0.59781766]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.766550  0.599711  0.683796  ...  0.168184 -0.810767 -0.738577
1  0.762026  0.774740  0.624559  ...  0.521746  0.512383  0.081228
2  0.187338 -0.662043 -0.361459  ... -0.561465  0.371915 -0.064570
3 -0.815319 -0.240640  0.206946  ...  0.025086  0.389251  0.199834
4 -0.366821 -0.623131 -0.356325  ... -0.141907 -0.628995  0.068047

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.1050269   0.04727633 -0.02311853 ...  0.9003229   0.82249546
   0.67717487]
 [ 0.10608381  0.04880899 -0.02093303 ...  0.8413621   0.7764169
   0.64564604]
 [ 0.10807899  0.05122772 -0.01823509 ...  0.8665967   0.79427135
   0.6568521 ]
 ...
 [ 0.10543908  0.04772122 -0.02267689 ...  0.96517324  0.87244976
   0.7110075 ]
 [ 0.10496753  0.04765496 -0.02189061 ...  0.77782476  0.7238538
   0.6080253 ]
 [ 0.0851144   0.01940183 -0.06078053 ...  0.8306416   0.7677568
   0.6395036 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.766550  0.599711  0.683796  ...  0.168184 -0.810767 -0.738577
1  0.762026  0.774740  0.624559  ...  0.521746  0.512383  0.081228
2  0.187338 -0.662043 -0.361459  ... -0.561465  0.371915 -0.064570
3 -0.815319 -0.240640  0.206946  ...  0.025086  0.389251  0.199834
4 -0.366821 -0.623131 -0.356325  ... -0.141907 -0.628995  0.068047

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.1198257e-01  1.3175786e-02  4.8846006e-05 ...  8.6862326e-01
   8.5323960e-01  7.8198355e-01]
 [ 1.1108498e-01  1.1190444e-02 -3.1449497e-03 ...  8.0940139e-01
   8.0363518e-01  7.4642015e-01]
 [ 1.1498593e-01  1.9245267e-02  8.7732077e-03 ...  8.3129913e-01
   8.1726122e-01  7.5477517e-01]
 ...
 [ 1.1514330e-01  1.9675821e-02  9.6296072e-03 ...  9.5037520e-01
   9.1785914e-01  8.2740462e-01]
 [ 1.1330855e-01  1.6029686e-02  4.5465827e-03 ...  7.4225426e-01
   7.4423575e-01  7.0258498e-01]
 [ 1.1023426e-01  9.4105005e-03 -5.7981908e-03 ...  7.5900519e-01
   7.5788927e-01  7.1237278e-01]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.2393e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaa8fc9c90>, <FrEIA.framework.Node object at 0x7faaa8fcc2d0>, <FrEIA.framework.Node object at 0x7fab7c626b50>, <FrEIA.framework.Node object at 0x7faaa8fa0390>, <FrEIA.framework.Node object at 0x7fab94085f50>, <FrEIA.framework.Node object at 0x7faaa9fedc90>, <FrEIA.framework.Node object at 0x7faaa9fed190>, <FrEIA.framework.Node object at 0x7faaab2e9350>, <FrEIA.framework.Node object at 0x7faaaf321f10>, <FrEIA.framework.Node object at 0x7faab5ded810>, <FrEIA.framework.Node object at 0x7faab5ded3d0>, <FrEIA.framework.Node object at 0x7fab94012550>, <FrEIA.framework.Node object at 0x7fab94012b10>, <FrEIA.framework.Node object at 0x7fab94012ad0>, <FrEIA.framework.Node object at 0x7fab94012e50>, <FrEIA.framework.Node object at 0x7fab94012410>, <FrEIA.framework.Node object at 0x7fab94012850>, <FrEIA.framework.OutputNode object at 0x7fab94012490>, <FrEIA.framework.ConditionNode object at 0x7faaa8fc9ed0>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'coupling_6' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_6' takes the following inputs:
	 Output #0 of node 'coupling_6' with dims (14,)

Node 'coupling_7' takes the following inputs:
	 Output #0 of node 'permute_6' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_7' takes the following inputs:
	 Output #0 of node 'coupling_7' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_7' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (14): PermuteRandom()
    (15): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (16): PermuteRandom()
    (17): dummy()
    (18): None
  )
)
Yang/Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005
number of trainable parameters is :
6000864
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm6.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.955789  0.189580  0.468993  ... -0.375169 -0.257607 -0.301809
1  0.756316  1.008490  0.434073  ... -0.432258 -0.664252  1.420657
2  0.065725 -0.629246  0.448836  ... -1.086151 -0.155620  0.317532
3 -0.705242 -0.137080  0.642679  ...  1.766962  0.422138 -0.290244
4 -0.291851 -0.849032  0.533176  ... -0.426624 -0.173083 -0.232975

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.05869761 0.04883221 0.0370755  ... 0.97085315 0.857514   0.6681771 ]
 [0.06081322 0.05194239 0.0411472  ... 0.8562988  0.76121175 0.5969649 ]
 [0.06114189 0.05263745 0.04236498 ... 0.88009626 0.7803331  0.61050683]
 ...
 [0.06128297 0.052817   0.04256333 ... 0.9704085  0.85488504 0.6646471 ]
 [0.06133239 0.05289695 0.04266825 ... 0.7469004  0.6693817  0.529321  ]
 [0.06326231 0.05619624 0.04766797 ... 0.7747469  0.692256   0.54582936]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.955789  0.189580  0.468993  ... -0.375169 -0.257607 -0.301809
1  0.756316  1.008490  0.434073  ... -0.432258 -0.664252  1.420657
2  0.065725 -0.629246  0.448836  ... -1.086151 -0.155620  0.317532
3 -0.705242 -0.137080  0.642679  ...  1.766962  0.422138 -0.290244
4 -0.291851 -0.849032  0.533176  ... -0.426624 -0.173083 -0.232975

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.11134253 -0.03828651  0.03749663 ...  1.0224894   0.83291245
   0.6687275 ]
 [-0.11012906 -0.03647521  0.04018924 ...  0.91382015  0.73895454
   0.5915915 ]
 [-0.11271593 -0.04059765  0.03369814 ...  0.93602717  0.7596892
   0.60955215]
 ...
 [-0.10835825 -0.03351679  0.04502857 ...  1.0146768   0.8204713
   0.65503764]
 [-0.1108769  -0.0376634   0.03833166 ...  0.7914845   0.6405543
   0.5153409 ]
 [-0.10945298 -0.03532329  0.0421122  ...  0.82960296  0.67062986
   0.538267  ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.955789  0.189580  0.468993  ... -0.375169 -0.257607 -0.301809
1  0.756316  1.008490  0.434073  ... -0.432258 -0.664252  1.420657
2  0.065725 -0.629246  0.448836  ... -1.086151 -0.155620  0.317532
3 -0.705242 -0.137080  0.642679  ...  1.766962  0.422138 -0.290244
4 -0.291851 -0.849032  0.533176  ... -0.426624 -0.173083 -0.232975

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08187524 0.05440112 0.01587079 ... 0.9503852  0.84652317 0.67868614]
 [0.08483035 0.05844302 0.02097111 ... 0.8468587  0.7606002  0.61639327]
 [0.08213245 0.05449754 0.01572017 ... 0.86588186 0.7761631  0.62750417]
 ...
 [0.08679675 0.06149566 0.02521622 ... 0.9404204  0.8356316  0.668535  ]
 [0.08392355 0.05726349 0.01955505 ... 0.7259513  0.6612009  0.54540217]
 [0.0844426  0.05815082 0.02086512 ... 0.7676947  0.69509256 0.569298  ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.955789  0.189580  0.468993  ... -0.375169 -0.257607 -0.301809
1  0.756316  1.008490  0.434073  ... -0.432258 -0.664252  1.420657
2  0.065725 -0.629246  0.448836  ... -1.086151 -0.155620  0.317532
3 -0.705242 -0.137080  0.642679  ...  1.766962  0.422138 -0.290244
4 -0.291851 -0.849032  0.533176  ... -0.426624 -0.173083 -0.232975

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08984672 0.06436017 0.02568407 ... 0.9177073  0.83182776 0.6856308 ]
 [0.08600877 0.05784409 0.01670732 ... 0.84360576 0.77317166 0.64683425]
 [0.08865462 0.06213316 0.02221845 ... 0.85026336 0.77761054 0.6493186 ]
 ...
 [0.08969852 0.06377012 0.02422699 ... 0.9360477  0.84504104 0.6936462 ]
 [0.09071572 0.06546049 0.0263924  ... 0.7232398  0.67739916 0.58321095]
 [0.09161986 0.06705545 0.02872936 ... 0.7543565  0.7017801  0.5992019 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.955789  0.189580  0.468993  ... -0.375169 -0.257607 -0.301809
1  0.756316  1.008490  0.434073  ... -0.432258 -0.664252  1.420657
2  0.065725 -0.629246  0.448836  ... -1.086151 -0.155620  0.317532
3 -0.705242 -0.137080  0.642679  ...  1.766962  0.422138 -0.290244
4 -0.291851 -0.849032  0.533176  ... -0.426624 -0.173083 -0.232975

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.7023362e-01  6.3210070e-02 -1.2299418e-04 ...  9.2418790e-01
   8.2493126e-01  6.6842520e-01]
 [ 1.6593221e-01  5.6688011e-02 -9.2829764e-03 ...  8.3593589e-01
   7.5824571e-01  6.2343824e-01]
 [ 1.6781683e-01  5.9654444e-02 -6.4438283e-03 ...  8.5673362e-01
   7.7162147e-01  6.3110828e-01]
 ...
 [ 1.6755545e-01  5.9312493e-02 -6.9544613e-03 ...  9.4285160e-01
   8.3668977e-01  6.7502546e-01]
 [ 1.7098263e-01  6.4535737e-02 -9.7540021e-04 ...  7.1227205e-01
   6.6087699e-01  5.5551952e-01]
 [ 1.7467155e-01  7.0208192e-02  6.1005056e-03 ...  7.3685527e-01
   6.7913151e-01  5.6764370e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.955789  0.189580  0.468993  ... -0.375169 -0.257607 -0.301809
1  0.756316  1.008490  0.434073  ... -0.432258 -0.664252  1.420657
2  0.065725 -0.629246  0.448836  ... -1.086151 -0.155620  0.317532
3 -0.705242 -0.137080  0.642679  ...  1.766962  0.422138 -0.290244
4 -0.291851 -0.849032  0.533176  ... -0.426624 -0.173083 -0.232975

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09258682 0.03486855 0.02005547 ... 0.9265413  0.8213401  0.631787  ]
 [0.09095025 0.03191738 0.01497622 ... 0.856598   0.7653589  0.59512794]
 [0.09198025 0.03367636 0.01773769 ... 0.8599794  0.767686   0.59650946]
 ...
 [0.09475261 0.03788824 0.02284878 ... 0.9440111  0.8326278  0.6381992 ]
 [0.0916483  0.03313781 0.01698877 ... 0.72689986 0.662562   0.52815413]
 [0.09219931 0.03407829 0.01846051 ... 0.7556277  0.6851958  0.5428501 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.955789  0.189580  0.468993  ... -0.375169 -0.257607 -0.301809
1  0.756316  1.008490  0.434073  ... -0.432258 -0.664252  1.420657
2  0.065725 -0.629246  0.448836  ... -1.086151 -0.155620  0.317532
3 -0.705242 -0.137080  0.642679  ...  1.766962  0.422138 -0.290244
4 -0.291851 -0.849032  0.533176  ... -0.426624 -0.173083 -0.232975

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.1234498   0.06218073 -0.01375356 ...  0.9208284   0.8174339
   0.7357205 ]
 [ 0.11821535  0.05411771 -0.02527323 ...  0.84719443  0.7610704
   0.69606584]
 [ 0.12379396  0.06137517 -0.01648206 ...  0.84961694  0.76180714
   0.6959179 ]
 ...
 [ 0.12662402  0.06488413 -0.01248035 ...  0.92901313  0.8217121
   0.7375444 ]
 [ 0.12533486  0.06329766 -0.01428807 ...  0.72031415  0.6632534
   0.62683   ]
 [ 0.1254327   0.06369933 -0.01340708 ...  0.75478196  0.6891154
   0.6447144 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.955789  0.189580  0.468993  ... -0.375169 -0.257607 -0.301809
1  0.756316  1.008490  0.434073  ... -0.432258 -0.664252  1.420657
2  0.065725 -0.629246  0.448836  ... -1.086151 -0.155620  0.317532
3 -0.705242 -0.137080  0.642679  ...  1.766962  0.422138 -0.290244
4 -0.291851 -0.849032  0.533176  ... -0.426624 -0.173083 -0.232975

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.1774579  0.10598263 0.02522108 ... 0.9449235  0.83300596 0.6660143 ]
 [0.17757936 0.10592049 0.02488291 ... 0.83773863 0.74701536 0.6052855 ]
 [0.17103393 0.09571168 0.01037458 ... 0.867319   0.7697332  0.6207401 ]
 ...
 [0.17794685 0.10613322 0.02476451 ... 0.9398222  0.82704735 0.6607307 ]
 [0.17278531 0.09838322 0.01409179 ... 0.7356512  0.663576   0.5454664 ]
 [0.17320073 0.09889755 0.01466069 ... 0.75255406 0.6767165  0.55450594]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.955789  0.189580  0.468993  ... -0.375169 -0.257607 -0.301809
1  0.756316  1.008490  0.434073  ... -0.432258 -0.664252  1.420657
2  0.065725 -0.629246  0.448836  ... -1.086151 -0.155620  0.317532
3 -0.705242 -0.137080  0.642679  ...  1.766962  0.422138 -0.290244
4 -0.291851 -0.849032  0.533176  ... -0.426624 -0.173083 -0.232975

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.1108837   0.05600908 -0.01047045 ...  0.92167723  0.8394356
   0.6889401 ]
 [ 0.10320526  0.0442988  -0.02778476 ...  0.8437618   0.7772161
   0.6455865 ]
 [ 0.10873316  0.05229421 -0.01654831 ...  0.845158    0.77711475
   0.6448934 ]
 ...
 [ 0.11290559  0.05833016 -0.00808251 ...  0.9327911   0.84608305
   0.6923857 ]
 [ 0.10532476  0.04733025 -0.02358592 ...  0.71932393  0.6764059
   0.5745915 ]
 [ 0.10521597  0.0475     -0.02284381 ...  0.74722624  0.6985949
   0.59001887]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.955789  0.189580  0.468993  ... -0.375169 -0.257607 -0.301809
1  0.756316  1.008490  0.434073  ... -0.432258 -0.664252  1.420657
2  0.065725 -0.629246  0.448836  ... -1.086151 -0.155620  0.317532
3 -0.705242 -0.137080  0.642679  ...  1.766962  0.422138 -0.290244
4 -0.291851 -0.849032  0.533176  ... -0.426624 -0.173083 -0.232975

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.11503296 0.01960799 0.00985926 ... 0.89561594 0.87475336 0.79727054]
 [0.11890756 0.02763677 0.02174279 ... 0.8112041  0.8021428  0.74430555]
 [0.11518104 0.01974231 0.00971705 ... 0.8161974  0.80506516 0.74616575]
 ...
 [0.11668874 0.02291617 0.01452956 ... 0.911943   0.88480115 0.8033709 ]
 [0.11615606 0.02176684 0.01270562 ... 0.6726177  0.683167   0.6578351 ]
 [0.1159974  0.02149346 0.01244062 ... 0.71164787 0.7157584  0.68130153]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.2626e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaa88a3390>, <FrEIA.framework.Node object at 0x7faaa88a37d0>, <FrEIA.framework.Node object at 0x7faaaa9c59d0>, <FrEIA.framework.Node object at 0x7faaa88a3f50>, <FrEIA.framework.Node object at 0x7faaa88a3810>, <FrEIA.framework.Node object at 0x7faaa88a3910>, <FrEIA.framework.Node object at 0x7faaa88a3050>, <FrEIA.framework.Node object at 0x7faaa88a33d0>, <FrEIA.framework.Node object at 0x7faaab969490>, <FrEIA.framework.Node object at 0x7faaa88ac050>, <FrEIA.framework.Node object at 0x7faaa88ac250>, <FrEIA.framework.Node object at 0x7faaa88ac850>, <FrEIA.framework.Node object at 0x7faaa88b1f50>, <FrEIA.framework.Node object at 0x7faaa88b1990>, <FrEIA.framework.Node object at 0x7faaa88b1e90>, <FrEIA.framework.Node object at 0x7faaab969f90>, <FrEIA.framework.Node object at 0x7faaab969ed0>, <FrEIA.framework.OutputNode object at 0x7fab94047e90>, <FrEIA.framework.ConditionNode object at 0x7faab55ca850>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'coupling_6' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_6' takes the following inputs:
	 Output #0 of node 'coupling_6' with dims (14,)

Node 'coupling_7' takes the following inputs:
	 Output #0 of node 'permute_6' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_7' takes the following inputs:
	 Output #0 of node 'coupling_7' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_7' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (14): PermuteRandom()
    (15): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (16): PermuteRandom()
    (17): dummy()
    (18): None
  )
)
Yang/Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005
number of trainable parameters is :
6000864
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm6.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.907916  0.285124  0.805873  ... -0.302125 -0.775245 -1.067647
1  0.558312  1.006252  0.179959  ...  0.685650  0.445359 -0.622751
2  0.102533 -0.531192 -0.692542  ...  0.543730 -0.025890 -0.465574
3 -0.701065 -0.281475 -0.466258  ...  1.366192 -0.760208 -0.133455
4 -0.301739 -0.960754  1.320492  ...  0.297624  0.262116  0.370494

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.0633633  0.0563022  0.04775244 ... 0.94782    0.83641195 0.65134996]
 [0.05949539 0.04958802 0.03744294 ... 0.84976226 0.7559892  0.5932379 ]
 [0.06284641 0.05537142 0.0462783  ... 0.91227883 0.8047677  0.6268475 ]
 ...
 [0.06079594 0.05205959 0.04150557 ... 0.97908163 0.8619687  0.6697816 ]
 [0.05902807 0.04930894 0.03768222 ... 0.7667056  0.68712693 0.54319006]
 [0.06261545 0.0551483  0.04615277 ... 0.75665355 0.67763555 0.5354397 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.907916  0.285124  0.805873  ... -0.302125 -0.775245 -1.067647
1  0.558312  1.006252  0.179959  ...  0.685650  0.445359 -0.622751
2  0.102533 -0.531192 -0.692542  ...  0.543730 -0.025890 -0.465574
3 -0.701065 -0.281475 -0.466258  ...  1.366192 -0.760208 -0.133455
4 -0.301739 -0.960754  1.320492  ...  0.297624  0.262116  0.370494

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10610491 -0.02990234  0.05074972 ...  0.9696212   0.7826911
   0.6247245 ]
 [-0.11017822 -0.03656811  0.04002282 ...  0.8882487   0.7195457
   0.57729185]
 [-0.10817607 -0.03328332  0.04532698 ...  0.9516287   0.76365066
   0.6069914 ]
 ...
 [-0.10956497 -0.03545946  0.04194579 ...  1.0240719   0.8292123
   0.6625979 ]
 [-0.10925083 -0.03491023  0.04287204 ...  0.81074595  0.65897155
   0.53154635]
 [-0.10879695 -0.0342553   0.04382572 ...  0.80341196  0.6504098
   0.52315056]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.907916  0.285124  0.805873  ... -0.302125 -0.775245 -1.067647
1  0.558312  1.006252  0.179959  ...  0.685650  0.445359 -0.622751
2  0.102533 -0.531192 -0.692542  ...  0.543730 -0.025890 -0.465574
3 -0.701065 -0.281475 -0.466258  ...  1.366192 -0.760208 -0.133455
4 -0.301739 -0.960754  1.320492  ...  0.297624  0.262116  0.370494

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08472615 0.05842201 0.02107163 ... 0.93076193 0.82908213 0.6650008 ]
 [0.08790755 0.06298187 0.02705172 ... 0.82994676 0.7462673  0.60567147]
 [0.08485018 0.05851386 0.02110666 ... 0.89448166 0.79702526 0.64033586]
 ...
 [0.08478039 0.0585276  0.02124288 ... 0.95119345 0.8446613  0.675235  ]
 [0.08316674 0.0564312  0.01873421 ... 0.752596   0.6837724  0.56217337]
 [0.08497681 0.05899279 0.02204929 ... 0.7510845  0.6815978  0.55977184]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.907916  0.285124  0.805873  ... -0.302125 -0.775245 -1.067647
1  0.558312  1.006252  0.179959  ...  0.685650  0.445359 -0.622751
2  0.102533 -0.531192 -0.692542  ...  0.543730 -0.025890 -0.465574
3 -0.701065 -0.281475 -0.466258  ...  1.366192 -0.760208 -0.133455
4 -0.301739 -0.960754  1.320492  ...  0.297624  0.262116  0.370494

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.0939379  0.07066733 0.0330942  ... 0.8867849  0.8067893  0.668766  ]
 [0.09214604 0.06755158 0.02863856 ... 0.82464194 0.75813854 0.6369024 ]
 [0.09358674 0.06994778 0.03187215 ... 0.8648187  0.78778946 0.65530074]
 ...
 [0.09110013 0.06607561 0.02723998 ... 0.9360695  0.84483826 0.69338226]
 [0.08599146 0.05815238 0.01777616 ... 0.7414042  0.6923384  0.5933957 ]
 [0.09003969 0.06455031 0.02562469 ... 0.7440562  0.69384277 0.5940684 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.907916  0.285124  0.805873  ... -0.302125 -0.775245 -1.067647
1  0.558312  1.006252  0.179959  ...  0.685650  0.445359 -0.622751
2  0.102533 -0.531192 -0.692542  ...  0.543730 -0.025890 -0.465574
3 -0.701065 -0.281475 -0.466258  ...  1.366192 -0.760208 -0.133455
4 -0.301739 -0.960754  1.320492  ...  0.297624  0.262116  0.370494

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.7214501e-01  6.6254973e-02  2.2325218e-03 ...  9.0367502e-01
   8.0830014e-01  6.5656227e-01]
 [ 1.7183469e-01  6.5821916e-02  8.0966949e-04 ...  8.2843894e-01
   7.5183475e-01  6.1867702e-01]
 [ 1.7776135e-01  7.5205654e-02  9.9586844e-03 ...  8.7315214e-01
   7.7827346e-01  6.3237000e-01]
 ...
 [ 1.7314431e-01  6.7876905e-02  3.4068227e-03 ...  9.3332016e-01
   8.2822454e-01  6.6860622e-01]
 [ 1.6631861e-01  5.7296216e-02 -8.5062683e-03 ...  7.4016285e-01
   6.8336272e-01  5.7148892e-01]
 [ 1.6598716e-01  5.6851596e-02 -9.9694133e-03 ...  7.3499191e-01
   6.7893851e-01  5.6820107e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.907916  0.285124  0.805873  ... -0.302125 -0.775245 -1.067647
1  0.558312  1.006252  0.179959  ...  0.685650  0.445359 -0.622751
2  0.102533 -0.531192 -0.692542  ...  0.543730 -0.025890 -0.465574
3 -0.701065 -0.281475 -0.466258  ...  1.366192 -0.760208 -0.133455
4 -0.301739 -0.960754  1.320492  ...  0.297624  0.262116  0.370494

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09191839 0.03355242 0.01748893 ... 0.90762234 0.8054528  0.6211149 ]
 [0.09253211 0.0343076  0.01784493 ... 0.8270178  0.7421651  0.5801265 ]
 [0.09246814 0.03432682 0.01823784 ... 0.8832208  0.78409255 0.6064379 ]
 ...
 [0.09182525 0.03336337 0.01710521 ... 0.95673764 0.8429736  0.6450234 ]
 [0.09076095 0.03194113 0.01601164 ... 0.7413658  0.6748372  0.5364469 ]
 [0.09279519 0.03506514 0.01992428 ... 0.7395373  0.67263126 0.53473353]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.907916  0.285124  0.805873  ... -0.302125 -0.775245 -1.067647
1  0.558312  1.006252  0.179959  ...  0.685650  0.445359 -0.622751
2  0.102533 -0.531192 -0.692542  ...  0.543730 -0.025890 -0.465574
3 -0.701065 -0.281475 -0.466258  ...  1.366192 -0.760208 -0.133455
4 -0.301739 -0.960754  1.320492  ...  0.297624  0.262116  0.370494

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12907982  0.06890842 -0.00645703 ...  0.902054    0.8022147
   0.72450674]
 [ 0.1305682   0.0699009  -0.00659299 ...  0.8146801   0.7364181
   0.6788647 ]
 [ 0.13488021  0.07484764 -0.00152007 ...  0.86666405  0.7720528
   0.7014517 ]
 ...
 [ 0.12593663  0.06417993 -0.01306507 ...  0.9228967   0.8169396
   0.7341317 ]
 [ 0.12005639  0.05714816 -0.02070537 ...  0.7334296   0.67390263
   0.6346875 ]
 [ 0.12546939  0.06405815 -0.01253951 ...  0.72833097  0.66948545
   0.6312723 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.907916  0.285124  0.805873  ... -0.302125 -0.775245 -1.067647
1  0.558312  1.006252  0.179959  ...  0.685650  0.445359 -0.622751
2  0.102533 -0.531192 -0.692542  ...  0.543730 -0.025890 -0.465574
3 -0.701065 -0.281475 -0.466258  ...  1.366192 -0.760208 -0.133455
4 -0.301739 -0.960754  1.320492  ...  0.297624  0.262116  0.370494

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.1757873  0.10324168 0.02119979 ... 0.9258351  0.817203   0.6545707 ]
 [0.17420828 0.10052922 0.01710486 ... 0.8300342  0.74120843 0.6013983 ]
 [0.18008499 0.1084747  0.02698934 ... 0.89020395 0.7833024  0.6275766 ]
 ...
 [0.17359145 0.09949365 0.01551911 ... 0.96180737 0.84461176 0.6730908 ]
 [0.16738644 0.09074667 0.00412098 ... 0.75605905 0.68178535 0.55938137]
 [0.17340983 0.09929124 0.01529175 ... 0.7421126  0.66838753 0.548651  ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.907916  0.285124  0.805873  ... -0.302125 -0.775245 -1.067647
1  0.558312  1.006252  0.179959  ...  0.685650  0.445359 -0.622751
2  0.102533 -0.531192 -0.692542  ...  0.543730 -0.025890 -0.465574
3 -0.701065 -0.281475 -0.466258  ...  1.366192 -0.760208 -0.133455
4 -0.301739 -0.960754  1.320492  ...  0.297624  0.262116  0.370494

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.11070168  0.05510096 -0.01268417 ...  0.88662004  0.8106222
   0.6684307 ]
 [ 0.10783596  0.05064361 -0.0194051  ...  0.8153194   0.75466967
   0.6299932 ]
 [ 0.10925774  0.0527724  -0.01626402 ...  0.8796536   0.8017609
   0.66050357]
 ...
 [ 0.11036718  0.05475514 -0.0129514  ...  0.9270265   0.8414756
   0.68916446]
 [ 0.0997013   0.04006401 -0.03247428 ...  0.74772954  0.7004992
   0.5921341 ]
 [ 0.10492091  0.0471355  -0.02327177 ...  0.7393311   0.6925322
   0.58592725]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.907916  0.285124  0.805873  ... -0.302125 -0.775245 -1.067647
1  0.558312  1.006252  0.179959  ...  0.685650  0.445359 -0.622751
2  0.102533 -0.531192 -0.692542  ...  0.543730 -0.025890 -0.465574
3 -0.701065 -0.281475 -0.466258  ...  1.366192 -0.760208 -0.133455
4 -0.301739 -0.960754  1.320492  ...  0.297624  0.262116  0.370494

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[1.15976855e-01 2.14703679e-02 1.24174356e-02 ... 8.59694839e-01
  8.42978716e-01 7.73840725e-01]
 [1.12872183e-01 1.48277581e-02 2.09563971e-03 ... 7.95701265e-01
  7.90675759e-01 7.36592293e-01]
 [1.14649579e-01 1.84154510e-02 7.28201866e-03 ... 8.52363467e-01
  8.30981195e-01 7.63384342e-01]
 ...
 [1.15931436e-01 2.13182569e-02 1.20969117e-02 ... 9.18556929e-01
  8.89932036e-01 8.06929767e-01]
 [1.12005398e-01 1.31932497e-02 6.60121441e-05 ... 7.04509854e-01
  7.12179780e-01 6.79447889e-01]
 [1.14823580e-01 1.90343857e-02 8.72650743e-03 ... 6.98343217e-01
  7.04964340e-01 6.73635006e-01]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.2950e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaae292910>, <FrEIA.framework.Node object at 0x7faaae292bd0>, <FrEIA.framework.Node object at 0x7faaae292ad0>, <FrEIA.framework.Node object at 0x7faaae2924d0>, <FrEIA.framework.Node object at 0x7faaae292c90>, <FrEIA.framework.Node object at 0x7faaae292750>, <FrEIA.framework.Node object at 0x7faaae292090>, <FrEIA.framework.Node object at 0x7faaaeb2d710>, <FrEIA.framework.Node object at 0x7faaaeb2d1d0>, <FrEIA.framework.Node object at 0x7faaaeb2d250>, <FrEIA.framework.Node object at 0x7fab7c7092d0>, <FrEIA.framework.Node object at 0x7faaafc4ecd0>, <FrEIA.framework.Node object at 0x7faaa88abb50>, <FrEIA.framework.Node object at 0x7faaa88ab750>, <FrEIA.framework.Node object at 0x7fab95c8bcd0>, <FrEIA.framework.Node object at 0x7faaaa9dd5d0>, <FrEIA.framework.Node object at 0x7faab40ba150>, <FrEIA.framework.Node object at 0x7faab55d5990>, <FrEIA.framework.Node object at 0x7faab408a2d0>, <FrEIA.framework.OutputNode object at 0x7faaad9d6090>, <FrEIA.framework.ConditionNode object at 0x7faaae292590>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'coupling_6' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_6' takes the following inputs:
	 Output #0 of node 'coupling_6' with dims (14,)

Node 'coupling_7' takes the following inputs:
	 Output #0 of node 'permute_6' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_7' takes the following inputs:
	 Output #0 of node 'coupling_7' with dims (14,)

Node 'coupling_8' takes the following inputs:
	 Output #0 of node 'permute_7' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_8' takes the following inputs:
	 Output #0 of node 'coupling_8' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_8' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (14): PermuteRandom()
    (15): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (16): PermuteRandom()
    (17): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (18): PermuteRandom()
    (19): dummy()
    (20): None
  )
)
Yang/Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005
number of trainable parameters is :
6750972
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm6.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.020716  0.237406  0.199562  ...  1.411254  1.310903  0.894023
1  0.468636  1.003791 -0.113744  ... -0.446386 -0.740531 -0.024110
2  0.156091 -0.455208 -0.653928  ... -0.091303  0.297346 -0.213459
3 -0.771806 -0.189399 -0.424863  ...  0.072679 -0.011597  0.060715
4 -0.522922 -0.875929 -0.543109  ...  1.624537  0.006467  0.658796

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06227532 0.05466387 0.04555673 ... 0.947441   0.8371545  0.65263945]
 [0.06460272 0.05829098 0.05059929 ... 0.84956414 0.75567627 0.5928976 ]
 [0.06275573 0.05512678 0.04579332 ... 0.9044729  0.7980207  0.62173325]
 ...
 [0.0630343  0.05559156 0.04648343 ... 1.0073837  0.8845437  0.6856196 ]
 [0.063901   0.05717357 0.04900617 ... 0.77159685 0.68920094 0.54327774]
 [0.06540361 0.0596463  0.05264349 ... 0.83446395 0.741119   0.58094484]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.020716  0.237406  0.199562  ...  1.411254  1.310903  0.894023
1  0.468636  1.003791 -0.113744  ... -0.446386 -0.740531 -0.024110
2  0.156091 -0.455208 -0.653928  ... -0.091303  0.297346 -0.213459
3 -0.771806 -0.189399 -0.424863  ...  0.072679 -0.011597  0.060715
4 -0.522922 -0.875929 -0.543109  ...  1.624537  0.006467  0.658796

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10764731 -0.03237948  0.04682207 ...  0.98138666  0.79382086
   0.63445497]
 [-0.1098181  -0.0359329   0.04110676 ...  0.8991159   0.731024
   0.5879868 ]
 [-0.10849464 -0.03382453  0.04442939 ...  0.9444381   0.7569375
   0.6011734 ]
 ...
 [-0.10985583 -0.0360032   0.0409838  ...  1.0598255   0.8557205
   0.68165314]
 [-0.10622743 -0.03010547  0.05042511 ...  0.819536    0.65953386
   0.527683  ]
 [-0.10457355 -0.02741474  0.05473086 ...  0.8441788   0.67776287
   0.54076207]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.020716  0.237406  0.199562  ...  1.411254  1.310903  0.894023
1  0.468636  1.003791 -0.113744  ... -0.446386 -0.740531 -0.024110
2  0.156091 -0.455208 -0.653928  ... -0.091303  0.297346 -0.213459
3 -0.771806 -0.189399 -0.424863  ...  0.072679 -0.011597  0.060715
4 -0.522922 -0.875929 -0.543109  ...  1.624537  0.006467  0.658796

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08220924 0.05477033 0.01623883 ... 0.93216693 0.83116585 0.66737175]
 [0.08621311 0.06060328 0.02398849 ... 0.83164614 0.7487169  0.608301  ]
 [0.0848317  0.05842455 0.02092527 ... 0.8790009  0.7844767  0.63146675]
 ...
 [0.08472317 0.05815514 0.02044632 ... 0.9920954  0.8773959  0.6978989 ]
 [0.08695234 0.06183049 0.0257735  ... 0.7652928  0.6923696  0.5666442 ]
 [0.08581041 0.06008555 0.02337559 ... 0.78196555 0.7062873  0.57678306]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.020716  0.237406  0.199562  ...  1.411254  1.310903  0.894023
1  0.468636  1.003791 -0.113744  ... -0.446386 -0.740531 -0.024110
2  0.156091 -0.455208 -0.653928  ... -0.091303  0.297346 -0.213459
3 -0.771806 -0.189399 -0.424863  ...  0.072679 -0.011597  0.060715
4 -0.522922 -0.875929 -0.543109  ...  1.624537  0.006467  0.658796

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09073673 0.06567082 0.02710134 ... 0.89967895 0.8174435  0.67605495]
 [0.09344196 0.06978685 0.03178497 ... 0.82145786 0.7558825  0.6355592 ]
 [0.09466475 0.07163705 0.03390998 ... 0.87290967 0.7939564  0.65924394]
 ...
 [0.09233387 0.06781068 0.02888763 ... 0.96250224 0.8655437  0.7069615 ]
 [0.09282029 0.06888252 0.03081563 ... 0.752385   0.69999295 0.59789795]
 [0.09412785 0.07096449 0.03344372 ... 0.783116   0.7241545  0.6137882 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.020716  0.237406  0.199562  ...  1.411254  1.310903  0.894023
1  0.468636  1.003791 -0.113744  ... -0.446386 -0.740531 -0.024110
2  0.156091 -0.455208 -0.653928  ... -0.091303  0.297346 -0.213459
3 -0.771806 -0.189399 -0.424863  ...  0.072679 -0.011597  0.060715
4 -0.522922 -0.875929 -0.543109  ...  1.624537  0.006467  0.658796

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17158309 0.06537995 0.00133592 ... 0.9067284  0.81097466 0.6585777 ]
 [0.17501031 0.07067138 0.00699836 ... 0.82272774 0.74756885 0.6158177 ]
 [0.17554672 0.07181221 0.0056321  ... 0.8598805  0.7687746  0.6262509 ]
 ...
 [0.17717084 0.07400468 0.01098511 ... 0.9646729  0.85176396 0.684415  ]
 [0.17677988 0.07346052 0.00981849 ... 0.73891735 0.6799598  0.5677922 ]
 [0.17839123 0.07594925 0.01310992 ... 0.7577964  0.6947746  0.5780895 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.020716  0.237406  0.199562  ...  1.411254  1.310903  0.894023
1  0.468636  1.003791 -0.113744  ... -0.446386 -0.740531 -0.024110
2  0.156091 -0.455208 -0.653928  ... -0.091303  0.297346 -0.213459
3 -0.771806 -0.189399 -0.424863  ...  0.072679 -0.011597  0.060715
4 -0.522922 -0.875929 -0.543109  ...  1.624537  0.006467  0.658796

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09125051 0.03258368 0.01645872 ... 0.9149157  0.8119124  0.62557346]
 [0.09570736 0.03943814 0.02506697 ... 0.8234892  0.7394584  0.5783967 ]
 [0.09149753 0.03277048 0.01608187 ... 0.88087475 0.78223944 0.60523295]
 ...
 [0.09602208 0.03978279 0.02505077 ... 0.9850606  0.863943   0.65813756]
 [0.09445065 0.03753167 0.02276081 ... 0.76372147 0.690769   0.5461736 ]
 [0.09363288 0.03616747 0.02069926 ... 0.8122262  0.729092   0.5710969 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.020716  0.237406  0.199562  ...  1.411254  1.310903  0.894023
1  0.468636  1.003791 -0.113744  ... -0.446386 -0.740531 -0.024110
2  0.156091 -0.455208 -0.653928  ... -0.091303  0.297346 -0.213459
3 -0.771806 -0.189399 -0.424863  ...  0.072679 -0.011597  0.060715
4 -0.522922 -0.875929 -0.543109  ...  1.624537  0.006467  0.658796

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12244901  0.06034744 -0.01671526 ...  0.9175726   0.8146004
   0.73352325]
 [ 0.13099113  0.07080865 -0.00499111 ...  0.82025826  0.7410401
   0.6823266 ]
 [ 0.1325815   0.07168031 -0.00559995 ...  0.8666695   0.7720852
   0.70149094]
 ...
 [ 0.12759537  0.06589553 -0.01161975 ...  0.97576225  0.85655177
   0.7614903 ]
 [ 0.13044575  0.07032111 -0.00525981 ...  0.7436105   0.6806284
   0.63878214]
 [ 0.12670442  0.06492281 -0.01252833 ...  0.790061    0.7157735
   0.6632623 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.020716  0.237406  0.199562  ...  1.411254  1.310903  0.894023
1  0.468636  1.003791 -0.113744  ... -0.446386 -0.740531 -0.024110
2  0.156091 -0.455208 -0.653928  ... -0.091303  0.297346 -0.213459
3 -0.771806 -0.189399 -0.424863  ...  0.072679 -0.011597  0.060715
4 -0.522922 -0.875929 -0.543109  ...  1.624537  0.006467  0.658796

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.1706791  0.09565592 0.01089457 ... 0.9251758  0.8179324  0.65580976]
 [0.17404437 0.10047781 0.01724154 ... 0.83547646 0.7461054  0.60516036]
 [0.18094409 0.10983482 0.02893898 ... 0.8873977  0.7810963  0.6260438 ]
 ...
 [0.17504804 0.10170537 0.01861474 ... 0.993686   0.8700404  0.69096935]
 [0.17565973 0.10251173 0.01953846 ... 0.756755   0.6794293  0.5560439 ]
 [0.17358153 0.09932545 0.01511428 ... 0.7979598  0.7129073  0.5799271 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.020716  0.237406  0.199562  ...  1.411254  1.310903  0.894023
1  0.468636  1.003791 -0.113744  ... -0.446386 -0.740531 -0.024110
2  0.156091 -0.455208 -0.653928  ... -0.091303  0.297346 -0.213459
3 -0.771806 -0.189399 -0.424863  ...  0.072679 -0.011597  0.060715
4 -0.522922 -0.875929 -0.543109  ...  1.624537  0.006467  0.658796

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10581225  0.04846172 -0.02134687 ...  0.9102739   0.830346
   0.68260795]
 [ 0.11213446  0.05695949 -0.01041982 ...  0.82990766  0.76627016
   0.638049  ]
 [ 0.10991204  0.0535748  -0.01536155 ...  0.8687295   0.79309857
   0.6544945 ]
 ...
 [ 0.10840151  0.05154447 -0.0180155  ...  0.9683167   0.8738551
   0.7113947 ]
 [ 0.10671765  0.04946503 -0.02039462 ...  0.7502079   0.7005718
   0.59118915]
 [ 0.11366704  0.05920328 -0.00719222 ...  0.7852274   0.72746694
   0.60933334]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  1.020716  0.237406  0.199562  ...  1.411254  1.310903  0.894023
1  0.468636  1.003791 -0.113744  ... -0.446386 -0.740531 -0.024110
2  0.156091 -0.455208 -0.653928  ... -0.091303  0.297346 -0.213459
3 -0.771806 -0.189399 -0.424863  ...  0.072679 -0.011597  0.060715
4 -0.522922 -0.875929 -0.543109  ...  1.624537  0.006467  0.658796

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.11695307 0.02358332 0.01575106 ... 0.8593901  0.8434095  0.7743652 ]
 [0.11832151 0.02637717 0.01979247 ... 0.7905743  0.78545016 0.7325773 ]
 [0.11502081 0.01921776 0.00853822 ... 0.84574056 0.82579976 0.7597866 ]
 ...
 [0.11709577 0.02371442 0.01559159 ... 0.9557167  0.921064   0.82928646]
 [0.11697292 0.02352771 0.01548001 ... 0.70939475 0.7133182  0.67938685]
 [0.11522856 0.01984951 0.00990197 ... 0.73621166 0.7366619  0.696469  ]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.2789e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaa9fdabd0>, <FrEIA.framework.Node object at 0x7faaa9fdadd0>, <FrEIA.framework.Node object at 0x7faaa9fdac90>, <FrEIA.framework.Node object at 0x7faaa9fda4d0>, <FrEIA.framework.Node object at 0x7faaa9fdaad0>, <FrEIA.framework.Node object at 0x7faaa9fda750>, <FrEIA.framework.Node object at 0x7faaa9fda150>, <FrEIA.framework.Node object at 0x7faab40bd790>, <FrEIA.framework.Node object at 0x7faab40bd250>, <FrEIA.framework.OutputNode object at 0x7faab40bd550>, <FrEIA.framework.ConditionNode object at 0x7faaa9fda610>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): dummy()
    (10): None
  )
)
Yang/Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005
number of trainable parameters is :
3000432
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm6.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.879018  0.634902 -0.496390  ...  0.158102  0.316629 -0.005808
1  0.601558  0.982272  0.744992  ...  0.663771  0.081705 -0.412188
2  0.075537 -0.606180  0.084010  ... -0.588110 -0.330177 -0.307394
3 -0.804458 -0.192154  0.384679  ...  0.446155 -0.172214 -0.660772
4 -0.101897 -0.828577  0.039196  ...  0.031389  0.076165 -0.788281

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06251694 0.05497676 0.0459065  ... 0.90811706 0.80436015 0.62856394]
 [0.06312597 0.0558304  0.04695006 ... 0.85611784 0.761258   0.5970882 ]
 [0.06196262 0.0539352  0.04420228 ... 0.9075475  0.80196327 0.625533  ]
 ...
 [0.06425925 0.05785947 0.05015186 ... 0.9558054  0.84219587 0.6550179 ]
 [0.06008299 0.05091821 0.03987787 ... 0.7792371  0.696705   0.5495913 ]
 [0.06198693 0.05409977 0.04459687 ... 0.74660695 0.67009693 0.5304655 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.879018  0.634902 -0.496390  ...  0.158102  0.316629 -0.005808
1  0.601558  0.982272  0.744992  ...  0.663771  0.081705 -0.412188
2  0.075537 -0.606180  0.084010  ... -0.588110 -0.330177 -0.307394
3 -0.804458 -0.192154  0.384679  ...  0.446155 -0.172214 -0.660772
4 -0.101897 -0.828577  0.039196  ...  0.031389  0.076165 -0.788281

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10759921 -0.03231785  0.04689854 ...  0.94929254  0.76780796
   0.6141614 ]
 [-0.1083841  -0.03361458  0.04479787 ...  0.9092711   0.7371019
   0.5913315 ]
 [-0.10846302 -0.03372601  0.04464248 ...  0.9500848   0.7654246
   0.6103362 ]
 ...
 [-0.10527809 -0.02848661  0.05310485 ...  1.0003518   0.8071711
   0.6435698 ]
 [-0.10858163 -0.03385985  0.04450291 ...  0.830937    0.6727129
   0.54054415]
 [-0.10800608 -0.03296173  0.04590124 ...  0.80280316  0.6506611
   0.52382815]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.879018  0.634902 -0.496390  ...  0.158102  0.316629 -0.005808
1  0.601558  0.982272  0.744992  ...  0.663771  0.081705 -0.412188
2  0.075537 -0.606180  0.084010  ... -0.588110 -0.330177 -0.307394
3 -0.804458 -0.192154  0.384679  ...  0.446155 -0.172214 -0.660772
4 -0.101897 -0.828577  0.039196  ...  0.031389  0.076165 -0.788281

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08384769 0.0572588  0.01965347 ... 0.89202607 0.7982915  0.6438908 ]
 [0.08674309 0.0613743  0.02501101 ... 0.8382245  0.7538298  0.61173403]
 [0.08407077 0.05730762 0.01943572 ... 0.88834345 0.7932832  0.6386476 ]
 ...
 [0.08297341 0.0558194  0.01757304 ... 0.9499645  0.84404975 0.67515385]
 [0.08310246 0.05610239 0.01805006 ... 0.76916367 0.69679517 0.5709148 ]
 [0.0848428  0.05872406 0.02162162 ... 0.73807925 0.6716373  0.55319816]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.879018  0.634902 -0.496390  ...  0.158102  0.316629 -0.005808
1  0.601558  0.982272  0.744992  ...  0.663771  0.081705 -0.412188
2  0.075537 -0.606180  0.084010  ... -0.588110 -0.330177 -0.307394
3 -0.804458 -0.192154  0.384679  ...  0.446155 -0.172214 -0.660772
4 -0.101897 -0.828577  0.039196  ...  0.031389  0.076165 -0.788281

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.0970452  0.07576165 0.03974891 ... 0.86110115 0.7868347  0.6557842 ]
 [0.08977394 0.06393845 0.02449632 ... 0.82627964 0.76001227 0.6384587 ]
 [0.09204057 0.06751589 0.02891769 ... 0.87262094 0.79460883 0.6601731 ]
 ...
 [0.09295943 0.06918748 0.03145593 ... 0.922606   0.83432984 0.6865239 ]
 [0.09034231 0.06505074 0.02629514 ... 0.75352395 0.701445   0.59915924]
 [0.08887932 0.06270465 0.0233247  ... 0.7283124  0.6821629  0.5867833 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.879018  0.634902 -0.496390  ...  0.158102  0.316629 -0.005808
1  0.601558  0.982272  0.744992  ...  0.663771  0.081705 -0.412188
2  0.075537 -0.606180  0.084010  ... -0.588110 -0.330177 -0.307394
3 -0.804458 -0.192154  0.384679  ...  0.446155 -0.172214 -0.660772
4 -0.101897 -0.828577  0.039196  ...  0.031389  0.076165 -0.788281

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.6941893e-01  6.2006593e-02 -2.1348894e-03 ...  8.7323529e-01
   7.8654182e-01  6.4258403e-01]
 [ 1.7094983e-01  6.4392477e-02 -1.4472008e-04 ...  8.3412397e-01
   7.5727451e-01  6.2298113e-01]
 [ 1.7607652e-01  7.2498262e-02  7.6618195e-03 ...  8.6456895e-01
   7.7421021e-01  6.3099188e-01]
 ...
 [ 1.7450884e-01  6.9966435e-02  6.2977970e-03 ...  9.3418545e-01
   8.2877755e-01  6.6893023e-01]
 [ 1.7265005e-01  6.7003489e-02  3.5341382e-03 ...  7.4894118e-01
   6.8967783e-01  5.7556409e-01]
 [ 1.6606298e-01  5.6883752e-02 -9.2393160e-03 ...  7.2790241e-01
   6.7498797e-01  5.6632763e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.879018  0.634902 -0.496390  ...  0.158102  0.316629 -0.005808
1  0.601558  0.982272  0.744992  ...  0.663771  0.081705 -0.412188
2  0.075537 -0.606180  0.084010  ... -0.588110 -0.330177 -0.307394
3 -0.804458 -0.192154  0.384679  ...  0.446155 -0.172214 -0.660772
4 -0.101897 -0.828577  0.039196  ...  0.031389  0.076165 -0.788281

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09484884 0.03815857 0.02358107 ... 0.8835894  0.7864064  0.60871327]
 [0.09239812 0.03419432 0.01799753 ... 0.84036124 0.75307167 0.58735216]
 [0.09247923 0.03430547 0.01808538 ... 0.8945855  0.79369676 0.6129234 ]
 ...
 [0.09308866 0.03538884 0.01989974 ... 0.9410225  0.83061326 0.63700795]
 [0.09053372 0.03145409 0.01496312 ... 0.7581099  0.68746305 0.5444362 ]
 [0.09217069 0.03407539 0.01859286 ... 0.7295177  0.66555995 0.53045464]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.879018  0.634902 -0.496390  ...  0.158102  0.316629 -0.005808
1  0.601558  0.982272  0.744992  ...  0.663771  0.081705 -0.412188
2  0.075537 -0.606180  0.084010  ... -0.588110 -0.330177 -0.307394
3 -0.804458 -0.192154  0.384679  ...  0.446155 -0.172214 -0.660772
4 -0.101897 -0.828577  0.039196  ...  0.031389  0.076165 -0.788281

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12680897  0.06593627 -0.01007873 ...  0.87518525  0.7824489
   0.71107876]
 [ 0.12791187  0.06705058 -0.00918436 ...  0.8303423   0.74876845
   0.6877699 ]
 [ 0.12850091  0.06673899 -0.01106083 ...  0.87731034  0.7815151
   0.7088934 ]
 ...
 [ 0.12473446  0.06255066 -0.0151208  ...  0.916751    0.81225014
   0.73084205]
 [ 0.1231606   0.06115499 -0.01590806 ...  0.74521947  0.68276846
   0.64083004]
 [ 0.12457615  0.06300551 -0.01366532 ...  0.72004884  0.6642369
   0.6282319 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.879018  0.634902 -0.496390  ...  0.158102  0.316629 -0.005808
1  0.601558  0.982272  0.744992  ...  0.663771  0.081705 -0.412188
2  0.075537 -0.606180  0.084010  ... -0.588110 -0.330177 -0.307394
3 -0.804458 -0.192154  0.384679  ...  0.446155 -0.172214 -0.660772
4 -0.101897 -0.828577  0.039196  ...  0.031389  0.076165 -0.788281

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17757183 0.10623318 0.02566743 ... 0.8811276  0.7823247  0.63050735]
 [0.1775695  0.1059382  0.02492777 ... 0.8423618  0.7513441  0.6086973 ]
 [0.17998849 0.10876754 0.02789515 ... 0.8767056  0.77449083 0.6225109 ]
 ...
 [0.17521465 0.10219449 0.01954356 ... 0.947849   0.83375114 0.665619  ]
 [0.17046416 0.09526494 0.01022807 ... 0.7618957  0.685722   0.56173366]
 [0.17170526 0.09706891 0.01261806 ... 0.73137593 0.66147107 0.5447422 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.879018  0.634902 -0.496390  ...  0.158102  0.316629 -0.005808
1  0.601558  0.982272  0.744992  ...  0.663771  0.081705 -0.412188
2  0.075537 -0.606180  0.084010  ... -0.588110 -0.330177 -0.307394
3 -0.804458 -0.192154  0.384679  ...  0.446155 -0.172214 -0.660772
4 -0.101897 -0.828577  0.039196  ...  0.031389  0.076165 -0.788281

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10975279  0.05379537 -0.01442438 ...  0.8781377   0.8041682
   0.66410553]
 [ 0.10843155  0.05160494 -0.01791713 ...  0.8374125   0.7723427
   0.6423211 ]
 [ 0.10735172  0.05012001 -0.01983944 ...  0.87980866  0.8033216
   0.662357  ]
 ...
 [ 0.10877834  0.05256344 -0.01585251 ...  0.93617713  0.8486074
   0.6940373 ]
 [ 0.10549083  0.04784513 -0.02244592 ...  0.75372744  0.7038301
   0.59368926]
 [ 0.10589674  0.04844159 -0.02161571 ...  0.7245464   0.6816405
   0.57883096]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.879018  0.634902 -0.496390  ...  0.158102  0.316629 -0.005808
1  0.601558  0.982272  0.744992  ...  0.663771  0.081705 -0.412188
2  0.075537 -0.606180  0.084010  ... -0.588110 -0.330177 -0.307394
3 -0.804458 -0.192154  0.384679  ...  0.446155 -0.172214 -0.660772
4 -0.101897 -0.828577  0.039196  ...  0.031389  0.076165 -0.788281

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.1162131  0.02206203 0.01351452 ... 0.8468472  0.83328223 0.76715446]
 [0.11653246 0.02267367 0.01431227 ... 0.80361605 0.7972821  0.7413514 ]
 [0.11545742 0.02023768 0.01029778 ... 0.8619264  0.84148026 0.7717171 ]
 ...
 [0.11769767 0.02508926 0.01795131 ... 0.8902518  0.86623514 0.78985244]
 [0.11608964 0.02174318 0.01292977 ... 0.70803976 0.7137667  0.68018913]
 [0.1135024  0.01631221 0.004713   ... 0.68842435 0.6986614  0.66971993]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.2553e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaa8fd3750>, <FrEIA.framework.Node object at 0x7faaa8c3fd50>, <FrEIA.framework.Node object at 0x7faaa8c3fd90>, <FrEIA.framework.Node object at 0x7faaa8c3fa90>, <FrEIA.framework.Node object at 0x7faaa8c3f550>, <FrEIA.framework.Node object at 0x7faaa8c3f8d0>, <FrEIA.framework.Node object at 0x7faaa8c3f250>, <FrEIA.framework.Node object at 0x7faaa8c3f2d0>, <FrEIA.framework.Node object at 0x7faaa8c3f410>, <FrEIA.framework.Node object at 0x7faaa8c36dd0>, <FrEIA.framework.Node object at 0x7faaa8c36a50>, <FrEIA.framework.Node object at 0x7faaa8c36d50>, <FrEIA.framework.Node object at 0x7faaa8c36910>, <FrEIA.framework.OutputNode object at 0x7faaa8c36790>, <FrEIA.framework.ConditionNode object at 0x7faaa9ff54d0>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): dummy()
    (14): None
  )
)
Yang/Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005
number of trainable parameters is :
4500648
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm6.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.960850  0.392892 -0.279927  ...  0.524660 -0.044437  0.249091
1  0.578910  1.105424  0.037342  ... -0.750334  0.551048  0.136765
2  0.229444 -0.510584 -0.285507  ... -0.217859  0.726751 -0.726365
3 -0.754582  0.003189 -0.179004  ...  0.168760  0.458220 -0.468946
4 -0.232814 -0.866308 -1.125593  ...  0.815015 -0.178834  0.948338

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06308465 0.05581414 0.04700072 ... 0.91618335 0.81047577 0.63262546]
 [0.06251305 0.05466478 0.04503701 ... 0.85536325 0.76033163 0.5961655 ]
 [0.06229137 0.05447856 0.04500284 ... 0.89741653 0.79414374 0.62019795]
 ...
 [0.06321479 0.05593938 0.0470725  ... 0.8849007  0.7830999  0.6116487 ]
 [0.06274268 0.05526435 0.04620044 ... 0.7434003  0.66660756 0.527341  ]
 [0.06335875 0.05624337 0.0475995  ... 0.77638024 0.69346875 0.54656154]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.960850  0.392892 -0.279927  ...  0.524660 -0.044437  0.249091
1  0.578910  1.105424  0.037342  ... -0.750334  0.551048  0.136765
2  0.229444 -0.510584 -0.285507  ... -0.217859  0.726751 -0.726365
3 -0.754582  0.003189 -0.179004  ...  0.168760  0.458220 -0.468946
4 -0.232814 -0.866308 -1.125593  ...  0.815015 -0.178834  0.948338

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10909919 -0.03480574  0.04285586 ...  0.9666616   0.7807671
   0.6235336 ]
 [-0.10828891 -0.03350815  0.04490471 ...  0.91121006  0.73650944
   0.58943605]
 [-0.10752448 -0.03221282  0.04705322 ...  0.9381881   0.75701904
   0.6045854 ]
 ...
 [-0.10829148 -0.03344774  0.04508016 ...  0.9251821   0.7441449
   0.5930059 ]
 [-0.10578617 -0.02938566  0.05158278 ...  0.7940521   0.63978565
   0.5128825 ]
 [-0.10515375 -0.02838123  0.05315718 ...  0.8449576   0.6783712
   0.54122066]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.960850  0.392892 -0.279927  ...  0.524660 -0.044437  0.249091
1  0.578910  1.105424  0.037342  ... -0.750334  0.551048  0.136765
2  0.229444 -0.510584 -0.285507  ... -0.217859  0.726751 -0.726365
3 -0.754582  0.003189 -0.179004  ...  0.168760  0.458220 -0.468946
4 -0.232814 -0.866308 -1.125593  ...  0.815015 -0.178834  0.948338

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08453376 0.05807239 0.02053545 ... 0.8971242  0.8018429  0.6458477 ]
 [0.0848629  0.05825935 0.02048412 ... 0.8439185  0.75839174 0.6147992 ]
 [0.08539597 0.05935974 0.02228856 ... 0.8731486  0.78113425 0.63020706]
 ...
 [0.08381336 0.05682503 0.01868116 ... 0.86879474 0.7772272  0.62707007]
 [0.08403782 0.05731726 0.0195077  ... 0.73171896 0.6658508  0.5485627 ]
 [0.0827553  0.05541817 0.01695492 ... 0.746753   0.6783766  0.5576699 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.960850  0.392892 -0.279927  ...  0.524660 -0.044437  0.249091
1  0.578910  1.105424  0.037342  ... -0.750334  0.551048  0.136765
2  0.229444 -0.510584 -0.285507  ... -0.217859  0.726751 -0.726365
3 -0.754582  0.003189 -0.179004  ...  0.168760  0.458220 -0.468946
4 -0.232814 -0.866308 -1.125593  ...  0.815015 -0.178834  0.948338

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.0931422  0.06933673 0.03129546 ... 0.89189315 0.8109517  0.6715834 ]
 [0.09271473 0.06845689 0.02977704 ... 0.8273699  0.76038456 0.6384396 ]
 [0.09379798 0.07034551 0.03249882 ... 0.85803354 0.7832459  0.65276366]
 ...
 [0.09391125 0.07051562 0.03269194 ... 0.8502252  0.77688336 0.64845264]
 [0.09042142 0.06506619 0.02608116 ... 0.7322233  0.6846844  0.58813435]
 [0.08832173 0.06156556 0.02141085 ... 0.7658036  0.71103424 0.6054286 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.960850  0.392892 -0.279927  ...  0.524660 -0.044437  0.249091
1  0.578910  1.105424  0.037342  ... -0.750334  0.551048  0.136765
2  0.229444 -0.510584 -0.285507  ... -0.217859  0.726751 -0.726365
3 -0.754582  0.003189 -0.179004  ...  0.168760  0.458220 -0.468946
4 -0.232814 -0.866308 -1.125593  ...  0.815015 -0.178834  0.948338

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.7473827e-01  7.0219636e-02  6.9957376e-03 ...  8.8612115e-01
   7.9497719e-01  6.4754188e-01]
 [ 1.6942389e-01  6.2120318e-02 -3.5801828e-03 ...  8.3695221e-01
   7.5898910e-01  6.2389988e-01]
 [ 1.7217810e-01  6.6451192e-02  1.0010600e-03 ...  8.7021112e-01
   7.7973354e-01  6.3542372e-01]
 ...
 [ 1.7243536e-01  6.6814601e-02  2.0033717e-03 ...  8.5429204e-01
   7.6907521e-01  6.2899721e-01]
 [ 1.6903891e-01  6.1564177e-02 -4.5483112e-03 ...  7.2856879e-01
   6.7400575e-01  5.6482720e-01]
 [ 1.7207685e-01  6.6306978e-02  5.4934621e-04 ...  7.3434293e-01
   6.7736369e-01  5.6651568e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.960850  0.392892 -0.279927  ...  0.524660 -0.044437  0.249091
1  0.578910  1.105424  0.037342  ... -0.750334  0.551048  0.136765
2  0.229444 -0.510584 -0.285507  ... -0.217859  0.726751 -0.726365
3 -0.754582  0.003189 -0.179004  ...  0.168760  0.458220 -0.468946
4 -0.232814 -0.866308 -1.125593  ...  0.815015 -0.178834  0.948338

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09440821 0.03742082 0.02246873 ... 0.890597   0.79185474 0.61222357]
 [0.0945003  0.0373643  0.02177308 ... 0.83892584 0.7511771  0.58584434]
 [0.09305847 0.03521825 0.01930095 ... 0.87796533 0.7805891  0.6044098 ]
 ...
 [0.09306894 0.03518167 0.01907986 ... 0.86234987 0.76838374 0.5965365 ]
 [0.09277214 0.03491062 0.0193498  ... 0.72815657 0.6636653  0.52892065]
 [0.09231418 0.03406322 0.01782514 ... 0.78521097 0.70795846 0.5574329 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.960850  0.392892 -0.279927  ...  0.524660 -0.044437  0.249091
1  0.578910  1.105424  0.037342  ... -0.750334  0.551048  0.136765
2  0.229444 -0.510584 -0.285507  ... -0.217859  0.726751 -0.726365
3 -0.754582  0.003189 -0.179004  ...  0.168760  0.458220 -0.468946
4 -0.232814 -0.866308 -1.125593  ...  0.815015 -0.178834  0.948338

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12579268  0.06414017 -0.01291806 ...  0.88153005  0.7871032
   0.7142323 ]
 [ 0.13266626  0.07271802 -0.0030604  ...  0.828678    0.7471043
   0.68636554]
 [ 0.12641257  0.06435165 -0.01348653 ...  0.8598547   0.76912844
   0.70076156]
 ...
 [ 0.1263301   0.06434458 -0.01334947 ...  0.8503745   0.76173383
   0.69547534]
 [ 0.12853175  0.06740326 -0.00939447 ...  0.71593916  0.6600428
   0.62465537]
 [ 0.12224662  0.0590322  -0.01978105 ...  0.7410237   0.6793492
   0.63830113]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.960850  0.392892 -0.279927  ...  0.524660 -0.044437  0.249091
1  0.578910  1.105424  0.037342  ... -0.750334  0.551048  0.136765
2  0.229444 -0.510584 -0.285507  ... -0.217859  0.726751 -0.726365
3 -0.754582  0.003189 -0.179004  ...  0.168760  0.458220 -0.468946
4 -0.232814 -0.866308 -1.125593  ...  0.815015 -0.178834  0.948338

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17597651 0.10347518 0.02148706 ... 0.89207006 0.79065347 0.63613206]
 [0.17098485 0.09562054 0.01029798 ... 0.85160065 0.7591872  0.61447793]
 [0.17448209 0.10080671 0.01729682 ... 0.8788719  0.7779949  0.626001  ]
 ...
 [0.17379384 0.09970582 0.01571298 ... 0.8707811  0.7716298  0.62157   ]
 [0.16983427 0.09389389 0.0078606  ... 0.73778355 0.6659243  0.5474913 ]
 [0.17832772 0.1063576  0.02467185 ... 0.75618744 0.6786807  0.555346  ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.960850  0.392892 -0.279927  ...  0.524660 -0.044437  0.249091
1  0.578910  1.105424  0.037342  ... -0.750334  0.551048  0.136765
2  0.229444 -0.510584 -0.285507  ... -0.217859  0.726751 -0.726365
3 -0.754582  0.003189 -0.179004  ...  0.168760  0.458220 -0.468946
4 -0.232814 -0.866308 -1.125593  ...  0.815015 -0.178834  0.948338

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.109418    0.05313247 -0.01561779 ...  0.8781389   0.8040707
   0.6639842 ]
 [ 0.11398977  0.05918306 -0.00797266 ...  0.8305938   0.7660192
   0.63744736]
 [ 0.10882124  0.05226947 -0.01680475 ...  0.8657119   0.7925844
   0.6551601 ]
 ...
 [ 0.10578099  0.04798912 -0.02261138 ...  0.851037    0.780583
   0.6466465 ]
 [ 0.10871315  0.05205144 -0.01721904 ...  0.71913993  0.67615247
   0.5743933 ]
 [ 0.10926121  0.05283953 -0.01610088 ...  0.7656628   0.712697
   0.59950536]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.960850  0.392892 -0.279927  ...  0.524660 -0.044437  0.249091
1  0.578910  1.105424  0.037342  ... -0.750334  0.551048  0.136765
2  0.229444 -0.510584 -0.285507  ... -0.217859  0.726751 -0.726365
3 -0.754582  0.003189 -0.179004  ...  0.168760  0.458220 -0.468946
4 -0.232814 -0.866308 -1.125593  ...  0.815015 -0.178834  0.948338

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.11495568 0.0193032  0.0090766  ... 0.8576623  0.84219486 0.77355206]
 [0.11555386 0.02046087 0.01061445 ... 0.7990095  0.792988   0.7381876 ]
 [0.11630224 0.02206808 0.01318091 ... 0.8398485  0.82381696 0.7592762 ]
 ...
 [0.11645697 0.02240056 0.01369989 ... 0.82072884 0.80776346 0.7478066 ]
 [0.1171416  0.02384993 0.01589549 ... 0.67863774 0.68801695 0.6613016 ]
 [0.11382361 0.01686633 0.0053173  ... 0.69521356 0.7027961  0.6722394 ]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.1655e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7faaabb0ae50>, <FrEIA.framework.Node object at 0x7faaa8c6a810>, <FrEIA.framework.Node object at 0x7faaa8c6ad50>, <FrEIA.framework.Node object at 0x7faaa8c6aa50>, <FrEIA.framework.Node object at 0x7faaa8c6a750>, <FrEIA.framework.Node object at 0x7fab940bfb10>, <FrEIA.framework.Node object at 0x7faaa8c66950>, <FrEIA.framework.Node object at 0x7faaa8c66b10>, <FrEIA.framework.Node object at 0x7faaa8c8d050>, <FrEIA.framework.Node object at 0x7faaa8c8dfd0>, <FrEIA.framework.Node object at 0x7faaa8c7d210>, <FrEIA.framework.Node object at 0x7faaa8c7ddd0>, <FrEIA.framework.Node object at 0x7faaa8c7da50>, <FrEIA.framework.OutputNode object at 0x7faaa8c3b310>, <FrEIA.framework.ConditionNode object at 0x7faaa9fdc090>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'coupling_4' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_4' takes the following inputs:
	 Output #0 of node 'coupling_4' with dims (14,)

Node 'coupling_5' takes the following inputs:
	 Output #0 of node 'permute_4' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_5' takes the following inputs:
	 Output #0 of node 'coupling_5' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_5' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (10): PermuteRandom()
    (11): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (12): PermuteRandom()
    (13): dummy()
    (14): None
  )
)
Yang/Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005
number of trainable parameters is :
4500648
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm6.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.914273  0.392213 -0.364021  ...  0.390862 -0.482751  0.156980
1  0.767742  0.960366  1.161011  ...  0.624487 -0.220521  0.369475
2 -0.046091 -0.581825 -0.032150  ...  0.636213 -0.196695 -0.048591
3 -0.685744 -0.232930 -1.422714  ... -0.102783 -0.277153 -0.384953
4 -0.563577 -0.861077  0.378603  ...  0.245649  0.221293  0.223901

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.0612564  0.05289152 0.04283269 ... 0.91885567 0.8135489  0.6354485 ]
 [0.06191885 0.0538577  0.04408035 ... 0.83351624 0.7431028  0.58423144]
 [0.06093021 0.05204967 0.04118145 ... 0.8998887  0.79633427 0.62187076]
 ...
 [0.06205936 0.05413491 0.04454884 ... 1.0027136  0.8810196  0.6833208 ]
 [0.06044129 0.0517169  0.04132111 ... 0.7863172  0.70290464 0.55439156]
 [0.06119277 0.05268153 0.04237138 ... 0.7496982  0.67205626 0.5314578 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.914273  0.392213 -0.364021  ...  0.390862 -0.482751  0.156980
1  0.767742  0.960366  1.161011  ...  0.624487 -0.220521  0.369475
2 -0.046091 -0.581825 -0.032150  ...  0.636213 -0.196695 -0.048591
3 -0.685744 -0.232930 -1.422714  ... -0.102783 -0.277153 -0.384953
4 -0.563577 -0.861077  0.378603  ...  0.245649  0.221293  0.223901

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10766464 -0.03239125  0.04682282 ...  0.96077657  0.77824223
   0.62302697]
 [-0.10916901 -0.0349023   0.04272136 ...  0.8845674   0.71730363
   0.576035  ]
 [-0.10958152 -0.03560734  0.0415619  ...  0.9474199   0.7659857
   0.6125425 ]
 ...
 [-0.11111033 -0.03797486  0.03791201 ...  1.0453482   0.8462986
   0.6758245 ]
 [-0.1073468  -0.03184628  0.04773808 ...  0.84445703  0.6824938
   0.5474205 ]
 [-0.11203004 -0.0394969   0.03544849 ...  0.8093265   0.6568197
   0.5292078 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.914273  0.392213 -0.364021  ...  0.390862 -0.482751  0.156980
1  0.767742  0.960366  1.161011  ...  0.624487 -0.220521  0.369475
2 -0.046091 -0.581825 -0.032150  ...  0.636213 -0.196695 -0.048591
3 -0.685744 -0.232930 -1.422714  ... -0.102783 -0.277153 -0.384953
4 -0.563577 -0.861077  0.378603  ...  0.245649  0.221293  0.223901

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.08426055 0.05783242 0.0203846  ... 0.9055571  0.8091833  0.6514262 ]
 [0.08528934 0.05923911 0.02216044 ... 0.82607436 0.744479   0.60557246]
 [0.08516126 0.05887762 0.02149825 ... 0.8853422  0.791202   0.6374438 ]
 ...
 [0.08379395 0.05696927 0.01904996 ... 0.97523725 0.8642263  0.6890809 ]
 [0.08314756 0.05638925 0.01865926 ... 0.7749643  0.7014769  0.5743255 ]
 [0.08344302 0.05646767 0.01839756 ... 0.7326898  0.6669382  0.5495863 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.914273  0.392213 -0.364021  ...  0.390862 -0.482751  0.156980
1  0.767742  0.960366  1.161011  ...  0.624487 -0.220521  0.369475
2 -0.046091 -0.581825 -0.032150  ...  0.636213 -0.196695 -0.048591
3 -0.685744 -0.232930 -1.422714  ... -0.102783 -0.277153 -0.384953
4 -0.563577 -0.861077  0.378603  ...  0.245649  0.221293  0.223901

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09279118 0.06901117 0.03140815 ... 0.8779956  0.8003057  0.66473776]
 [0.09592173 0.07388063 0.0372211  ... 0.81345487 0.7494904  0.6313084 ]
 [0.09101239 0.06562631 0.02598447 ... 0.86377573 0.78814197 0.65620214]
 ...
 [0.09031126 0.06474799 0.02544062 ... 0.96186376 0.8649907  0.70656025]
 [0.0911895  0.06667997 0.02892642 ... 0.7618953  0.70800745 0.60344833]
 [0.08904797 0.0627269  0.02286127 ... 0.7359059  0.68746495 0.58990604]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.914273  0.392213 -0.364021  ...  0.390862 -0.482751  0.156980
1  0.767742  0.960366  1.161011  ...  0.624487 -0.220521  0.369475
2 -0.046091 -0.581825 -0.032150  ...  0.636213 -0.196695 -0.048591
3 -0.685744 -0.232930 -1.422714  ... -0.102783 -0.277153 -0.384953
4 -0.563577 -0.861077  0.378603  ...  0.245649  0.221293  0.223901

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 1.7559594e-01  7.1536362e-02  8.9192986e-03 ...  8.8173902e-01
   7.9168957e-01  6.4532864e-01]
 [ 1.7161687e-01  6.5414280e-02  1.1990964e-03 ...  8.1176543e-01
   7.4010479e-01  6.1125183e-01]
 [ 1.7277868e-01  6.7310542e-02  1.9925833e-03 ...  8.6678302e-01
   7.7811301e-01  6.3487524e-01]
 ...
 [ 1.7032571e-01  6.3529134e-02 -1.4008880e-03 ...  9.6305329e-01
   8.5091770e-01  6.8405479e-01]
 [ 1.7119724e-01  6.4755261e-02  7.8967214e-04 ...  7.5053132e-01
   6.9022274e-01  5.7557505e-01]
 [ 1.7450358e-01  7.0075780e-02  4.6392679e-03 ...  7.1432292e-01
   6.6190100e-01  5.5588949e-01]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.914273  0.392213 -0.364021  ...  0.390862 -0.482751  0.156980
1  0.767742  0.960366  1.161011  ...  0.624487 -0.220521  0.369475
2 -0.046091 -0.581825 -0.032150  ...  0.636213 -0.196695 -0.048591
3 -0.685744 -0.232930 -1.422714  ... -0.102783 -0.277153 -0.384953
4 -0.563577 -0.861077  0.378603  ...  0.245649  0.221293  0.223901

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09320228 0.03561658 0.02035956 ... 0.8941908  0.79525876 0.6146481 ]
 [0.09456934 0.03765672 0.02272809 ... 0.8204416  0.73723733 0.57702065]
 [0.09371388 0.03620882 0.02049813 ... 0.8779595  0.78117025 0.6050134 ]
 ...
 [0.09362382 0.03615682 0.0206933  ... 0.9759325  0.85751104 0.6542406 ]
 [0.08843516 0.02836818 0.01154132 ... 0.7744349  0.70100284 0.5534641 ]
 [0.09138431 0.0327152  0.0163983  ... 0.7381394  0.6716347  0.53413373]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.914273  0.392213 -0.364021  ...  0.390862 -0.482751  0.156980
1  0.767742  0.960366  1.161011  ...  0.624487 -0.220521  0.369475
2 -0.046091 -0.581825 -0.032150  ...  0.636213 -0.196695 -0.048591
3 -0.685744 -0.232930 -1.422714  ... -0.102783 -0.277153 -0.384953
4 -0.563577 -0.861077  0.378603  ...  0.245649  0.221293  0.223901

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.13020197  0.07061026 -0.0040575  ...  0.8824893   0.7877027
   0.71457344]
 [ 0.1281752   0.06725344 -0.00913471 ...  0.8155867   0.73750144
   0.67986023]
 [ 0.13072824  0.06967705 -0.00746602 ...  0.8665539   0.7742743
   0.70439255]
 ...
 [ 0.12742522  0.06626675 -0.0103288  ...  0.9577807   0.8429195
   0.7519783 ]
 [ 0.12417373  0.06307182 -0.01274756 ...  0.75655496  0.6908831
   0.6462017 ]
 [ 0.12664434  0.06466275 -0.01310185 ...  0.7178238   0.6615495
   0.6257548 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.914273  0.392213 -0.364021  ...  0.390862 -0.482751  0.156980
1  0.767742  0.960366  1.161011  ...  0.624487 -0.220521  0.369475
2 -0.046091 -0.581825 -0.032150  ...  0.636213 -0.196695 -0.048591
3 -0.685744 -0.232930 -1.422714  ... -0.102783 -0.277153 -0.384953
4 -0.563577 -0.861077  0.378603  ...  0.245649  0.221293  0.223901

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17687482 0.10490221 0.02351913 ... 0.8999946  0.79684603 0.64040625]
 [0.17157277 0.09702662 0.01279181 ... 0.83352596 0.7455753  0.60538036]
 [0.17450713 0.10070029 0.01697904 ... 0.87723535 0.7770468  0.62554145]
 ...
 [0.17696021 0.104711   0.02288231 ... 0.9729963  0.85325325 0.67900443]
 [0.17006531 0.094917   0.01000708 ... 0.77185905 0.6939318  0.56765735]
 [0.17247738 0.09760356 0.01266295 ... 0.73484015 0.6628293  0.54488534]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.914273  0.392213 -0.364021  ...  0.390862 -0.482751  0.156980
1  0.767742  0.960366  1.161011  ...  0.624487 -0.220521  0.369475
2 -0.046091 -0.581825 -0.032150  ...  0.636213 -0.196695 -0.048591
3 -0.685744 -0.232930 -1.422714  ... -0.102783 -0.277153 -0.384953
4 -0.563577 -0.861077  0.378603  ...  0.245649  0.221293  0.223901

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10926384  0.05320725 -0.01506016 ...  0.8905231   0.81416845
   0.6711283 ]
 [ 0.10975002  0.05360128 -0.01497936 ...  0.8126775   0.7527894
   0.6288159 ]
 [ 0.10945837  0.05290344 -0.01637527 ...  0.87483907  0.8001692
   0.66059494]
 ...
 [ 0.10871451  0.05234942 -0.01634961 ...  0.9569278   0.8650104
   0.705366  ]
 [ 0.10468838  0.04705025 -0.02301845 ...  0.75603473  0.70588
   0.5952116 ]
 [ 0.10382782  0.04526159 -0.02630645 ...  0.7462286   0.6982701
   0.59005594]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.914273  0.392213 -0.364021  ...  0.390862 -0.482751  0.156980
1  0.767742  0.960366  1.161011  ...  0.624487 -0.220521  0.369475
2 -0.046091 -0.581825 -0.032150  ...  0.636213 -0.196695 -0.048591
3 -0.685744 -0.232930 -1.422714  ... -0.102783 -0.277153 -0.384953
4 -0.563577 -0.861077  0.378603  ...  0.245649  0.221293  0.223901

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.1165252  0.02268389 0.01439485 ... 0.85319155 0.8380818  0.7705225 ]
 [0.11548136 0.02041143 0.01077658 ... 0.77720755 0.77543813 0.725708  ]
 [0.11477491 0.01879871 0.0080705  ... 0.84931    0.8327749  0.76604676]
 ...
 [0.11569506 0.02083951 0.01141369 ... 0.94786453 0.9146389  0.8247179 ]
 [0.1134568  0.01623183 0.00462553 ... 0.71250665 0.7178379  0.68315756]
 [0.11465424 0.01856643 0.00779504 ... 0.688501   0.6964204  0.6673999 ]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=7.9699e-03)
Evaluation finished
Retrieving flag object for parameters
after removing prefix models/, now model_dir is: Yang/Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005
Your dataset is none of the artificial datasets
In read_data, flags.data_set = Yang_sim
shape of data_x (10000, 14)
shape of data_y (10000, 2000)
total number of training sample is 7500, the dimension of the feature is 14
total number of test sample is 2500
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/Yang/Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005
The nodes are: [<FrEIA.framework.InputNode object at 0x7fab911d0ad0>, <FrEIA.framework.Node object at 0x7fab911c4390>, <FrEIA.framework.Node object at 0x7fab911c4e10>, <FrEIA.framework.Node object at 0x7fab911c4fd0>, <FrEIA.framework.Node object at 0x7faaa7fd8e50>, <FrEIA.framework.Node object at 0x7fab911d4190>, <FrEIA.framework.Node object at 0x7faaab23b690>, <FrEIA.framework.Node object at 0x7faab55c5890>, <FrEIA.framework.Node object at 0x7faab55c5310>, <FrEIA.framework.OutputNode object at 0x7faab55c5050>, <FrEIA.framework.ConditionNode object at 0x7fab911d0f50>]
Node 'coupling_0' takes the following inputs:
	 Output #0 of node 'input' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_0' takes the following inputs:
	 Output #0 of node 'coupling_0' with dims (14,)

Node 'coupling_1' takes the following inputs:
	 Output #0 of node 'permute_0' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_1' takes the following inputs:
	 Output #0 of node 'coupling_1' with dims (14,)

Node 'coupling_2' takes the following inputs:
	 Output #0 of node 'permute_1' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_2' takes the following inputs:
	 Output #0 of node 'coupling_2' with dims (14,)

Node 'coupling_3' takes the following inputs:
	 Output #0 of node 'permute_2' with dims (14,)
	 conditioned on node 'node' with dims (2000,)

Node 'permute_3' takes the following inputs:
	 Output #0 of node 'coupling_3' with dims (14,)

Node 'output' takes the following inputs:
	 Output #0 of node 'permute_3' with dims (14,)

ReversibleGraphNet(
  (module_list): ModuleList(
    (0): None
    (1): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (2): PermuteRandom()
    (3): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (4): PermuteRandom()
    (5): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (6): PermuteRandom()
    (7): GLOWCouplingBlock(
      (s1): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
      (s2): Sequential(
        (0): Linear(in_features=2007, out_features=160, bias=True)
        (1): ReLU()
        (2): Linear(in_features=160, out_features=160, bias=True)
        (3): ReLU()
        (4): Linear(in_features=160, out_features=160, bias=True)
        (5): ReLU()
        (6): Linear(in_features=160, out_features=14, bias=True)
      )
    )
    (8): PermuteRandom()
    (9): dummy()
    (10): None
  )
)
Yang/Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005
number of trainable parameters is :
3000432
Start eval now:
entering folder to predict: ../Data/Yang_sim/state_dicts/
entering: mm8.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm4.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm5.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: mm1.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num5labmda_mse100_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm6.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num7labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm9.pt
entering: mm0.pt
entering: mm3.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num9labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num6labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse1_lr_0.001_reg_scale_0.005.csv.png
entering: mm2.pt
entering: ensemble_plothomesr365MM_BenchcINNdatatest_Xpred_Yang_Yang_simcouple_layer_num8labmda_mse10_lr_0.001_reg_scale_0.005.csv.png
entering: mm7.pt
this is doing ensemble prediction for models : ['../Data/Yang_sim/state_dicts/mm8.pt', '../Data/Yang_sim/state_dicts/mm4.pt', '../Data/Yang_sim/state_dicts/mm5.pt', '../Data/Yang_sim/state_dicts/mm1.pt', '../Data/Yang_sim/state_dicts/mm6.pt', '../Data/Yang_sim/state_dicts/mm9.pt', '../Data/Yang_sim/state_dicts/mm0.pt', '../Data/Yang_sim/state_dicts/mm3.pt', '../Data/Yang_sim/state_dicts/mm2.pt', '../Data/Yang_sim/state_dicts/mm7.pt']
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.860606  0.155447  1.179917  ...  0.406369 -0.528712 -0.343267
1  0.594505  0.808283 -0.374011  ... -0.452236  0.742534 -1.481412
2  0.164007 -0.594004 -1.042262  ...  1.043348 -0.061643 -0.827611
3 -0.691981  0.151223 -0.773461  ...  0.168119 -0.746642 -0.058981
4 -0.153021 -0.864379  0.002816  ...  0.154054  0.569624  0.483272

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.06384952 0.05717485 0.04912921 ... 0.98225147 0.86471057 0.67184544]
 [0.06483436 0.05870884 0.0512635  ... 0.84670603 0.7532581  0.59110266]
 [0.06211877 0.05408963 0.04429213 ... 0.9113647  0.8050023  0.62763643]
 ...
 [0.06214754 0.0540701  0.0441734  ... 1.002567   0.8810227  0.68334246]
 [0.05973907 0.05032652 0.03897248 ... 0.75567573 0.67721206 0.53539705]
 [0.06519961 0.05953502 0.05276835 ... 0.77218294 0.6900412  0.5441646 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.860606  0.155447  1.179917  ...  0.406369 -0.528712 -0.343267
1  0.594505  0.808283 -0.374011  ... -0.452236  0.742534 -1.481412
2  0.164007 -0.594004 -1.042262  ...  1.043348 -0.061643 -0.827611
3 -0.691981  0.151223 -0.773461  ...  0.168119 -0.746642 -0.058981
4 -0.153021 -0.864379  0.002816  ...  0.154054  0.569624  0.483272

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[-0.10903662 -0.03461495  0.04327291 ...  1.0153706   0.82202697
   0.65689707]
 [-0.10699971 -0.03136653  0.04839325 ...  0.8798753   0.71265113
   0.57184625]
 [-0.10734719 -0.03195089  0.04744086 ...  0.95016205  0.7645992
   0.60910904]
 ...
 [-0.11195275 -0.03940582  0.03554329 ...  1.0434434   0.8446747
   0.67448354]
 [-0.11194126 -0.03934067  0.03570855 ...  0.8174436   0.6624813
   0.53302777]
 [-0.10786285 -0.03268433  0.04639378 ...  0.8303139   0.6716
   0.5392865 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.860606  0.155447  1.179917  ...  0.406369 -0.528712 -0.343267
1  0.594505  0.808283 -0.374011  ... -0.452236  0.742534 -1.481412
2  0.164007 -0.594004 -1.042262  ...  1.043348 -0.061643 -0.827611
3 -0.691981  0.151223 -0.773461  ...  0.168119 -0.746642 -0.058981
4 -0.153021 -0.864379  0.002816  ...  0.154054  0.569624  0.483272

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.0864218  0.06103708 0.02469295 ... 0.9634572  0.8550404  0.68287253]
 [0.08680578 0.06142291 0.02502885 ... 0.82660735 0.74430484 0.60490173]
 [0.08453763 0.05793825 0.02022194 ... 0.8928921  0.7967919  0.64093536]
 ...
 [0.08543681 0.05919268 0.02182213 ... 0.9861441  0.8727942  0.6947652 ]
 [0.08305194 0.05590065 0.01764824 ... 0.73819697 0.6712267  0.5525046 ]
 [0.08500486 0.05912134 0.02231316 ... 0.77441835 0.7007846  0.5735205 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.860606  0.155447  1.179917  ...  0.406369 -0.528712 -0.343267
1  0.594505  0.808283 -0.374011  ... -0.452236  0.742534 -1.481412
2  0.164007 -0.594004 -1.042262  ...  1.043348 -0.061643 -0.827611
3 -0.691981  0.151223 -0.773461  ...  0.168119 -0.746642 -0.058981
4 -0.153021 -0.864379  0.002816  ...  0.154054  0.569624  0.483272

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09373979 0.0704685  0.0330995  ... 0.9337591  0.8435041  0.6927786 ]
 [0.09411223 0.07075967 0.0328061  ... 0.8076303  0.74485004 0.62821984]
 [0.09205398 0.06741127 0.02850682 ... 0.87628365 0.7974564  0.6620328 ]
 ...
 [0.09371354 0.07001585 0.03165349 ... 0.95950246 0.8632684  0.70552456]
 [0.08780366 0.06087959 0.02084662 ... 0.7343591  0.6863998  0.58928144]
 [0.09120049 0.06652969 0.02839921 ... 0.7694434  0.7137252  0.6071075 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.860606  0.155447  1.179917  ...  0.406369 -0.528712 -0.343267
1  0.594505  0.808283 -0.374011  ... -0.452236  0.742534 -1.481412
2  0.164007 -0.594004 -1.042262  ...  1.043348 -0.061643 -0.827611
3 -0.691981  0.151223 -0.773461  ...  0.168119 -0.746642 -0.058981
4 -0.153021 -0.864379  0.002816  ...  0.154054  0.569624  0.483272

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.16626176  0.05720413 -0.00846034 ...  0.94810474  0.8416522
   0.6789571 ]
 [ 0.17717008  0.07403785  0.01073068 ...  0.8122689   0.73873985
   0.6093396 ]
 [ 0.17475133  0.07043704  0.00543565 ...  0.88062084  0.78700805
   0.6399921 ]
 ...
 [ 0.16957751  0.06234214 -0.00296786 ...  0.97351515  0.8605882
   0.69157124]
 [ 0.1689705   0.06148598 -0.0047664  ...  0.7351248   0.67835456
   0.5674254 ]
 [ 0.17319882  0.06785387  0.00448301 ...  0.75799084  0.69584584
   0.5793549 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.860606  0.155447  1.179917  ...  0.406369 -0.528712 -0.343267
1  0.594505  0.808283 -0.374011  ... -0.452236  0.742534 -1.481412
2  0.164007 -0.594004 -1.042262  ...  1.043348 -0.061643 -0.827611
3 -0.691981  0.151223 -0.773461  ...  0.168119 -0.746642 -0.058981
4 -0.153021 -0.864379  0.002816  ...  0.154054  0.569624  0.483272

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.09338735 0.03592432 0.02082132 ... 0.959149   0.8453237  0.64671624]
 [0.09417777 0.03701614 0.02180423 ... 0.8202746  0.7371452  0.5769778 ]
 [0.09418856 0.03695197 0.02146696 ... 0.8928977  0.7918166  0.61149865]
 ...
 [0.09389442 0.03644031 0.02063376 ... 0.9700378  0.85323393 0.6516154 ]
 [0.09143737 0.03289491 0.01693337 ... 0.73935854 0.67268455 0.5348407 ]
 [0.09304805 0.03553133 0.02074297 ... 0.76242673 0.6907046  0.54647815]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.860606  0.155447  1.179917  ...  0.406369 -0.528712 -0.343267
1  0.594505  0.808283 -0.374011  ... -0.452236  0.742534 -1.481412
2  0.164007 -0.594004 -1.042262  ...  1.043348 -0.061643 -0.827611
3 -0.691981  0.151223 -0.773461  ...  0.168119 -0.746642 -0.058981
4 -0.153021 -0.864379  0.002816  ...  0.154054  0.569624  0.483272

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.12538937  0.06423044 -0.01193807 ...  0.9357629   0.8275893
   0.74210227]
 [ 0.13249165  0.07255039 -0.00317657 ...  0.7983534   0.7243092
   0.6705783 ]
 [ 0.13183662  0.07142353 -0.0049147  ...  0.8783615   0.7825433
   0.70975065]
 ...
 [ 0.12665829  0.06471914 -0.01298222 ...  0.9678602   0.8512005
   0.7581429 ]
 [ 0.12494862  0.06264418 -0.01527989 ...  0.724697    0.6665927
   0.6291722 ]
 [ 0.12749162  0.06692591 -0.00873151 ...  0.7525159   0.6875849
   0.6437603 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.860606  0.155447  1.179917  ...  0.406369 -0.528712 -0.343267
1  0.594505  0.808283 -0.374011  ... -0.452236  0.742534 -1.481412
2  0.164007 -0.594004 -1.042262  ...  1.043348 -0.061643 -0.827611
3 -0.691981  0.151223 -0.773461  ...  0.168119 -0.746642 -0.058981
4 -0.153021 -0.864379  0.002816  ...  0.154054  0.569624  0.483272

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.17445615 0.10129717 0.0185869  ... 0.9596756  0.84418464 0.67353034]
 [0.17571141 0.1027061  0.01999798 ... 0.81620824 0.72999644 0.5934094 ]
 [0.1769532  0.10423318 0.02169135 ... 0.8858601  0.78237    0.62838256]
 ...
 [0.17714216 0.10501468 0.02335551 ... 0.97783625 0.85774255 0.682526  ]
 [0.17038544 0.0946812  0.00889093 ... 0.74614394 0.67199993 0.55142164]
 [0.17029038 0.09498689 0.00979587 ... 0.7879192  0.70607316 0.5758062 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.860606  0.155447  1.179917  ...  0.406369 -0.528712 -0.343267
1  0.594505  0.808283 -0.374011  ... -0.452236  0.742534 -1.481412
2  0.164007 -0.594004 -1.042262  ...  1.043348 -0.061643 -0.827611
3 -0.691981  0.151223 -0.773461  ...  0.168119 -0.746642 -0.058981
4 -0.153021 -0.864379  0.002816  ...  0.154054  0.569624  0.483272

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[ 0.10934852  0.05335943 -0.01481175 ...  0.93309844  0.84718215
   0.69359636]
 [ 0.1111314   0.05533554 -0.01293269 ...  0.8110657   0.75118256
   0.6275246 ]
 [ 0.10829572  0.0515054  -0.01787648 ...  0.8866606   0.80890286
   0.66630757]
 ...
 [ 0.10833876  0.05148555 -0.01805726 ...  0.96023643  0.8680706
   0.7077326 ]
 [ 0.10622691  0.04865095 -0.0216811  ...  0.7403382   0.69285035
   0.5858979 ]
 [ 0.11096081  0.05582172 -0.01115581 ...  0.76756394  0.7142211
   0.6006081 ]]
Evaluation finished
This is doing the prediction for file /home/sr365/MM_Bench/cINN/data/test_Xpred_Yang_Yang_simcouple_layer_num4labmda_mse100_lr_0.001_reg_scale_0.005.csv
Retrieving flag object for parameters
Making network now
This is inference mode, the ckpt is /home/sr365/MM_Bench/cINN/models/../Data/Yang_sim/model_param
NA(
  (linears): ModuleList(
    (0): Linear(in_features=14, out_features=1000, bias=True)
    (1): Linear(in_features=1000, out_features=1000, bias=True)
    (2): Linear(in_features=1000, out_features=1000, bias=True)
    (3): Linear(in_features=1000, out_features=1000, bias=True)
    (4): Linear(in_features=1000, out_features=1000, bias=True)
    (5): Linear(in_features=1000, out_features=1000, bias=True)
    (6): Linear(in_features=1000, out_features=1000, bias=True)
    (7): Linear(in_features=1000, out_features=1000, bias=True)
    (8): Linear(in_features=1000, out_features=1000, bias=True)
    (9): Linear(in_features=1000, out_features=1000, bias=True)
    (10): Linear(in_features=1000, out_features=1000, bias=True)
    (11): Linear(in_features=1000, out_features=1000, bias=True)
    (12): Linear(in_features=1000, out_features=500, bias=True)
  )
  (bn_linears): ModuleList(
    (0): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (convs): ModuleList(
    (0): ConvTranspose1d(1, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (1): ConvTranspose1d(4, 4, kernel_size=(8,), stride=(2,), padding=(3,))
    (2): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (3): ConvTranspose1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))
    (4): Conv1d(4, 1, kernel_size=(1,), stride=(1,))
  )
)
number of trainable parameters is :
11551841
Start eval now:
entering predict function
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2500 entries, 0 to 2499
Data columns (total 14 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   0       2500 non-null   float64
 1   1       2500 non-null   float64
 2   2       2500 non-null   float64
 3   3       2500 non-null   float64
 4   4       2500 non-null   float64
 5   5       2500 non-null   float64
 6   6       2500 non-null   float64
 7   7       2500 non-null   float64
 8   8       2500 non-null   float64
 9   9       2500 non-null   float64
 10  10      2500 non-null   float64
 11  11      2500 non-null   float64
 12  12      2500 non-null   float64
 13  13      2500 non-null   float64
dtypes: float64(14)
memory usage: 273.6 KB
         0         1         2   ...        11        12        13
0  0.860606  0.155447  1.179917  ...  0.406369 -0.528712 -0.343267
1  0.594505  0.808283 -0.374011  ... -0.452236  0.742534 -1.481412
2  0.164007 -0.594004 -1.042262  ...  1.043348 -0.061643 -0.827611
3 -0.691981  0.151223 -0.773461  ...  0.168119 -0.746642 -0.058981
4 -0.153021 -0.864379  0.002816  ...  0.154054  0.569624  0.483272

[5 rows x 14 columns]
Xpred shape (2500, 14)
[[0.11500354 0.01947078 0.0094904  ... 0.9044395  0.8809536  0.8013305 ]
 [0.11646338 0.02242854 0.01373458 ... 0.7860465  0.7817433  0.7299365 ]
 [0.11675265 0.02296856 0.01444036 ... 0.847836   0.83019376 0.76381797]
 ...
 [0.11463213 0.01855683 0.00782028 ... 0.9439333  0.91325283 0.82433265]
 [0.11351147 0.01622778 0.00438583 ... 0.69756925 0.70455295 0.6733916 ]
 [0.11628744 0.02220723 0.01375085 ... 0.71704507 0.7209871  0.6852567 ]]
Evaluation finished
in compare truth pred function in eval_help package, your shape of pred file is (2500, 2000)
(Avg MSE=8.1860e-03)
Evaluation finished
